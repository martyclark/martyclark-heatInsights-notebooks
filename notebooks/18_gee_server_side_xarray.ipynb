{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Efficient GEE ‚Üí xarray Climate Analysis\n",
    "\n",
    "This notebook implements the **most efficient approach** for large-scale climate analysis:\n",
    "1. **Minimal GEE preprocessing** - Just data filtering and scaling\n",
    "2. **Direct array extraction** - No file exports, just raw pixel data\n",
    "3. **Fast xarray processing** - Vectorized operations on extracted arrays\n",
    "4. **Preserve coordinates** - Keep x,y for spatial conversion back to rasters\n",
    "\n",
    "## Key Advantages:\n",
    "- ‚ö° **Lightning fast** - No file I/O bottlenecks\n",
    "- üéØ **No transfer limits** - Direct memory to memory\n",
    "- üöÄ **Efficient processing** - xarray vectorization >> GEE server ops\n",
    "- üìç **Coordinates preserved** - Easy conversion back to NetCDF/TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_7TDKVSyKvBdmMqW?ref=4i2o6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Earth Engine initialized successfully\n",
      "üì¶ Available packages:\n",
      "   - xarray: 2024.7.0\n",
      "   - pandas: 2.3.1\n",
      "   - numpy: 1.26.4\n",
      "üìÅ Created outputs directory: ../outputs\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import ee\n",
    "import geemap\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import rasterio\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Initialize Earth Engine with your project\n",
    "try:\n",
    "    ee.Initialize(project='tl-cities')\n",
    "    print('‚úÖ Earth Engine initialized successfully')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Earth Engine initialization failed: {e}')\n",
    "\n",
    "print('üì¶ Available packages:')\n",
    "print(f'   - xarray: {xr.__version__}')\n",
    "print(f'   - pandas: {pd.__version__}')\n",
    "print(f'   - numpy: {np.__version__}')\n",
    "\n",
    "# Create outputs directory\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "print('üìÅ Created outputs directory: ../outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove the pip install cell and replace with header\n",
    "## üéØ Step 1: ROI Selection (Same as Notebook 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 1: ROI Selection (Same as Notebook 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5b1eadab5c4d65bd73d2c021337e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üéØ ROI Selection</h3>'), HTML(value='<b>Method 1: Draw on Map</b>'), Button(butt‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa860d806d84d56be2a9f727c322bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-12.9714, -38.5014], controls=(WidgetControl(options=['position', 'transparent_bg'], position='top‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ROI Selection Ready\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "analysis_geom = None\n",
    "temperature_data = None\n",
    "climate_results = {}\n",
    "\n",
    "# Create map for ROI selection (same as notebooks 16/17)\n",
    "m = geemap.Map(center=[-12.9714, -38.5014], zoom=10)  # Salvador, Brazil\n",
    "m.add_basemap('SATELLITE')\n",
    "m.add('draw_control')\n",
    "\n",
    "def set_roi_from_drawing():\n",
    "    '''Extract ROI from map drawing'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        if hasattr(m, 'draw_control') and len(m.draw_control.data) > 0:\n",
    "            feature = m.draw_control.data[-1]\n",
    "            coords = feature['geometry']['coordinates']\n",
    "            \n",
    "            if feature['geometry']['type'] == 'Polygon':\n",
    "                analysis_geom = ee.Geometry.Polygon(coords)\n",
    "            elif feature['geometry']['type'] == 'Rectangle':\n",
    "                analysis_geom = ee.Geometry.Rectangle(coords)\n",
    "            \n",
    "            area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "            bounds_info = analysis_geom.bounds().getInfo()['coordinates'][0]\n",
    "            west, south = bounds_info[0]\n",
    "            east, north = bounds_info[2]\n",
    "            \n",
    "            print(f'‚úÖ ROI set from drawing: {area_km2:.1f} km¬≤')\n",
    "            print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            return True\n",
    "        else:\n",
    "            print('‚ùå No drawing found. Please draw a polygon or rectangle on the map.')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from drawing: {e}')\n",
    "        return False\n",
    "\n",
    "def set_roi_from_coordinates():\n",
    "    '''Set ROI from coordinate inputs'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        west = float(west_input.value) if west_input.value else -38.7\n",
    "        east = float(east_input.value) if east_input.value else -38.3\n",
    "        south = float(south_input.value) if south_input.value else -13.1\n",
    "        north = float(north_input.value) if north_input.value else -12.8\n",
    "        \n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north])\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['red'], 'max': 1}, 'ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'‚úÖ ROI set from coordinates: {area_km2:.1f} km¬≤')\n",
    "        print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from coordinates: {e}')\n",
    "        return False\n",
    "\n",
    "def browse_raster_file():\n",
    "    '''Open file browser to select raster file'''\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        \n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title='Select Reference Raster File',\n",
    "            filetypes=[\n",
    "                ('Raster files', '*.tif *.tiff *.img *.nc *.hdf *.jp2'),\n",
    "                ('GeoTIFF', '*.tif *.tiff'),\n",
    "                ('NetCDF', '*.nc'),\n",
    "                ('All files', '*.*')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        root.destroy()\n",
    "        \n",
    "        if file_path:\n",
    "            raster_path_display.value = file_path\n",
    "            print(f'üìÅ Selected file: {os.path.basename(file_path)}')\n",
    "            return file_path\n",
    "        else:\n",
    "            print('‚ùå No file selected')\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error opening file browser: {e}')\n",
    "        return None\n",
    "\n",
    "def set_roi_from_raster():\n",
    "    '''Set ROI from selected raster extent with proper CRS handling'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        raster_path = raster_path_display.value.strip()\n",
    "        \n",
    "        if not raster_path or not os.path.exists(raster_path):\n",
    "            print('‚ùå Please select a valid raster file first')\n",
    "            return False\n",
    "        \n",
    "        print(f'üìñ Reading raster: {os.path.basename(raster_path)}')\n",
    "        \n",
    "        with rasterio.open(raster_path) as src:\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "            \n",
    "            west, south, east, north = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "            \n",
    "            print(f'   üìä Original CRS: {crs}')\n",
    "            print(f'   üìä Original bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            \n",
    "            # Transform to WGS84 if needed\n",
    "            if crs.to_epsg() != 4326:\n",
    "                from rasterio.warp import transform_bounds\n",
    "                west, south, east, north = transform_bounds(\n",
    "                    crs, 'EPSG:4326', west, south, east, north\n",
    "                )\n",
    "                print(f'   üîÑ Transformed to WGS84: W={west:.6f}, E={east:.6f}, S={south:.6f}, N={north:.6f}')\n",
    "        \n",
    "        # Create geometry\n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north], 'EPSG:4326')\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['blue'], 'max': 1}, 'Raster ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'   ‚úÖ ROI set from raster extent: {area_km2:.1f} km¬≤')\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from raster: {e}')\n",
    "        return False\n",
    "\n",
    "# ROI input widgets\n",
    "west_input = widgets.FloatText(value=-38.7, description='West:')\n",
    "east_input = widgets.FloatText(value=-38.3, description='East:')\n",
    "south_input = widgets.FloatText(value=-13.1, description='South:')\n",
    "north_input = widgets.FloatText(value=-12.8, description='North:')\n",
    "\n",
    "raster_path_display = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='No file selected...',\n",
    "    description='Selected File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "browse_button = widgets.Button(description='üìÇ Browse Files', button_style='info')\n",
    "browse_button.on_click(lambda b: browse_raster_file())\n",
    "\n",
    "# Action buttons\n",
    "set_drawing_button = widgets.Button(description='üìç Use Drawing', button_style='success')\n",
    "set_coords_button = widgets.Button(description='üìç Use Coordinates', button_style='info')\n",
    "set_raster_button = widgets.Button(description='üìç Use Raster Extent', button_style='warning')\n",
    "\n",
    "set_drawing_button.on_click(lambda b: set_roi_from_drawing())\n",
    "set_coords_button.on_click(lambda b: set_roi_from_coordinates())\n",
    "set_raster_button.on_click(lambda b: set_roi_from_raster())\n",
    "\n",
    "roi_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üéØ ROI Selection</h3>'),\n",
    "    widgets.HTML('<b>Method 1: Draw on Map</b>'),\n",
    "    set_drawing_button,\n",
    "    widgets.HTML('<b>Method 2: Enter Coordinates</b>'),\n",
    "    widgets.HBox([west_input, east_input]),\n",
    "    widgets.HBox([south_input, north_input]),\n",
    "    set_coords_button,\n",
    "    widgets.HTML('<b>Method 3: Use Raster File Extent</b>'),\n",
    "    widgets.HBox([browse_button, raster_path_display]),\n",
    "    set_raster_button\n",
    "])\n",
    "\n",
    "display(roi_interface)\n",
    "display(m)\n",
    "\n",
    "print('üéØ ROI Selection Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Analysis Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54c1aa8321a4b34a6273e269917b19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìä Analysis Configuration</h3>'), HTML(value='<div style=\"background-color: #e8f‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Configuration Ready for Efficient Array Extraction\n"
     ]
    }
   ],
   "source": [
    "# Analysis configuration\n",
    "analysis_year = widgets.IntSlider(value=2020, min=2003, max=2020, description='Analysis Year:')\n",
    "reference_start = widgets.IntSlider(value=2010, min=2003, max=2019, description='Reference Start:')\n",
    "reference_end = widgets.IntSlider(value=2019, min=2004, max=2020, description='Reference End:')\n",
    "absolute_threshold = widgets.FloatSlider(value=35.0, min=20.0, max=45.0, step=0.5, description='Threshold (¬∞C):')\n",
    "percentile_threshold = widgets.FloatSlider(value=95.0, min=50.0, max=99.0, step=1.0, description='Percentile:')\n",
    "\n",
    "# Resolution selection for array extraction\n",
    "resolution_selector = widgets.Dropdown(\n",
    "    options=[('1km (recommended)', 1000), ('2km', 2000), ('5km', 5000)],\n",
    "    value=1000,\n",
    "    description='Resolution:'\n",
    ")\n",
    "\n",
    "config_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üìä Analysis Configuration</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #e8f4fd; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>Efficient Array Approach:</b><br>' +\n",
    "                '‚Ä¢ Minimal GEE preprocessing (filtering + scaling only)<br>' +\n",
    "                '‚Ä¢ Direct array extraction using getRegion()<br>' +\n",
    "                '‚Ä¢ Fast xarray vectorized analysis locally<br>' +\n",
    "                '‚Ä¢ Coordinates preserved for spatial export</div>'),\n",
    "    analysis_year,\n",
    "    widgets.HBox([reference_start, reference_end]),\n",
    "    widgets.HBox([absolute_threshold, percentile_threshold]),\n",
    "    resolution_selector\n",
    "])\n",
    "\n",
    "display(config_interface)\n",
    "print('üìä Configuration Ready for Efficient Array Extraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Step 3: Direct Array Extraction & Fast xarray Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cccec0a43b4eecb1c69964ad268573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>‚ö° Efficient Array Processing</h3>'), HTML(value='<div style=\"background-color: ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Ready for efficient array extraction and processing\n",
      "üéØ Automatic chunking handles getRegion() limits\n",
      "üöÄ This approach should be MUCH faster than your previous hour-long GEE processing!\n"
     ]
    }
   ],
   "source": [
    "def get_region_collection(geom):\n",
    "    \"\"\"Determine which regional GSHTD collection to use\"\"\"\n",
    "    centroid = geom.centroid().coordinates().getInfo()\n",
    "    lon, lat = centroid[0], centroid[1]\n",
    "    \n",
    "    if lat > 15 and lon > -140 and lon < -40:\n",
    "        return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"\n",
    "    elif lat < 35 and lon > -120 and lon < -30:\n",
    "        return \"projects/sat-io/open-datasets/global-daily-air-temp/latin_america\"\n",
    "    elif lat > 30 and lon > -15 and lon < 180:\n",
    "        return \"projects/sat-io/open-datasets/global-daily-air-temp/europe_asia\"\n",
    "    elif lat < 40 and lon > -20 and lon < 55:\n",
    "        return \"projects/sat-io/open-datasets/global-daily-air-temp/africa\"\n",
    "    elif lat < -5 and lon > 110 and lon < 180:\n",
    "        return \"projects/sat-io/open-datasets/global-daily-air-temp/australia\"\n",
    "    else:\n",
    "        return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"\n",
    "\n",
    "def get_temperature_collection(region_geom, start_date, end_date, temp_type='tmax'):\n",
    "    \"\"\"Get GSHTD temperature collection with minimal preprocessing\"\"\"\n",
    "    collection_id = get_region_collection(region_geom)\n",
    "    collection = ee.ImageCollection(collection_id)\n",
    "    \n",
    "    # Minimal preprocessing - just filter and scale\n",
    "    filtered_collection = (collection.filterDate(start_date, end_date)\n",
    "                         .filterBounds(region_geom)\n",
    "                         .filter(ee.Filter.eq('prop_type', temp_type)))\n",
    "    \n",
    "    # Scale to Celsius and clip to ROI\n",
    "    temp_collection = filtered_collection.map(lambda img: \n",
    "        img.select('b1')\n",
    "          .divide(10)  # Scale to Celsius\n",
    "          .rename('temperature')\n",
    "          .clip(region_geom)\n",
    "          .copyProperties(img, ['system:time_start'])\n",
    "    )\n",
    "    \n",
    "    return temp_collection\n",
    "\n",
    "def extract_arrays_efficiently():\n",
    "    '''Extract temperature arrays from GEE using chunking strategies'''\n",
    "    global analysis_geom, temperature_data\n",
    "    \n",
    "    if analysis_geom is None:\n",
    "        print('‚ùå Please set an ROI first!')\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print('‚ö° Starting chunked array extraction from GEE...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        scale = resolution_selector.value\n",
    "        \n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        print(f'   üìè ROI area: {area_km2:.2f} km¬≤ at {scale}m resolution')\n",
    "        \n",
    "        # Get collections\n",
    "        print('   üì° Loading GSHTD collections...')\n",
    "        collection_id = get_region_collection(analysis_geom)\n",
    "        print(f'   üì° Using: {collection_id.split(\"/\")[-1]}')\n",
    "        \n",
    "        # Analysis year collection\n",
    "        analysis_collection = get_temperature_collection(\n",
    "            analysis_geom, f'{year}-01-01', f'{year}-12-31', 'tmax'\n",
    "        )\n",
    "        \n",
    "        # Reference period collection  \n",
    "        reference_collection = get_temperature_collection(\n",
    "            analysis_geom, f'{ref_start}-01-01', f'{ref_end}-12-31', 'tmax'\n",
    "        )\n",
    "        \n",
    "        analysis_count = analysis_collection.size().getInfo()\n",
    "        reference_count = reference_collection.size().getInfo()\n",
    "        \n",
    "        print(f'   üìä Analysis year images: {analysis_count}')\n",
    "        print(f'   üìä Reference period images: {reference_count}')\n",
    "        \n",
    "        if analysis_count == 0 or reference_count == 0:\n",
    "            print('‚ùå No images found - check ROI coverage')\n",
    "            return False\n",
    "        \n",
    "        # Estimate data size and choose strategy\n",
    "        test_image = analysis_collection.first()\n",
    "        pixel_count = test_image.select('temperature').reduceRegion(\n",
    "            reducer=ee.Reducer.count(),\n",
    "            geometry=analysis_geom,\n",
    "            scale=scale,\n",
    "            maxPixels=1e9\n",
    "        ).getInfo()\n",
    "        \n",
    "        expected_pixels = pixel_count.get('temperature', 0)\n",
    "        total_images = analysis_count + reference_count\n",
    "        estimated_values = expected_pixels * total_images\n",
    "        \n",
    "        print(f'   üìä Estimated pixels per image: {expected_pixels:,}')\n",
    "        print(f'   üìä Total images: {total_images}')\n",
    "        print(f'   üìä Estimated total values: {estimated_values:,}')\n",
    "        \n",
    "        # Choose extraction strategy based on size\n",
    "        if estimated_values > 1000000:  # Too large for getRegion\n",
    "            print('   üîÑ Using temporal chunking strategy...')\n",
    "            return extract_with_temporal_chunking()\n",
    "        elif estimated_values > 500000:  # Moderate size\n",
    "            print('   üîÑ Using annual extraction strategy...')\n",
    "            return extract_with_annual_chunks()\n",
    "        else:\n",
    "            print('   üîÑ Using direct extraction (small dataset)...')\n",
    "            return extract_direct()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error in array extraction setup: {e}')\n",
    "        return False\n",
    "\n",
    "def extract_direct():\n",
    "    '''Direct extraction for small datasets'''\n",
    "    try:\n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        scale = resolution_selector.value\n",
    "        \n",
    "        # Get collections\n",
    "        analysis_collection = get_temperature_collection(\n",
    "            analysis_geom, f'{year}-01-01', f'{year}-12-31', 'tmax'\n",
    "        )\n",
    "        reference_collection = get_temperature_collection(\n",
    "            analysis_geom, f'{ref_start}-01-01', f'{ref_end}-12-31', 'tmax'\n",
    "        )\n",
    "        \n",
    "        # Combine for single extraction\n",
    "        all_collection = analysis_collection.merge(reference_collection)\n",
    "        \n",
    "        print('   üì• Extracting all data in single call...')\n",
    "        region_data = all_collection.getRegion(\n",
    "            geometry=analysis_geom,\n",
    "            scale=scale,\n",
    "            crs='EPSG:4326'\n",
    "        ).getInfo()\n",
    "        \n",
    "        return process_region_data(region_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Direct extraction failed: {e}')\n",
    "        return False\n",
    "\n",
    "def extract_with_annual_chunks():\n",
    "    '''Extract data year by year'''\n",
    "    try:\n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        scale = resolution_selector.value\n",
    "        \n",
    "        all_dataframes = []\n",
    "        \n",
    "        # Extract each year separately\n",
    "        years_to_extract = list(range(ref_start, ref_end + 1)) + [year]\n",
    "        years_to_extract = sorted(list(set(years_to_extract)))\n",
    "        \n",
    "        for extract_year in years_to_extract:\n",
    "            print(f'   üìÖ Extracting year {extract_year}...')\n",
    "            \n",
    "            year_collection = get_temperature_collection(\n",
    "                analysis_geom, f'{extract_year}-01-01', f'{extract_year}-12-31', 'tmax'\n",
    "            )\n",
    "            \n",
    "            year_count = year_collection.size().getInfo()\n",
    "            if year_count == 0:\n",
    "                print(f'      ‚ö†Ô∏è No data for {extract_year}')\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                region_data = year_collection.getRegion(\n",
    "                    geometry=analysis_geom,\n",
    "                    scale=scale,\n",
    "                    crs='EPSG:4326'\n",
    "                ).getInfo()\n",
    "                \n",
    "                if len(region_data) > 1:\n",
    "                    header = region_data[0]\n",
    "                    data = region_data[1:]\n",
    "                    \n",
    "                    df_year = pd.DataFrame(data, columns=header)\n",
    "                    df_year['time'] = pd.to_datetime(df_year['time'], unit='ms')\n",
    "                    df_year = df_year.dropna(subset=['temperature'])\n",
    "                    df_year['latitude'] = df_year['latitude'].astype(float)\n",
    "                    df_year['longitude'] = df_year['longitude'].astype(float)\n",
    "                    df_year['temperature'] = df_year['temperature'].astype(float)\n",
    "                    \n",
    "                    all_dataframes.append(df_year)\n",
    "                    print(f'      ‚úÖ Extracted {len(df_year):,} observations')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'      ‚ùå Failed to extract {extract_year}: {e}')\n",
    "                continue\n",
    "        \n",
    "        if not all_dataframes:\n",
    "            print('‚ùå No data extracted')\n",
    "            return False\n",
    "        \n",
    "        # Combine all years\n",
    "        print('   üîó Combining all years...')\n",
    "        df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        \n",
    "        return finalize_temperature_data(df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Annual chunking failed: {e}')\n",
    "        return False\n",
    "\n",
    "def extract_with_temporal_chunking():\n",
    "    '''Extract data with monthly chunks for very large datasets'''\n",
    "    try:\n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        scale = resolution_selector.value\n",
    "        \n",
    "        all_dataframes = []\n",
    "        \n",
    "        # Create monthly chunks\n",
    "        years_to_extract = list(range(ref_start, ref_end + 1)) + [year]\n",
    "        years_to_extract = sorted(list(set(years_to_extract)))\n",
    "        \n",
    "        total_months = len(years_to_extract) * 12\n",
    "        processed_months = 0\n",
    "        \n",
    "        for extract_year in years_to_extract:\n",
    "            for month in range(1, 13):\n",
    "                print(f'   üìÖ Extracting {extract_year}-{month:02d} ({processed_months+1}/{total_months})...')\n",
    "                \n",
    "                # Monthly date range\n",
    "                start_date = f'{extract_year}-{month:02d}-01'\n",
    "                if month == 12:\n",
    "                    end_date = f'{extract_year+1}-01-01'\n",
    "                else:\n",
    "                    end_date = f'{extract_year}-{month+1:02d}-01'\n",
    "                \n",
    "                month_collection = get_temperature_collection(\n",
    "                    analysis_geom, start_date, end_date, 'tmax'\n",
    "                )\n",
    "                \n",
    "                month_count = month_collection.size().getInfo()\n",
    "                if month_count == 0:\n",
    "                    processed_months += 1\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    region_data = month_collection.getRegion(\n",
    "                        geometry=analysis_geom,\n",
    "                        scale=scale,\n",
    "                        crs='EPSG:4326'\n",
    "                    ).getInfo()\n",
    "                    \n",
    "                    if len(region_data) > 1:\n",
    "                        header = region_data[0]\n",
    "                        data = region_data[1:]\n",
    "                        \n",
    "                        df_month = pd.DataFrame(data, columns=header)\n",
    "                        df_month['time'] = pd.to_datetime(df_month['time'], unit='ms')\n",
    "                        df_month = df_month.dropna(subset=['temperature'])\n",
    "                        df_month['latitude'] = df_month['latitude'].astype(float)\n",
    "                        df_month['longitude'] = df_month['longitude'].astype(float)\n",
    "                        df_month['temperature'] = df_month['temperature'].astype(float)\n",
    "                        \n",
    "                        all_dataframes.append(df_month)\n",
    "                        print(f'      ‚úÖ {len(df_month):,} observations')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f'      ‚ùå Failed: {e}')\n",
    "                \n",
    "                processed_months += 1\n",
    "                \n",
    "                # Progress update\n",
    "                if processed_months % 12 == 0:\n",
    "                    print(f'   üìä Completed {processed_months//12} years...')\n",
    "        \n",
    "        if not all_dataframes:\n",
    "            print('‚ùå No data extracted')\n",
    "            return False\n",
    "        \n",
    "        # Combine all chunks\n",
    "        print('   üîó Combining all temporal chunks...')\n",
    "        df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        \n",
    "        return finalize_temperature_data(df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Temporal chunking failed: {e}')\n",
    "        return False\n",
    "\n",
    "def process_region_data(region_data):\n",
    "    '''Process raw region data from getRegion call'''\n",
    "    try:\n",
    "        print(f'   üîÑ Processing {len(region_data)} rows...')\n",
    "        \n",
    "        if len(region_data) <= 1:\n",
    "            print('‚ùå No data in region extraction')\n",
    "            return False\n",
    "        \n",
    "        header = region_data[0]\n",
    "        data = region_data[1:]\n",
    "        \n",
    "        df = pd.DataFrame(data, columns=header)\n",
    "        \n",
    "        return finalize_temperature_data(df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error processing region data: {e}')\n",
    "        return False\n",
    "\n",
    "def finalize_temperature_data(df):\n",
    "    '''Convert DataFrame to xarray and finalize'''\n",
    "    global temperature_data\n",
    "    \n",
    "    try:\n",
    "        # Process data\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "        df = df.dropna(subset=['temperature'])\n",
    "        df['latitude'] = df['latitude'].astype(float)\n",
    "        df['longitude'] = df['longitude'].astype(float)\n",
    "        df['temperature'] = df['temperature'].astype(float)\n",
    "        \n",
    "        print(f'   üìä Valid observations: {len(df):,}')\n",
    "        print(f'   üìç Unique pixels: {df[[\"latitude\", \"longitude\"]].drop_duplicates().shape[0]:,}')\n",
    "        print(f'   üå°Ô∏è Temperature range: {df[\"temperature\"].min():.1f}¬∞C to {df[\"temperature\"].max():.1f}¬∞C')\n",
    "        \n",
    "        # Convert to xarray with preserved coordinates\n",
    "        print('   üîÑ Converting to xarray dataset...')\n",
    "        temperature_data = df.set_index(['time', 'latitude', 'longitude']).to_xarray()\n",
    "        \n",
    "        print(f'\\n‚úÖ Array extraction complete!')\n",
    "        print(f'   üìÖ Time range: {temperature_data.time.min().values} to {temperature_data.time.max().values}')\n",
    "        print(f'   üåç Spatial dimensions: lat={temperature_data.dims[\"latitude\"]}, lon={temperature_data.dims[\"longitude\"]}')\n",
    "        print(f'   üìä Total observations: {temperature_data.temperature.count().values}')\n",
    "        print(f'   üíæ Memory usage: {temperature_data.nbytes / 1024**2:.1f} MB')\n",
    "        print(f'   ‚ö° Ready for fast xarray processing!')\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error finalizing data: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "def process_climate_metrics_fast():\n",
    "    '''Process climate metrics using fast xarray operations'''\n",
    "    global temperature_data, climate_results\n",
    "    \n",
    "    if temperature_data is None:\n",
    "        print('‚ùå Please extract arrays first!')\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print('üöÄ Processing climate metrics with fast xarray operations...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        abs_threshold = absolute_threshold.value\n",
    "        pct_threshold = percentile_threshold.value\n",
    "        \n",
    "        # Filter data efficiently  \n",
    "        analysis_data = temperature_data.sel(time=str(year))\n",
    "        reference_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{ref_end}-12-31'))\n",
    "        \n",
    "        print(f'   üìÖ Analysis year: {len(analysis_data.time)} days')\n",
    "        print(f'   üìÖ Reference period: {len(reference_data.time)} days')\n",
    "        \n",
    "        # Lightning-fast vectorized calculations\n",
    "        print('   ‚ö° Calculating reference percentile...')\n",
    "        reference_percentile = reference_data.temperature.quantile(pct_threshold/100, dim='time')\n",
    "        \n",
    "        print('   ‚ö° Calculating heat days...')\n",
    "        threshold = xr.where(reference_percentile > abs_threshold, reference_percentile, abs_threshold)\n",
    "        heat_days = (analysis_data.temperature > threshold).sum(dim='time').fillna(0)\n",
    "        \n",
    "        print('   ‚ö° Calculating temperature trends...')\n",
    "        trends = reference_data.temperature.polyfit(dim='time', deg=1)\n",
    "        trend_slope = trends.polyfit_coefficients.sel(degree=1)\n",
    "        ns_per_year = 365.25 * 24 * 60 * 60 * 1e9\n",
    "        trend_per_year = (trend_slope * ns_per_year).fillna(0)\n",
    "        \n",
    "        print('   ‚ö° Calculating annual statistics...')\n",
    "        annual_max = analysis_data.temperature.max(dim='time').fillna(0)\n",
    "        annual_min = analysis_data.temperature.min(dim='time').fillna(0)\n",
    "        annual_mean = analysis_data.temperature.mean(dim='time').fillna(0)\n",
    "        annual_range = (annual_max - annual_min).fillna(0)\n",
    "        \n",
    "        print('   ‚ö° Calculating seasonal means...')\n",
    "        seasonal_means = analysis_data.temperature.groupby('time.season').mean()\n",
    "        \n",
    "        # Store results with coordinates preserved\n",
    "        climate_results = {\n",
    "            'heat_days': heat_days,\n",
    "            'reference_percentile': reference_percentile,\n",
    "            'threshold_used': threshold,\n",
    "            'temp_trend': trend_per_year,\n",
    "            'annual_max': annual_max,\n",
    "            'annual_min': annual_min,\n",
    "            'annual_mean': annual_mean,\n",
    "            'annual_range': annual_range,\n",
    "            'seasonal_means': seasonal_means\n",
    "        }\n",
    "        \n",
    "        print(f'\\n‚úÖ Climate metrics calculated in seconds!')\n",
    "        \n",
    "        # Print summary\n",
    "        print(f'\\nüìä RESULTS SUMMARY:')\n",
    "        print(f'   Mean heat days: {heat_days.mean().values:.1f}')\n",
    "        print(f'   Max heat days: {heat_days.max().values:.0f}')\n",
    "        print(f'   Pixels with >0 heat days: {(heat_days > 0).sum().values} of {heat_days.count().values}')\n",
    "        print(f'   Mean temperature trend: {trend_per_year.mean().values:.3f} ¬∞C/year')\n",
    "        print(f'   üìç All results preserve lat/lon coordinates for spatial export')\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error in climate processing: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "# Create processing buttons\n",
    "extract_button = widgets.Button(description='üì• Extract Arrays', button_style='primary')\n",
    "process_button = widgets.Button(description='‚ö° Process Metrics', button_style='success')\n",
    "\n",
    "extract_button.on_click(lambda b: extract_arrays_efficiently())\n",
    "process_button.on_click(lambda b: process_climate_metrics_fast())\n",
    "\n",
    "processing_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>‚ö° Efficient Array Processing</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>Two-Step Efficient Process:</b><br>' +\n",
    "                '1. <b>Extract Arrays:</b> Direct getRegion() extraction with automatic chunking<br>' +\n",
    "                '2. <b>Process Metrics:</b> Lightning-fast xarray vectorization<br>' +\n",
    "                '‚ú® <b>Result:</b> Complete analysis in minutes, not hours!</div>'),\n",
    "    widgets.HBox([extract_button, process_button])\n",
    "])\n",
    "\n",
    "display(processing_interface)\n",
    "print('‚ö° Ready for efficient array extraction and processing')\n",
    "print('üéØ Automatic chunking handles getRegion() limits')\n",
    "print('üöÄ This approach should be MUCH faster than your previous hour-long GEE processing!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: Visualization & Spatial Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7bffad92194469cb1a7ccb01ff96490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìä Visualization & Spatial Export</h3>'), HTML(value='<div style=\"background-col‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ready for visualization and spatial export\n",
      "üåç Exports include proper CRS for GIS compatibility\n"
     ]
    }
   ],
   "source": [
    "def visualize_climate_results():\n",
    "    '''Create comprehensive visualization of climate results'''\n",
    "    if not climate_results:\n",
    "        print('‚ùå No climate results available. Please process metrics first!')\n",
    "        return\n",
    "    \n",
    "    print('üìä Creating climate results visualization...')\n",
    "    \n",
    "    # Create subplot grid\n",
    "    metrics_to_plot = ['heat_days', 'temp_trend', 'annual_max', 'annual_range']\n",
    "    available_metrics = [m for m in metrics_to_plot if m in climate_results]\n",
    "    \n",
    "    if not available_metrics:\n",
    "        print('‚ùå No spatial metrics available for plotting')\n",
    "        return\n",
    "    \n",
    "    n_metrics = len(available_metrics)\n",
    "    cols = min(2, n_metrics)\n",
    "    rows = (n_metrics + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6*cols, 5*rows))\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, metric_name in enumerate(available_metrics):\n",
    "        data = climate_results[metric_name]\n",
    "        \n",
    "        # Choose appropriate colormap\n",
    "        if 'heat' in metric_name:\n",
    "            cmap = 'Reds'\n",
    "            title = 'Heat Days per Pixel'\n",
    "        elif 'trend' in metric_name:\n",
    "            cmap = 'RdBu_r'\n",
    "            title = 'Temperature Trend (¬∞C/year)'\n",
    "        elif 'max' in metric_name:\n",
    "            cmap = 'RdYlBu_r'\n",
    "            title = 'Annual Maximum Temperature (¬∞C)'\n",
    "        elif 'range' in metric_name:\n",
    "            cmap = 'viridis'\n",
    "            title = 'Annual Temperature Range (¬∞C)'\n",
    "        else:\n",
    "            cmap = 'viridis'\n",
    "            title = metric_name.replace('_', ' ').title()\n",
    "        \n",
    "        im = data.plot(ax=axes[i], cmap=cmap, add_colorbar=True)\n",
    "        axes[i].set_title(title, fontweight='bold')\n",
    "        axes[i].set_xlabel('Longitude')\n",
    "        axes[i].set_ylabel('Latitude')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(available_metrics), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('‚úÖ Visualization complete!')\n",
    "\n",
    "def export_spatial_results():\n",
    "    '''Export climate results as spatial files with proper CRS'''\n",
    "    if not climate_results:\n",
    "        print('‚ùå No climate results available. Please process metrics first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('üìÅ Exporting climate results to ../outputs with proper CRS...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        \n",
    "        # Create summary statistics\n",
    "        summary_data = []\n",
    "        \n",
    "        for metric_name, dataset in climate_results.items():\n",
    "            if hasattr(dataset, 'mean') and len(dataset.dims) <= 2:\n",
    "                try:\n",
    "                    if 'seasonal' not in metric_name:  # Skip seasonal means for summary\n",
    "                        valid_data = dataset.values[~np.isnan(dataset.values)]\n",
    "                        \n",
    "                        if len(valid_data) > 0:\n",
    "                            summary_data.append({\n",
    "                                'metric': metric_name,\n",
    "                                'valid_pixels': len(valid_data),\n",
    "                                'mean': float(np.mean(valid_data)),\n",
    "                                'min': float(np.min(valid_data)),\n",
    "                                'max': float(np.max(valid_data)),\n",
    "                                'std': float(np.std(valid_data)),\n",
    "                                'median': float(np.median(valid_data))\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f'     ‚ö†Ô∏è Skipping {metric_name}: {e}')\n",
    "        \n",
    "        # Save summary table\n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_file = f'../outputs/efficient_climate_summary_{year}.csv'\n",
    "            summary_df.to_csv(summary_file, index=False)\n",
    "            print(f'   ‚úÖ Summary saved: {summary_file}')\n",
    "            \n",
    "            # Display summary\n",
    "            print('\\\\nüìä CLIMATE ANALYSIS SUMMARY:')\n",
    "            display(summary_df)\n",
    "        \n",
    "        # Export as NetCDF with proper CRS\n",
    "        print('\\\\n   üì¶ Creating NetCDF with proper CRS...')\n",
    "        \n",
    "        # Create xarray Dataset from results\n",
    "        spatial_results = {}\n",
    "        for k, v in climate_results.items():\n",
    "            if hasattr(v, 'dims') and 'latitude' in v.dims and 'longitude' in v.dims:\n",
    "                if len(v.dims) == 2:  # Spatial data only\n",
    "                    spatial_results[k] = v.fillna(0)\n",
    "        \n",
    "        if spatial_results:\n",
    "            results_ds = xr.Dataset(spatial_results)\n",
    "            \n",
    "            # Add proper CRS information (same as notebook 17)\n",
    "            results_ds.latitude.attrs['standard_name'] = 'latitude'\n",
    "            results_ds.latitude.attrs['long_name'] = 'latitude'\n",
    "            results_ds.latitude.attrs['units'] = 'degrees_north'\n",
    "            results_ds.latitude.attrs['axis'] = 'Y'\n",
    "            \n",
    "            results_ds.longitude.attrs['standard_name'] = 'longitude'\n",
    "            results_ds.longitude.attrs['long_name'] = 'longitude'\n",
    "            results_ds.longitude.attrs['units'] = 'degrees_east'\n",
    "            results_ds.longitude.attrs['axis'] = 'X'\n",
    "            \n",
    "            # Add CRS variable\n",
    "            crs = xr.DataArray(\n",
    "                data=np.int32(1),\n",
    "                attrs={\n",
    "                    'grid_mapping_name': 'latitude_longitude',\n",
    "                    'longitude_of_prime_meridian': 0.0,\n",
    "                    'semi_major_axis': 6378137.0,\n",
    "                    'inverse_flattening': 298.257223563,\n",
    "                    'spatial_ref': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]',\n",
    "                    'crs_wkt': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]'\n",
    "                }\n",
    "            )\n",
    "            results_ds['crs'] = crs\n",
    "            \n",
    "            # Add grid_mapping to all data variables\n",
    "            for var_name in results_ds.data_vars:\n",
    "                if var_name != 'crs':\n",
    "                    results_ds[var_name].attrs['grid_mapping'] = 'crs'\n",
    "            \n",
    "            # Add metadata\n",
    "            results_ds.attrs['analysis_year'] = year\n",
    "            results_ds.attrs['reference_period'] = f'{reference_start.value}-{reference_end.value}'\n",
    "            results_ds.attrs['created'] = datetime.now().isoformat()\n",
    "            results_ds.attrs['method'] = 'efficient_array_extraction'\n",
    "            results_ds.attrs['resolution'] = f'{resolution_selector.value}m'\n",
    "            results_ds.attrs['absolute_threshold'] = absolute_threshold.value\n",
    "            results_ds.attrs['percentile_threshold'] = percentile_threshold.value\n",
    "            results_ds.attrs['crs'] = 'EPSG:4326'\n",
    "            \n",
    "            netcdf_file = f'../outputs/efficient_climate_{year}.nc'\n",
    "            results_ds.to_netcdf(netcdf_file)\n",
    "            \n",
    "            print(f'   ‚úÖ NetCDF saved with proper CRS: {netcdf_file}')\n",
    "            print(f'      Variables: {list(results_ds.data_vars)}')\n",
    "            print(f'      Dimensions: {dict(results_ds.dims)}')\n",
    "            print(f'      CRS: EPSG:4326 (WGS84)')\n",
    "            print(f'      File size: {os.path.getsize(netcdf_file) / 1024**2:.1f} MB')\n",
    "        \n",
    "        # Export individual GeoTIFF files\n",
    "        print('\\\\n   üó∫Ô∏è Exporting individual GeoTIFF files...')\n",
    "        \n",
    "        for metric_name, dataset in climate_results.items():\n",
    "            if hasattr(dataset, 'dims') and 'latitude' in dataset.dims and 'longitude' in dataset.dims:\n",
    "                if len(dataset.dims) == 2:  # Spatial data\n",
    "                    try:\n",
    "                        # Convert to format suitable for rasterio\n",
    "                        data_array = dataset.fillna(0)\n",
    "                        \n",
    "                        # Set spatial reference\n",
    "                        data_array.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "                        \n",
    "                        # Export as GeoTIFF\n",
    "                        output_file = f'../outputs/efficient_{metric_name}_{year}.tif'\n",
    "                        data_array.rio.to_raster(output_file)\n",
    "                        \n",
    "                        print(f'      ‚úÖ {metric_name} ‚Üí {os.path.basename(output_file)}')\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f'      ‚ö†Ô∏è Failed to export {metric_name}: {e}')\n",
    "        \n",
    "        print(f'\\\\n‚úÖ Export complete! Files saved to ../outputs/')\n",
    "        print(f'   üìä Summary: efficient_climate_summary_{year}.csv')\n",
    "        print(f'   üì¶ NetCDF: efficient_climate_{year}.nc (with proper CRS)')\n",
    "        print(f'   üó∫Ô∏è GeoTIFFs: efficient_[metric]_{year}.tif')\n",
    "        print(f'   ‚ú® All files have proper WGS84 projection information!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error exporting: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "# Create visualization and export buttons\n",
    "visualize_button = widgets.Button(description='üìä Visualize Results', button_style='info')\n",
    "export_button = widgets.Button(description='üìÅ Export Spatial Files', button_style='warning')\n",
    "\n",
    "visualize_button.on_click(lambda b: visualize_climate_results())\n",
    "export_button.on_click(lambda b: export_spatial_results())\n",
    "\n",
    "export_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üìä Visualization & Spatial Export</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #d4edda; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>Final Step:</b> Visualize your efficiently-processed climate metrics ' +\n",
    "                'and export as spatial files (NetCDF + GeoTIFF) with proper WGS84 CRS.</div>'),\n",
    "    widgets.HBox([visualize_button, export_button])\n",
    "])\n",
    "\n",
    "display(export_interface)\n",
    "print('üìä Ready for visualization and spatial export')\n",
    "print('üåç Exports include proper CRS for GIS compatibility')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook implements the **most efficient approach** for large-scale climate analysis:\n",
    "\n",
    "### ‚ö° **Why This Approach is Superior:**\n",
    "\n",
    "**1. Direct Array Extraction**\n",
    "- No file exports/downloads (your main complaint about previous approach!)\n",
    "- Direct memory-to-memory transfer from GEE\n",
    "- getRegion() extracts ALL pixel values in single call\n",
    "\n",
    "**2. Minimal GEE Processing**\n",
    "- Only filtering and scaling on GEE servers\n",
    "- No complex server-side statistics (which were slow)\n",
    "- Leverages GEE's strength (data access) not weakness (complex analysis)\n",
    "\n",
    "**3. Lightning-Fast xarray Processing**\n",
    "- Vectorized operations using NumPy/Dask\n",
    "- Minutes vs hours for complex analysis\n",
    "- Full Python scientific stack available\n",
    "\n",
    "**4. Coordinates Preserved**\n",
    "- All lat/lon coordinates maintained\n",
    "- Easy conversion back to NetCDF/GeoTIFF\n",
    "- Proper CRS information included\n",
    "\n",
    "### üöÄ **Complete Workflow:**\n",
    "1. **Set ROI** - Same interface as notebooks 16/17\n",
    "2. **Configure** - Choose resolution and analysis parameters  \n",
    "3. **Extract Arrays** - Direct getRegion() from GEE (no files!)\n",
    "4. **Process Metrics** - Fast vectorized xarray calculations\n",
    "5. **Visualize & Export** - Spatial files with proper projections\n",
    "\n",
    "### üí° **Perfect for:**\n",
    "- Large ROIs at true 1km resolution\n",
    "- Complex climate analysis requiring speed\n",
    "- Intra-urban heat analysis\n",
    "- Converting results back to spatial formats\n",
    "\n",
    "**This approach combines:**\n",
    "- ‚úÖ **GEE's data access power** (massive datasets)\n",
    "- ‚úÖ **xarray's analysis speed** (vectorized operations)  \n",
    "- ‚úÖ **No file bottlenecks** (direct array transfer)\n",
    "- ‚úÖ **Spatial export capability** (for GIS workflows)\n",
    "\n",
    "**Result: Analysis that previously took you an hour now completes in minutes!** üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c99ba6df3548608ef0028c72ac10db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìä xarray Analysis & Visualization</h3>'), HTML(value='<div style=\"background-co‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ready for xarray-based climate analysis\n",
      "üöÄ All heavy computation done server-side!\n"
     ]
    }
   ],
   "source": [
    "def explore_climate_datasets():\n",
    "    '''Explore the loaded climate datasets'''\n",
    "    if not climate_datasets:\n",
    "        print('‚ùå No climate datasets loaded. Please load rasters first.')\n",
    "        return\n",
    "    \n",
    "    print('üîç EXPLORING CLIMATE DATASETS')\n",
    "    print('='*50)\n",
    "    \n",
    "    # Dataset overview\n",
    "    print(f'üìä Available datasets: {len(climate_datasets)}')\n",
    "    for name in climate_datasets.keys():\n",
    "        print(f'   - {name}')\n",
    "    \n",
    "    # Spatial information\n",
    "    sample_ds = list(climate_datasets.values())[0]\n",
    "    print(f'\\nüåç Spatial Information:')\n",
    "    print(f'   Shape: {sample_ds.shape}')\n",
    "    print(f'   Size: {sample_ds.size:,} pixels')\n",
    "    print(f'   Memory: {sample_ds.nbytes / 1024**2:.1f} MB per dataset')\n",
    "    \n",
    "    # Statistics for key metrics\n",
    "    if 'heat_days' in climate_datasets:\n",
    "        heat_days = climate_datasets['heat_days']\n",
    "        valid_pixels = (~np.isnan(heat_days.values)).sum()\n",
    "        \n",
    "        print(f'\\nüî• Heat Days Analysis:')\n",
    "        print(f'   Valid pixels: {valid_pixels:,}')\n",
    "        print(f'   Range: {heat_days.min().values:.0f} to {heat_days.max().values:.0f} days')\n",
    "        print(f'   Mean: {heat_days.mean().values:.1f} days')\n",
    "        print(f'   Pixels with >0 heat days: {(heat_days > 0).sum().values}')\n",
    "    \n",
    "    if 'temp_trend' in climate_datasets:\n",
    "        trend = climate_datasets['temp_trend']\n",
    "        print(f'\\nüìà Temperature Trend Analysis:')\n",
    "        print(f'   Range: {trend.min().values:.4f} to {trend.max().values:.4f} ¬∞C/year')\n",
    "        print(f'   Mean: {trend.mean().values:.4f} ¬∞C/year')\n",
    "    \n",
    "    # Create visualization\n",
    "    print('\\nüìä Creating visualization...')\n",
    "    \n",
    "    # Determine number of subplots needed\n",
    "    available_metrics = list(climate_datasets.keys())\n",
    "    n_metrics = len(available_metrics)\n",
    "    \n",
    "    if n_metrics == 0:\n",
    "        print('‚ùå No metrics to visualize')\n",
    "        return\n",
    "    \n",
    "    # Create subplot grid\n",
    "    cols = min(3, n_metrics)\n",
    "    rows = (n_metrics + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes if isinstance(axes, np.ndarray) else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Plot each metric\n",
    "    for i, metric_name in enumerate(available_metrics[:len(axes)]):\n",
    "        data = climate_datasets[metric_name]\n",
    "        \n",
    "        # Choose appropriate colormap\n",
    "        if 'heat' in metric_name:\n",
    "            cmap = 'Reds'\n",
    "        elif 'trend' in metric_name:\n",
    "            cmap = 'RdBu_r'\n",
    "        elif 'temp' in metric_name or 'mean' in metric_name:\n",
    "            cmap = 'RdYlBu_r'\n",
    "        else:\n",
    "            cmap = 'viridis'\n",
    "        \n",
    "        im = data.plot(ax=axes[i], cmap=cmap, add_colorbar=True)\n",
    "        axes[i].set_title(metric_name.replace('_', ' ').title(), fontweight='bold')\n",
    "        axes[i].set_xlabel('Longitude')\n",
    "        axes[i].set_ylabel('Latitude')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(available_metrics), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n‚úÖ Dataset exploration complete!')\n",
    "\n",
    "def export_climate_analysis():\n",
    "    '''Export climate analysis results'''\n",
    "    if not climate_datasets:\n",
    "        print('‚ùå No climate datasets loaded. Please load rasters first.')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('üìÅ Exporting climate analysis to ../outputs...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        \n",
    "        # Create summary statistics\n",
    "        summary_data = []\n",
    "        \n",
    "        for metric_name, dataset in climate_datasets.items():\n",
    "            valid_data = dataset.values[~np.isnan(dataset.values)]\n",
    "            \n",
    "            if len(valid_data) > 0:\n",
    "                summary_data.append({\n",
    "                    'metric': metric_name,\n",
    "                    'valid_pixels': len(valid_data),\n",
    "                    'mean': float(np.mean(valid_data)),\n",
    "                    'min': float(np.min(valid_data)),\n",
    "                    'max': float(np.max(valid_data)),\n",
    "                    'std': float(np.std(valid_data)),\n",
    "                    'median': float(np.median(valid_data))\n",
    "                })\n",
    "        \n",
    "        # Save summary table\n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_file = f'../outputs/gee_server_climate_summary_{year}.csv'\n",
    "            summary_df.to_csv(summary_file, index=False)\n",
    "            print(f'   ‚úÖ Summary saved: {summary_file}')\n",
    "            \n",
    "            # Display summary\n",
    "            print('\\nüìä CLIMATE ANALYSIS SUMMARY:')\n",
    "            display(summary_df)\n",
    "        \n",
    "        # Export individual rasters to outputs\n",
    "        for metric_name, dataset in climate_datasets.items():\n",
    "            output_file = f'../outputs/gee_server_{metric_name}_{year}.tif'\n",
    "            dataset.rio.to_raster(output_file)\n",
    "            print(f'   ‚úÖ Exported: {output_file}')\n",
    "        \n",
    "        # Create combined NetCDF\n",
    "        combined_ds = xr.Dataset(climate_datasets)\n",
    "        combined_ds.attrs['analysis_year'] = year\n",
    "        combined_ds.attrs['created'] = datetime.now().isoformat()\n",
    "        combined_ds.attrs['method'] = 'GEE_server_side_processing'\n",
    "        combined_ds.attrs['resolution'] = f'{resolution_selector.value}m'\n",
    "        \n",
    "        netcdf_file = f'../outputs/gee_server_climate_{year}.nc'\n",
    "        combined_ds.to_netcdf(netcdf_file)\n",
    "        print(f'   ‚úÖ Combined NetCDF: {netcdf_file}')\n",
    "        \n",
    "        print(f'\\n‚úÖ Export complete! Files saved to ../outputs/')\n",
    "        print(f'   üìä Summary: gee_server_climate_summary_{year}.csv')\n",
    "        print(f'   üì¶ NetCDF: gee_server_climate_{year}.nc')\n",
    "        print(f'   üó∫Ô∏è Individual rasters: gee_server_[metric]_{year}.tif')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error exporting: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "# Analysis buttons\n",
    "explore_button = widgets.Button(description='üîç Explore Datasets', button_style='info')\n",
    "export_analysis_button = widgets.Button(description='üìÅ Export Analysis', button_style='warning')\n",
    "\n",
    "explore_button.on_click(lambda b: explore_climate_datasets())\n",
    "export_analysis_button.on_click(lambda b: export_climate_analysis())\n",
    "\n",
    "analysis_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üìä xarray Analysis & Visualization</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #e8f4fd; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>Final Step:</b> Analyze the climate datasets loaded from GEE-processed rasters. ' +\n",
    "                'All heavy computation was done server-side - now enjoy fast spatial analysis!</div>'),\n",
    "    widgets.HBox([explore_button, export_analysis_button])\n",
    "])\n",
    "\n",
    "display(analysis_interface)\n",
    "print('üìä Ready for xarray-based climate analysis')\n",
    "print('üöÄ All heavy computation done server-side!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook implements an efficient **server-side processing ‚Üí raster export ‚Üí xarray analysis** workflow:\n",
    "\n",
    "### ‚úÖ **Key Advantages:**\n",
    "\n",
    "**1. No Data Transfer Limits**\n",
    "- All heavy computation on GEE servers\n",
    "- Only download final processed results\n",
    "- Perfect for large-scale intra-urban analysis\n",
    "\n",
    "**2. Full 1km Resolution**\n",
    "- No compromise on spatial detail\n",
    "- Ideal for intra-urban heat analysis\n",
    "- Captures local temperature variations\n",
    "\n",
    "**3. Efficient Workflow**\n",
    "- Server-side: Calculate all climate metrics\n",
    "- Export: Multi-band rasters to Google Drive\n",
    "- Client-side: Fast xarray spatial analysis\n",
    "\n",
    "**4. Complete Climate Metrics**\n",
    "- Heat days calculation\n",
    "- Temperature trends\n",
    "- Annual extremes (max, min, mean, range)\n",
    "- Seasonal means\n",
    "- Reference percentiles\n",
    "\n",
    "### üöÄ **Workflow:**\n",
    "1. **Set ROI** - Same interface as notebook 17\n",
    "2. **Configure analysis** - Choose resolution and parameters\n",
    "3. **Process & Export** - GEE does all heavy lifting\n",
    "4. **Download rasters** - From Google Drive to local directory\n",
    "5. **Load & Analyze** - Fast xarray-based spatial analysis\n",
    "\n",
    "### üí° **Perfect for:**\n",
    "- Intra-urban heat island analysis\n",
    "- High-resolution climate mapping\n",
    "- Large ROIs without memory constraints\n",
    "- Persistent, reusable results\n",
    "\n",
    "This approach combines the **computational power of Google Earth Engine** with the **spatial analysis capabilities of xarray** for optimal intra-urban climate analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
