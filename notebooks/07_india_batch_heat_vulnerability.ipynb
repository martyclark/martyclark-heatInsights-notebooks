{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# India-Wide Heat Vulnerability Analysis\n",
    "\n",
    "Batch processing of all Indian cities using Google Earth Engine map-reduce to calculate heat vulnerability ratios and demographic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GEE initialized for India-wide processing\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Initialize GEE\n",
    "ee.Initialize(project='tl-cities')\n",
    "print('‚úÖ GEE initialized for India-wide processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cities globally: 11422\n",
      "WorldPop 2020 bands: 37\n",
      "‚úÖ Datasets loaded\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "allCities = ee.FeatureCollection('projects/tl-cities/assets/GHS_UCDB_THEME_HAZARD_RISK_GLOBE_R2024A')\n",
    "worldpopCollection = ee.ImageCollection('WorldPop/GP/100m/pop_age_sex')\n",
    "\n",
    "# Get WorldPop data for 2020 (confirmed available year)\n",
    "worldpop_2020 = worldpopCollection.filter(ee.Filter.eq('year', 2020)).mosaic()\n",
    "\n",
    "print(f\"Total cities globally: {allCities.size().getInfo()}\")\n",
    "print(f\"WorldPop 2020 bands: {len(worldpop_2020.bandNames().getInfo())}\")\n",
    "print('‚úÖ Datasets loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indian Cities Filtering and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üáÆüá≥ Filtering Indian cities...\n",
      "‚úÖ Found 300 Indian cities\n",
      "   Minimum population: 100,000\n",
      "   Maximum cities: 300\n",
      "\n",
      "üìä Top 15 cities by population:\n",
      "   1. New Delhi                 - Pop:   31,422,508, Area:   2139.0 km¬≤\n",
      "   2. Kolkata                   - Pop:   23,314,585, Area:   2482.0 km¬≤\n",
      "   3. Mumbai                    - Pop:   20,453,270, Area:    738.0 km¬≤\n",
      "   4. Bengaluru                 - Pop:   15,178,533, Area:   1008.0 km¬≤\n",
      "   5. Chennai                   - Pop:   11,466,400, Area:   1052.0 km¬≤\n",
      "   6. Hajipur                   - Pop:    9,755,303, Area:   3166.0 km¬≤\n",
      "   7. Hyderabad                 - Pop:    9,455,230, Area:    889.0 km¬≤\n",
      "   8. Ahmedabad                 - Pop:    7,898,650, Area:    365.0 km¬≤\n",
      "   9. Kozhikode                 - Pop:    7,612,130, Area:   1341.0 km¬≤\n",
      "  10. Surat                     - Pop:    7,100,723, Area:    296.0 km¬≤\n",
      "  11. Pune                      - Pop:    6,674,000, Area:    580.0 km¬≤\n",
      "  12. Lucknow                   - Pop:    5,214,964, Area:    513.0 km¬≤\n",
      "  13. Kochi                     - Pop:    5,069,022, Area:   1266.0 km¬≤\n",
      "  14. Kanpur                    - Pop:    4,413,625, Area:    309.0 km¬≤\n",
      "  15. Jaipur                    - Pop:    4,229,050, Area:    458.0 km¬≤\n",
      "\n",
      "üéØ Ready to process 300 Indian cities\n",
      "\n",
      "üìù Note: India has many more cities than Brazil, so we use higher thresholds:\n",
      "   ‚Ä¢ Minimum population: 100,000 (vs 50,000 for Brazil)\n",
      "   ‚Ä¢ Maximum cities: 300 (vs 200 for Brazil)\n",
      "   ‚Ä¢ This captures major urban centers across all Indian states\n"
     ]
    }
   ],
   "source": [
    "def get_filtered_indian_cities(min_population=100000, max_cities=300):\n",
    "    \"\"\"Get filtered Indian cities for batch processing\"\"\"\n",
    "    print(f'üáÆüá≥ Filtering Indian cities...')\n",
    "    \n",
    "    # Filter Indian cities with population threshold\n",
    "    indian_cities = (allCities\n",
    "        .filter(ee.Filter.eq('GC_CNT_GAD', 'India'))\n",
    "        .filter(ee.Filter.gt('GC_POP_TOT', min_population))\n",
    "        .sort('GC_POP_TOT', False)  # Largest cities first\n",
    "        .limit(max_cities)\n",
    "    )\n",
    "    \n",
    "    # Get basic statistics\n",
    "    total_count = indian_cities.size().getInfo()\n",
    "    \n",
    "    print(f'‚úÖ Found {total_count} Indian cities')\n",
    "    print(f'   Minimum population: {min_population:,}')\n",
    "    print(f'   Maximum cities: {max_cities}')\n",
    "    \n",
    "    # Show sample of top cities\n",
    "    sample = indian_cities.limit(15).getInfo()\n",
    "    print(f'\\nüìä Top 15 cities by population:')\n",
    "    for i, city in enumerate(sample['features']):\n",
    "        props = city['properties']\n",
    "        name = props.get('GC_UCN_MAI', 'Unknown')\n",
    "        pop = props.get('GC_POP_TOT', 0)\n",
    "        area = props.get('GC_UCA_KM2', 0)\n",
    "        print(f'  {i+1:2d}. {name:25s} - Pop: {pop:>12,.0f}, Area: {area:>8.1f} km¬≤')\n",
    "    \n",
    "    return indian_cities\n",
    "\n",
    "# Test the filtering\n",
    "indian_cities = get_filtered_indian_cities()\n",
    "print(f'\\nüéØ Ready to process {indian_cities.size().getInfo()} Indian cities')\n",
    "print('\\nüìù Note: India has many more cities than Brazil, so we use higher thresholds:')\n",
    "print('   ‚Ä¢ Minimum population: 100,000 (vs 50,000 for Brazil)')\n",
    "print('   ‚Ä¢ Maximum cities: 300 (vs 200 for Brazil)')\n",
    "print('   ‚Ä¢ This captures major urban centers across all Indian states')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map-Reduce Functions for Heat Vulnerability (Same as Brazil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Map-reduce function created\n"
     ]
    }
   ],
   "source": [
    "def create_heat_vulnerability_map_function():\n",
    "    \"\"\"Create the map function for processing individual cities\"\"\"\n",
    "    \n",
    "    def map_city_heat_vulnerability(city_feature):\n",
    "        \"\"\"Map function: Calculate heat vulnerability statistics for one city\"\"\"\n",
    "        \n",
    "        # Get city properties and geometry\n",
    "        city_geometry = city_feature.geometry()\n",
    "        \n",
    "        # Define age cohorts using WorldPop bands\n",
    "        age_cohort_bands = {\n",
    "            'age_0_4': ['M_0', 'M_1', 'F_0', 'F_1'],\n",
    "            'age_5_9': ['M_5', 'F_5'],\n",
    "            'age_10_14': ['M_10', 'F_10'],\n",
    "            'age_15_19': ['M_15', 'F_15'],\n",
    "            'age_20_24': ['M_20', 'F_20'],\n",
    "            'age_25_29': ['M_25', 'F_25'],\n",
    "            'age_30_34': ['M_30', 'F_30'],\n",
    "            'age_35_39': ['M_35', 'F_35'],\n",
    "            'age_40_44': ['M_40', 'F_40'],\n",
    "            'age_45_49': ['M_45', 'F_45'],\n",
    "            'age_50_54': ['M_50', 'F_50'],\n",
    "            'age_55_59': ['M_55', 'F_55'],\n",
    "            'age_60_64': ['M_60', 'F_60'],\n",
    "            'age_65_69': ['M_65', 'F_65'],\n",
    "            'age_70_74': ['M_70', 'F_70'],\n",
    "            'age_75_79': ['M_75', 'F_75'],\n",
    "            'age_80_plus': ['M_80', 'F_80'],\n",
    "            'heat_vuln_ratio': ['M_0', 'M_1', 'F_0', 'F_1', 'M_65', 'F_65', 'M_70', 'F_70', 'M_75', 'F_75', 'M_80', 'F_80']\n",
    "        }\n",
    "        \n",
    "        # Create total population image (all bands except duplicates in heat_vuln_ratio)\n",
    "        all_unique_bands = []\n",
    "        for cohort_name, bands in age_cohort_bands.items():\n",
    "            if cohort_name != 'heat_vuln_ratio':\n",
    "                all_unique_bands.extend(bands)\n",
    "        \n",
    "        all_unique_bands = list(dict.fromkeys(all_unique_bands))  # Remove duplicates\n",
    "        total_pop_image = worldpop_2020.select(all_unique_bands).reduce(ee.Reducer.sum())\n",
    "        \n",
    "        # Calculate statistics for each cohort\n",
    "        cohort_stats = {}\n",
    "        \n",
    "        for cohort_name, bands in age_cohort_bands.items():\n",
    "            # Create cohort population image\n",
    "            cohort_image = worldpop_2020.select(bands).reduce(ee.Reducer.sum())\n",
    "            \n",
    "            # Calculate percentage: (cohort / total) * 100\n",
    "            # Add small constant to avoid division by zero\n",
    "            percentage_image = cohort_image.divide(total_pop_image.add(0.001)).multiply(100)\n",
    "            \n",
    "            # Calculate comprehensive statistics within city boundary\n",
    "            stats = percentage_image.reduceRegion(\n",
    "                reducer=(\n",
    "                    ee.Reducer.mean().combine(ee.Reducer.median(), sharedInputs=True)\n",
    "                    .combine(ee.Reducer.stdDev(), sharedInputs=True)\n",
    "                    .combine(ee.Reducer.minMax(), sharedInputs=True)\n",
    "                    .combine(ee.Reducer.percentile([25, 75]), sharedInputs=True)\n",
    "                    .combine(ee.Reducer.count(), sharedInputs=True)\n",
    "                ),\n",
    "                geometry=city_geometry,\n",
    "                scale=90,  # WorldPop native resolution\n",
    "                maxPixels=1e8,\n",
    "                bestEffort=True\n",
    "            )\n",
    "            \n",
    "            # Extract statistics with proper naming\n",
    "            cohort_stats[f'{cohort_name}_mean'] = stats.get('sum_mean')\n",
    "            cohort_stats[f'{cohort_name}_median'] = stats.get('sum_median')\n",
    "            cohort_stats[f'{cohort_name}_std'] = stats.get('sum_stdDev')\n",
    "            cohort_stats[f'{cohort_name}_min'] = stats.get('sum_min')\n",
    "            cohort_stats[f'{cohort_name}_max'] = stats.get('sum_max')\n",
    "            cohort_stats[f'{cohort_name}_q25'] = stats.get('sum_p25')\n",
    "            cohort_stats[f'{cohort_name}_q75'] = stats.get('sum_p75')\n",
    "            cohort_stats[f'{cohort_name}_count'] = stats.get('sum_count')\n",
    "        \n",
    "        # Also calculate total population for the city\n",
    "        total_pop_stats = total_pop_image.reduceRegion(\n",
    "            reducer=ee.Reducer.sum(),\n",
    "            geometry=city_geometry,\n",
    "            scale=90,\n",
    "            maxPixels=1e8,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        \n",
    "        cohort_stats['total_worldpop_population'] = total_pop_stats.get('sum')\n",
    "        \n",
    "        # Return city feature with computed statistics as properties\n",
    "        return city_feature.set(cohort_stats)\n",
    "    \n",
    "    return map_city_heat_vulnerability\n",
    "\n",
    "print('‚úÖ Map-reduce function created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing Implementation for India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Batch processing functions ready (optimized for Indian cities)\n"
     ]
    }
   ],
   "source": [
    "def process_cities_batch(cities_collection, batch_size=8):\n",
    "    \"\"\"Process a batch of cities and return results as pandas DataFrame\"\"\"\n",
    "    \n",
    "    print(f'üîÑ Processing batch of {batch_size} cities...')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Create the map function\n",
    "        map_function = create_heat_vulnerability_map_function()\n",
    "        \n",
    "        # Apply map function to all cities in batch\n",
    "        cities_with_stats = cities_collection.map(map_function)\n",
    "        \n",
    "        # Get the results\n",
    "        print('   üìä Computing statistics...')\n",
    "        results = cities_with_stats.getInfo()\n",
    "        \n",
    "        # Convert to pandas DataFrame\n",
    "        batch_data = []\n",
    "        \n",
    "        for city in results['features']:\n",
    "            props = city['properties']\n",
    "            \n",
    "            # Extract city basic info\n",
    "            city_info = {\n",
    "                'city_name': props.get('GC_UCN_MAI', 'Unknown'),\n",
    "                'country': props.get('GC_CNT_GAD', 'Unknown'),\n",
    "                'population_estimate': props.get('GC_POP_TOT', 0),\n",
    "                'area_km2': props.get('GC_UCA_KM2', 0),\n",
    "                'total_worldpop_population': props.get('total_worldpop_population', 0)\n",
    "            }\n",
    "            \n",
    "            # Extract all cohort statistics\n",
    "            for key, value in props.items():\n",
    "                if any(key.startswith(prefix) for prefix in [\n",
    "                    'age_0_4_', 'age_5_9_', 'age_10_14_', 'age_15_19_', 'age_20_24_',\n",
    "                    'age_25_29_', 'age_30_34_', 'age_35_39_', 'age_40_44_', 'age_45_49_',\n",
    "                    'age_50_54_', 'age_55_59_', 'age_60_64_', 'age_65_69_', 'age_70_74_',\n",
    "                    'age_75_79_', 'age_80_plus_', 'heat_vuln_ratio_'\n",
    "                ]):\n",
    "                    city_info[key] = value\n",
    "            \n",
    "            batch_data.append(city_info)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(batch_data)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        print(f'   ‚úÖ Batch completed in {processing_time:.1f} seconds')\n",
    "        print(f'   üìä Processed {len(df)} cities successfully')\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'   ‚ùå Batch processing failed: {e}')\n",
    "        return None\n",
    "\n",
    "def process_all_indian_cities_in_batches(batch_size=8, max_batches=None):\n",
    "    \"\"\"Process all Indian cities in manageable batches\"\"\"\n",
    "    \n",
    "    print(f'üöÄ Starting India-wide heat vulnerability analysis')\n",
    "    print(f'   Batch size: {batch_size} cities (smaller for Indian mega-cities)')\n",
    "    print(f'   Max batches: {max_batches or \"All\"}')\n",
    "    print('='*60)\n",
    "    \n",
    "    # Get filtered cities\n",
    "    cities = get_filtered_indian_cities()\n",
    "    total_cities = cities.size().getInfo()\n",
    "    total_batches = (total_cities + batch_size - 1) // batch_size\n",
    "    \n",
    "    if max_batches:\n",
    "        total_batches = min(total_batches, max_batches)\n",
    "    \n",
    "    print(f'\\nüìä Processing plan:')\n",
    "    print(f'   Total cities: {total_cities}')\n",
    "    print(f'   Total batches: {total_batches}')\n",
    "    print(f'   Cities per batch: {batch_size}')\n",
    "    \n",
    "    all_results = []\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for batch_idx in range(total_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        \n",
    "        print(f'\\nüì¶ Batch {batch_idx + 1}/{total_batches} (Cities {start_idx + 1}-{min(start_idx + batch_size, total_cities)})')\n",
    "        \n",
    "        try:\n",
    "            # Get batch of cities\n",
    "            batch_cities_list = cities.toList(batch_size, start_idx)\n",
    "            batch_cities = ee.FeatureCollection(batch_cities_list)\n",
    "            \n",
    "            # Process batch\n",
    "            batch_df = process_cities_batch(batch_cities, batch_size)\n",
    "            \n",
    "            if batch_df is not None and len(batch_df) > 0:\n",
    "                all_results.append(batch_df)\n",
    "                print(f'   ‚úÖ Batch {batch_idx + 1} successful - {len(batch_df)} cities')\n",
    "            else:\n",
    "                print(f'   ‚ùå Batch {batch_idx + 1} failed or returned no data')\n",
    "            \n",
    "            # Add longer delay for India due to larger cities and processing complexity\n",
    "            if batch_idx < total_batches - 1:  # Don't delay after last batch\n",
    "                print('   ‚è≥ Waiting 5 seconds before next batch (longer delay for Indian mega-cities)...')\n",
    "                time.sleep(5)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f'   ‚ùå Batch {batch_idx + 1} error: {e}')\n",
    "            continue\n",
    "    \n",
    "    # Combine all successful batches\n",
    "    if all_results:\n",
    "        final_df = pd.concat(all_results, ignore_index=True)\n",
    "        \n",
    "        # Calculate processing summary\n",
    "        end_time = datetime.now()\n",
    "        total_time = (end_time - start_time).total_seconds()\n",
    "        \n",
    "        print(f'\\nüéâ India-wide processing completed!')\n",
    "        print(f'   Total cities processed: {len(final_df)}')\n",
    "        print(f'   Successful batches: {len(all_results)}/{total_batches}')\n",
    "        print(f'   Total processing time: {total_time:.1f} seconds')\n",
    "        print(f'   Average time per city: {total_time/len(final_df):.1f} seconds')\n",
    "        \n",
    "        return final_df\n",
    "    else:\n",
    "        print('\\n‚ùå No successful batches - processing failed')\n",
    "        return None\n",
    "\n",
    "print('‚úÖ Batch processing functions ready (optimized for Indian cities)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype Test: Process Small Batch of Indian Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ PROTOTYPE TEST: Processing 4 largest Indian cities\n",
      "============================================================\n",
      "üöÄ Starting India-wide heat vulnerability analysis\n",
      "   Batch size: 4 cities (smaller for Indian mega-cities)\n",
      "   Max batches: 1\n",
      "============================================================\n",
      "üáÆüá≥ Filtering Indian cities...\n",
      "‚úÖ Found 300 Indian cities\n",
      "   Minimum population: 100,000\n",
      "   Maximum cities: 300\n",
      "\n",
      "üìä Top 15 cities by population:\n",
      "   1. New Delhi                 - Pop:   31,422,508, Area:   2139.0 km¬≤\n",
      "   2. Kolkata                   - Pop:   23,314,585, Area:   2482.0 km¬≤\n",
      "   3. Mumbai                    - Pop:   20,453,270, Area:    738.0 km¬≤\n",
      "   4. Bengaluru                 - Pop:   15,178,533, Area:   1008.0 km¬≤\n",
      "   5. Chennai                   - Pop:   11,466,400, Area:   1052.0 km¬≤\n",
      "   6. Hajipur                   - Pop:    9,755,303, Area:   3166.0 km¬≤\n",
      "   7. Hyderabad                 - Pop:    9,455,230, Area:    889.0 km¬≤\n",
      "   8. Ahmedabad                 - Pop:    7,898,650, Area:    365.0 km¬≤\n",
      "   9. Kozhikode                 - Pop:    7,612,130, Area:   1341.0 km¬≤\n",
      "  10. Surat                     - Pop:    7,100,723, Area:    296.0 km¬≤\n",
      "  11. Pune                      - Pop:    6,674,000, Area:    580.0 km¬≤\n",
      "  12. Lucknow                   - Pop:    5,214,964, Area:    513.0 km¬≤\n",
      "  13. Kochi                     - Pop:    5,069,022, Area:   1266.0 km¬≤\n",
      "  14. Kanpur                    - Pop:    4,413,625, Area:    309.0 km¬≤\n",
      "  15. Jaipur                    - Pop:    4,229,050, Area:    458.0 km¬≤\n",
      "\n",
      "üìä Processing plan:\n",
      "   Total cities: 300\n",
      "   Total batches: 1\n",
      "   Cities per batch: 4\n",
      "\n",
      "üì¶ Batch 1/1 (Cities 1-4)\n",
      "üîÑ Processing batch of 4 cities...\n",
      "   üìä Computing statistics...\n",
      "   ‚úÖ Batch completed in 31.0 seconds\n",
      "   üìä Processed 4 cities successfully\n",
      "   ‚úÖ Batch 1 successful - 4 cities\n",
      "\n",
      "üéâ India-wide processing completed!\n",
      "   Total cities processed: 4\n",
      "   Successful batches: 1/1\n",
      "   Total processing time: 31.0 seconds\n",
      "   Average time per city: 7.7 seconds\n",
      "\n",
      "üìä PROTOTYPE RESULTS:\n",
      "   Cities processed: 4\n",
      "   Columns: 149\n",
      "\n",
      "üèôÔ∏è Cities processed:\n",
      "   1. New Delhi                 - Pop:   31,422,508, WorldPop:   29,107,023, Heat Vuln:  13.35%\n",
      "   2. Kolkata                   - Pop:   23,314,585, WorldPop:   21,693,351, Heat Vuln:  14.03%\n",
      "   3. Mumbai                    - Pop:   20,453,270, WorldPop:   19,106,064, Heat Vuln:  12.54%\n",
      "   4. Bengaluru                 - Pop:   15,178,533, WorldPop:   12,829,881, Heat Vuln:  12.85%\n",
      "\n",
      "üå°Ô∏è Heat Vulnerability Statistics:\n",
      "   heat_vuln_ratio_count    : min=83910.00%, max=308858.00%, mean=205022.50%\n",
      "   heat_vuln_ratio_max      : min= 14.41%, max= 16.53%, mean= 15.23%\n",
      "   heat_vuln_ratio_mean     : min= 12.54%, max= 14.03%, mean= 13.19%\n",
      "   heat_vuln_ratio_median   : min= 12.55%, max= 13.81%, mean= 13.17%\n",
      "   heat_vuln_ratio_min      : min=  9.21%, max= 13.58%, mean= 11.99%\n",
      "   heat_vuln_ratio_q25      : min= 12.26%, max= 13.78%, mean= 12.81%\n",
      "   heat_vuln_ratio_q75      : min= 12.55%, max= 14.41%, mean= 13.53%\n",
      "   heat_vuln_ratio_std      : min=  0.18%, max=  1.20%, mean=  0.54%\n",
      "\n",
      "‚úÖ Prototype test successful! Ready for full-scale processing.\n",
      "\n",
      "üìù India Processing Notes:\n",
      "   ‚Ä¢ Indian cities tend to be larger and more complex than Brazilian cities\n",
      "   ‚Ä¢ Using smaller batch sizes (4-8) and longer delays (5 seconds)\n",
      "   ‚Ä¢ This ensures reliable processing of mega-cities like Delhi and Mumbai\n"
     ]
    }
   ],
   "source": [
    "# Test with a small batch first\n",
    "print('üß™ PROTOTYPE TEST: Processing 4 largest Indian cities')\n",
    "print('='*60)\n",
    "\n",
    "# Process just 1 batch of 4 cities for testing (smaller due to Indian mega-city sizes)\n",
    "prototype_results = process_all_indian_cities_in_batches(\n",
    "    batch_size=4, \n",
    "    max_batches=1  # Only process 1 batch for testing\n",
    ")\n",
    "\n",
    "if prototype_results is not None:\n",
    "    print(f'\\nüìä PROTOTYPE RESULTS:')\n",
    "    print(f'   Cities processed: {len(prototype_results)}')\n",
    "    print(f'   Columns: {len(prototype_results.columns)}')\n",
    "    \n",
    "    # Show basic info\n",
    "    print(f'\\nüèôÔ∏è Cities processed:')\n",
    "    for idx, row in prototype_results.iterrows():\n",
    "        city_name = row['city_name']\n",
    "        pop_est = row['population_estimate']\n",
    "        worldpop_total = row['total_worldpop_population']\n",
    "        heat_vuln = row.get('heat_vuln_ratio_mean', 'N/A')\n",
    "        \n",
    "        print(f'   {idx+1}. {city_name:25s} - Pop: {pop_est:>12,.0f}, WorldPop: {worldpop_total:>12,.0f}, Heat Vuln: {heat_vuln:>6.2f}%')\n",
    "    \n",
    "    # Show sample of heat vulnerability statistics\n",
    "    heat_vuln_cols = [col for col in prototype_results.columns if 'heat_vuln_ratio_' in col]\n",
    "    if heat_vuln_cols:\n",
    "        print(f'\\nüå°Ô∏è Heat Vulnerability Statistics:')\n",
    "        for col in heat_vuln_cols:\n",
    "            values = prototype_results[col].dropna()\n",
    "            if len(values) > 0:\n",
    "                print(f'   {col:25s}: min={values.min():6.2f}%, max={values.max():6.2f}%, mean={values.mean():6.2f}%')\n",
    "    \n",
    "    print(f'\\n‚úÖ Prototype test successful! Ready for full-scale processing.')\n",
    "    print(f'\\nüìù India Processing Notes:')\n",
    "    print(f'   ‚Ä¢ Indian cities tend to be larger and more complex than Brazilian cities')\n",
    "    print(f'   ‚Ä¢ Using smaller batch sizes (4-8) and longer delays (5 seconds)')\n",
    "    print(f'   ‚Ä¢ This ensures reliable processing of mega-cities like Delhi and Mumbai')\n",
    "else:\n",
    "    print(f'\\n‚ùå Prototype test failed - check configuration and retry.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Scale Processing Interface for India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5606fe62a872482895e818b2587de345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üáÆüá≥ India-Wide Heat Vulnerability Processing</h3>'), HTML(value='\\n    <p><stron‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üáÆüá≥ India-wide processing interface ready!\n",
      "Configure batch settings above and click \"Process Indian Cities\" to start.\n",
      "\n",
      "üìù Recommended settings for different use cases:\n",
      "   ‚Ä¢ Quick test: Batch Size=4, Max Batches=2 (~8 largest cities)\n",
      "   ‚Ä¢ Major cities: Batch Size=8, Max Batches=15 (~120 largest cities)\n",
      "   ‚Ä¢ Comprehensive: Batch Size=8, Max Batches=40 (~320 cities)\n"
     ]
    }
   ],
   "source": [
    "# Create interface for full-scale processing\n",
    "batch_size_slider = widgets.IntSlider(\n",
    "    value=8,\n",
    "    min=4,\n",
    "    max=12,\n",
    "    step=2,\n",
    "    description='Batch Size:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "max_batches_slider = widgets.IntSlider(\n",
    "    value=30,\n",
    "    min=1,\n",
    "    max=75,\n",
    "    step=1,\n",
    "    description='Max Batches:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "process_button = widgets.Button(\n",
    "    description='üáÆüá≥ Process Indian Cities',\n",
    "    button_style='primary',\n",
    "    layout={'width': '250px'}\n",
    ")\n",
    "\n",
    "export_button = widgets.Button(\n",
    "    description='üíæ Export Results to CSV',\n",
    "    button_style='success',\n",
    "    layout={'width': '200px'},\n",
    "    disabled=True\n",
    ")\n",
    "\n",
    "processing_output = widgets.Output()\n",
    "\n",
    "# Global variable to store results\n",
    "india_results = None\n",
    "\n",
    "def on_process_click(button):\n",
    "    global india_results\n",
    "    \n",
    "    with processing_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        batch_size = batch_size_slider.value\n",
    "        max_batches = max_batches_slider.value\n",
    "        \n",
    "        print(f'üöÄ Starting full-scale India processing')\n",
    "        print(f'   Configuration: {batch_size} cities per batch, max {max_batches} batches')\n",
    "        print(f'   Estimated cities: {batch_size * max_batches}')\n",
    "        print(f'   Note: Smaller batches and longer delays due to Indian mega-cities')\n",
    "        \n",
    "        india_results = process_all_indian_cities_in_batches(\n",
    "            batch_size=batch_size,\n",
    "            max_batches=max_batches\n",
    "        )\n",
    "        \n",
    "        if india_results is not None:\n",
    "            print(f'\\nüéâ SUCCESS! Processed {len(india_results)} Indian cities')\n",
    "            \n",
    "            # Show top cities by heat vulnerability\n",
    "            if 'heat_vuln_ratio_mean' in india_results.columns:\n",
    "                top_vulnerable = india_results.nlargest(10, 'heat_vuln_ratio_mean')\n",
    "                print(f'\\nüå°Ô∏è TOP 10 MOST HEAT VULNERABLE CITIES:')\n",
    "                for idx, row in top_vulnerable.iterrows():\n",
    "                    city = row['city_name']\n",
    "                    vuln = row['heat_vuln_ratio_mean']\n",
    "                    pop = row['population_estimate']\n",
    "                    print(f'   {city:25s}: {vuln:5.2f}% heat vulnerable (Pop: {pop:,.0f})')\n",
    "                \n",
    "                # Show top cities by population for context\n",
    "                top_population = india_results.nlargest(10, 'population_estimate')\n",
    "                print(f'\\nüèôÔ∏è TOP 10 LARGEST CITIES (by population):')\n",
    "                for idx, row in top_population.iterrows():\n",
    "                    city = row['city_name']\n",
    "                    pop = row['population_estimate']\n",
    "                    vuln = row.get('heat_vuln_ratio_mean', 0)\n",
    "                    print(f'   {city:25s}: {pop:>12,.0f} people, {vuln:5.2f}% heat vulnerable')\n",
    "            \n",
    "            # Enable export button\n",
    "            export_button.disabled = False\n",
    "            \n",
    "        else:\n",
    "            print(f'\\n‚ùå Processing failed - check logs above for details')\n",
    "\n",
    "def on_export_click(button):\n",
    "    global india_results\n",
    "    \n",
    "    if india_results is not None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = f'/Users/martynclark/heatInsights-notebooks/data/india_heat_vulnerability_{timestamp}.csv'\n",
    "        \n",
    "        india_results.to_csv(filename, index=False)\n",
    "        print(f'‚úÖ Results exported to: {filename}')\n",
    "        print(f'   Cities: {len(india_results)}')\n",
    "        print(f'   Columns: {len(india_results.columns)}')\n",
    "    else:\n",
    "        print('‚ùå No results to export - run processing first')\n",
    "\n",
    "process_button.on_click(on_process_click)\n",
    "export_button.on_click(on_export_click)\n",
    "\n",
    "# Display interface\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML('<h3>üáÆüá≥ India-Wide Heat Vulnerability Processing</h3>'),\n",
    "    widgets.HTML('''\n",
    "    <p><strong>Batch process all major Indian cities to calculate heat vulnerability ratios.</strong></p>\n",
    "    <p><strong>India-Specific Configuration:</strong></p>\n",
    "    <ul>\n",
    "        <li><strong>Batch Size:</strong> 4-12 cities (smaller than Brazil due to mega-cities)</li>\n",
    "        <li><strong>Max Batches:</strong> 1-75 batches (more cities than Brazil)</li>\n",
    "        <li><strong>Processing Delays:</strong> 5 seconds between batches (vs 3 for Brazil)</li>\n",
    "        <li><strong>Population Threshold:</strong> 100,000+ (vs 50,000+ for Brazil)</li>\n",
    "        <li><strong>Expected Cities:</strong> ~300 major Indian urban centers</li>\n",
    "    </ul>\n",
    "    <p><strong>Processing Time:</strong> ~60-120 seconds per batch (Indian cities are larger/more complex)</p>\n",
    "    <p><strong>Major Cities Expected:</strong> Delhi, Mumbai, Bangalore, Hyderabad, Chennai, Kolkata, Ahmedabad, Pune, Surat, Jaipur, and many more</p>\n",
    "    '''),\n",
    "    widgets.HBox([batch_size_slider, max_batches_slider]),\n",
    "    widgets.HBox([process_button, export_button]),\n",
    "    processing_output\n",
    "]))\n",
    "\n",
    "print('\\nüáÆüá≥ India-wide processing interface ready!')\n",
    "print('Configure batch settings above and click \"Process Indian Cities\" to start.')\n",
    "print('\\nüìù Recommended settings for different use cases:')\n",
    "print('   ‚Ä¢ Quick test: Batch Size=4, Max Batches=2 (~8 largest cities)')\n",
    "print('   ‚Ä¢ Major cities: Batch Size=8, Max Batches=15 (~120 largest cities)')\n",
    "print('   ‚Ä¢ Comprehensive: Batch Size=8, Max Batches=40 (~320 cities)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
