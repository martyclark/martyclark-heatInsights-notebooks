{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå°Ô∏è Climate Analysis with xarray - Complete Version\n",
    "\n",
    "This notebook demonstrates the xarray approach to climate analysis with:\n",
    "- File browser for raster upload\n",
    "- Inline plots within notebook cells\n",
    "- Full ROI selection tools (drawing, coordinates, raster upload)\n",
    "- Data exploration before analysis\n",
    "- Export to ../outputs directory\n",
    "\n",
    "## Key Features:\n",
    "- ‚ö° **Fast analysis**: No repeated GEE API calls\n",
    "- üîß **Data exploration**: Examine xarray structure before analysis\n",
    "- üìä **Inline plots**: All visualizations appear in notebook cells\n",
    "- üéØ **File browser**: Easy raster file selection\n",
    "- üìÅ **Full pixel export**: Every individual pixel value preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_7TDKVSyKvBdmMqW?ref=4i2o6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Earth Engine initialized successfully\n",
      "üì¶ Available packages:\n",
      "   - xarray: 2024.7.0\n",
      "   - pandas: 2.3.1\n",
      "   - numpy: 1.26.4\n",
      "üìÅ Created outputs directory: ../outputs\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import ee\n",
    "import geemap\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import rasterio\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Initialize Earth Engine with your project\n",
    "try:\n",
    "    ee.Initialize(project='tl-cities')\n",
    "    print('‚úÖ Earth Engine initialized successfully')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Earth Engine initialization failed: {e}')\n",
    "\n",
    "print('üì¶ Available packages:')\n",
    "print(f'   - xarray: {xr.__version__}')\n",
    "print(f'   - pandas: {pd.__version__}')\n",
    "print(f'   - numpy: {np.__version__}')\n",
    "\n",
    "# Create outputs directory\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "print('üìÅ Created outputs directory: ../outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 1: Enhanced ROI Selection with File Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd00bd04ca5444ef867848f817013c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üéØ ROI Selection - Enhanced with File Browser</h3>'), HTML(value='<b>Method 1: D‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fa234c5e754f42b2c2c9f2c9d4f55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-12.9714, -38.5014], controls=(WidgetControl(options=['position', 'transparent_bg'], position='top‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Enhanced ROI Selection Ready with File Browser\n",
      "üîß Improved CRS handling and coordinate validation\n",
      "Choose any method to define your region of interest\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "analysis_geom = None\n",
    "temperature_data = None\n",
    "\n",
    "# Create map for ROI selection\n",
    "m = geemap.Map(center=[-12.9714, -38.5014], zoom=10)  # Salvador, Brazil\n",
    "m.add_basemap('SATELLITE')\n",
    "m.add('draw_control')\n",
    "\n",
    "def set_roi_from_drawing():\n",
    "    '''Extract ROI from map drawing'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        if hasattr(m, 'draw_control') and len(m.draw_control.data) > 0:\n",
    "            # Get the last drawn feature\n",
    "            feature = m.draw_control.data[-1]\n",
    "            coords = feature['geometry']['coordinates']\n",
    "            \n",
    "            if feature['geometry']['type'] == 'Polygon':\n",
    "                analysis_geom = ee.Geometry.Polygon(coords)\n",
    "            elif feature['geometry']['type'] == 'Rectangle':\n",
    "                analysis_geom = ee.Geometry.Rectangle(coords)\n",
    "            \n",
    "            area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "            bounds_info = analysis_geom.bounds().getInfo()['coordinates'][0]\n",
    "            west, south = bounds_info[0]\n",
    "            east, north = bounds_info[2]\n",
    "            \n",
    "            print(f'‚úÖ ROI set from drawing: {area_km2:.1f} km¬≤')\n",
    "            print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            return True\n",
    "        else:\n",
    "            print('‚ùå No drawing found. Please draw a polygon or rectangle on the map.')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from drawing: {e}')\n",
    "        return False\n",
    "\n",
    "def set_roi_from_coordinates():\n",
    "    '''Set ROI from coordinate inputs'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        west = float(west_input.value) if west_input.value else -38.7\n",
    "        east = float(east_input.value) if east_input.value else -38.3\n",
    "        south = float(south_input.value) if south_input.value else -13.1\n",
    "        north = float(north_input.value) if north_input.value else -12.8\n",
    "        \n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north])\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        # Add rectangle to map with proper visualization\n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['red'], 'max': 1}, 'ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'‚úÖ ROI set from coordinates: {area_km2:.1f} km¬≤')\n",
    "        print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from coordinates: {e}')\n",
    "        return False\n",
    "\n",
    "def browse_raster_file():\n",
    "    '''Open file browser to select raster file'''\n",
    "    try:\n",
    "        # Create a temporary tkinter root window\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()  # Hide the root window\n",
    "        \n",
    "        # Open file dialog\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title='Select Reference Raster File',\n",
    "            filetypes=[\n",
    "                ('Raster files', '*.tif *.tiff *.img *.nc *.hdf *.jp2'),\n",
    "                ('GeoTIFF', '*.tif *.tiff'),\n",
    "                ('NetCDF', '*.nc'),\n",
    "                ('All files', '*.*')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        root.destroy()  # Clean up\n",
    "        \n",
    "        if file_path:\n",
    "            raster_path_display.value = file_path\n",
    "            print(f'üìÅ Selected file: {os.path.basename(file_path)}')\n",
    "            print(f'    Full path: {file_path}')\n",
    "            return file_path\n",
    "        else:\n",
    "            print('‚ùå No file selected')\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error opening file browser: {e}')\n",
    "        print('   Note: File browser requires GUI environment')\n",
    "        return None\n",
    "\n",
    "def set_roi_from_raster():\n",
    "    '''Set ROI from selected raster extent with proper CRS handling'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        raster_path = raster_path_display.value.strip()\n",
    "        \n",
    "        if not raster_path or not os.path.exists(raster_path):\n",
    "            print('‚ùå Please select a valid raster file first')\n",
    "            return False\n",
    "        \n",
    "        print(f'üìñ Reading raster: {os.path.basename(raster_path)}')\n",
    "        \n",
    "        # Read raster bounds and CRS information\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "            shape = src.shape\n",
    "            transform = src.transform\n",
    "            \n",
    "            # Get bounds in original CRS\n",
    "            west, south, east, north = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "            \n",
    "            print(f'   üìä Raster info:')\n",
    "            print(f'      CRS: {crs}')\n",
    "            print(f'      Shape: {shape}')\n",
    "            print(f'      Original bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            \n",
    "            # Transform to WGS84 if needed\n",
    "            if crs.to_epsg() != 4326:\n",
    "                from rasterio.warp import transform_bounds\n",
    "                west_wgs84, south_wgs84, east_wgs84, north_wgs84 = transform_bounds(\n",
    "                    crs, 'EPSG:4326', west, south, east, north\n",
    "                )\n",
    "                print(f'      Transformed to WGS84:')\n",
    "                print(f'      WGS84 bounds: W={west_wgs84:.6f}, E={east_wgs84:.6f}, S={south_wgs84:.6f}, N={north_wgs84:.6f}')\n",
    "                west, south, east, north = west_wgs84, south_wgs84, east_wgs84, north_wgs84\n",
    "            else:\n",
    "                print(f'      Already in WGS84')\n",
    "        \n",
    "        # Validate bounds are reasonable\n",
    "        if abs(west) > 180 or abs(east) > 180 or abs(south) > 90 or abs(north) > 90:\n",
    "            print(f'‚ùå Invalid bounds detected - coordinates out of valid range')\n",
    "            print(f'   This suggests a CRS projection issue')\n",
    "            return False\n",
    "        \n",
    "        if west >= east or south >= north:\n",
    "            print(f'‚ùå Invalid bounds - west >= east or south >= north')\n",
    "            return False\n",
    "        \n",
    "        # Create geometry in WGS84\n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north], 'EPSG:4326')\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        # Add to map with proper visualization\n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['blue'], 'max': 1}, 'Raster ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'   ‚úÖ ROI set from raster extent: {area_km2:.1f} km¬≤')\n",
    "        print(f'   Final WGS84 bounds: W={west:.6f}, E={east:.6f}, S={south:.6f}, N={north:.6f}')\n",
    "        \n",
    "        # Test if ROI overlaps with GSHTD data coverage\n",
    "        test_centroid = analysis_geom.centroid().coordinates().getInfo()\n",
    "        test_lon, test_lat = test_centroid[0], test_centroid[1]\n",
    "        print(f'   üéØ ROI center: {test_lat:.3f}¬∞N, {test_lon:.3f}¬∞E')\n",
    "        \n",
    "        # Check if in valid GSHTD coverage areas\n",
    "        valid_coverage = False\n",
    "        if test_lat > 15 and test_lon > -140 and test_lon < -40:  # North America\n",
    "            print(f'   üåç ROI appears to be in North America coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat < 35 and test_lon > -120 and test_lon < -30:  # Latin America  \n",
    "            print(f'   üåç ROI appears to be in Latin America coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat > 30 and test_lon > -15 and test_lon < 180:  # Europe & Asia\n",
    "            print(f'   üåç ROI appears to be in Europe/Asia coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat < 40 and test_lon > -20 and test_lon < 55:  # Africa\n",
    "            print(f'   üåç ROI appears to be in Africa coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat < -5 and test_lon > 110 and test_lon < 180:  # Australia\n",
    "            print(f'   üåç ROI appears to be in Australia coverage')\n",
    "            valid_coverage = True\n",
    "        \n",
    "        if not valid_coverage:\n",
    "            print(f'   ‚ö†Ô∏è Warning: ROI may be outside GSHTD coverage areas')\n",
    "            print(f'   ‚ö†Ô∏è GSHTD covers: North America, Latin America, Europe/Asia, Africa, Australia')\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from raster: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "# ROI input widgets\n",
    "west_input = widgets.FloatText(value=-38.7, description='West:')\n",
    "east_input = widgets.FloatText(value=-38.3, description='East:')\n",
    "south_input = widgets.FloatText(value=-13.1, description='South:')\n",
    "north_input = widgets.FloatText(value=-12.8, description='North:')\n",
    "\n",
    "# File browser widgets\n",
    "raster_path_display = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='No file selected...',\n",
    "    description='Selected File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    disabled=True  # Read-only display\n",
    ")\n",
    "\n",
    "browse_button = widgets.Button(\n",
    "    description='üìÇ Browse Files',\n",
    "    button_style='info',\n",
    "    tooltip='Click to select a raster file'\n",
    ")\n",
    "browse_button.on_click(lambda b: browse_raster_file())\n",
    "\n",
    "# Action buttons\n",
    "set_drawing_button = widgets.Button(description='üìç Use Drawing', button_style='success')\n",
    "set_coords_button = widgets.Button(description='üìç Use Coordinates', button_style='info')\n",
    "set_raster_button = widgets.Button(description='üìç Use Raster Extent', button_style='warning')\n",
    "\n",
    "set_drawing_button.on_click(lambda b: set_roi_from_drawing())\n",
    "set_coords_button.on_click(lambda b: set_roi_from_coordinates())\n",
    "set_raster_button.on_click(lambda b: set_roi_from_raster())\n",
    "\n",
    "roi_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üéØ ROI Selection - Enhanced with File Browser</h3>'),\n",
    "    \n",
    "    widgets.HTML('<b>Method 1: Draw on Map</b>'),\n",
    "    widgets.HTML('Draw a polygon or rectangle on the map below, then click:'),\n",
    "    set_drawing_button,\n",
    "    \n",
    "    widgets.HTML('<b>Method 2: Enter Coordinates</b>'),\n",
    "    widgets.HBox([west_input, east_input]),\n",
    "    widgets.HBox([south_input, north_input]),\n",
    "    set_coords_button,\n",
    "    \n",
    "    widgets.HTML('<b>Method 3: Use Raster File Extent</b>'),\n",
    "    widgets.HTML('Click Browse to select a reference raster file:'),\n",
    "    widgets.HBox([browse_button, raster_path_display]),\n",
    "    set_raster_button\n",
    "])\n",
    "\n",
    "display(roi_interface)\n",
    "display(m)\n",
    "\n",
    "print('üéØ Enhanced ROI Selection Ready with File Browser')\n",
    "print('üîß Improved CRS handling and coordinate validation')\n",
    "print('Choose any method to define your region of interest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Analysis Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14ff904ea2d4d1aa15218f3c19fd641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìä Analysis Configuration</h3>'), HTML(value='<div style=\"background-color: #fff‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Configuration Ready\n"
     ]
    }
   ],
   "source": [
    "# Analysis configuration\n",
    "analysis_year = widgets.IntSlider(value=2020, min=2003, max=2020, description='Analysis Year:')\n",
    "reference_start = widgets.IntSlider(value=2010, min=2003, max=2019, description='Reference Start:')\n",
    "reference_end = widgets.IntSlider(value=2019, min=2004, max=2020, description='Reference End:')\n",
    "absolute_threshold = widgets.FloatSlider(value=35.0, min=20.0, max=45.0, step=0.5, description='Threshold (¬∞C):')\n",
    "percentile_threshold = widgets.FloatSlider(value=95.0, min=50.0, max=99.0, step=1.0, description='Percentile:')\n",
    "\n",
    "config_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üìä Analysis Configuration</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>Note:</b> High thresholds (35¬∞C, 95th percentile) may result in few/zero heat days ' +\n",
    "                'in some regions. This is scientifically valid for climatological extremes.</div>'),\n",
    "    analysis_year,\n",
    "    widgets.HBox([reference_start, reference_end]),\n",
    "    widgets.HBox([absolute_threshold, percentile_threshold])\n",
    "])\n",
    "\n",
    "display(config_interface)\n",
    "print('üìä Configuration Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 3: Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9121d8c52ac641d4a69984e27364b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='üîÑ Extract Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Ready to extract pixel-level temperature data using temporal chunking\n",
      "üéØ Maintains 1km resolution for intra-urban analysis\n",
      "‚ö° Extracts year-by-year to avoid GEE limits\n"
     ]
    }
   ],
   "source": [
    "def extract_temperature_data():\n",
    "    '''Extract temperature data from GSHTD using temporal chunking for 1km resolution'''\n",
    "    global temperature_data, analysis_geom\n",
    "    \n",
    "    if analysis_geom is None:\n",
    "        print('‚ùå Please set an ROI first!')\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print('üîÑ Extracting temperature data from GSHTD with temporal chunking for 1km resolution...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        \n",
    "        # Debug ROI information\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        bounds = analysis_geom.bounds().getInfo()\n",
    "        print(f'   üìè ROI area: {area_km2:.2f} km¬≤')\n",
    "        print(f'   üó∫Ô∏è ROI bounds: {bounds}')\n",
    "        \n",
    "        # Function to get regional collection based on location\n",
    "        def get_region_collection(geom):\n",
    "            \"\"\"Determine which regional GSHTD collection to use based on geometry location\"\"\"\n",
    "            centroid = geom.centroid().coordinates().getInfo()\n",
    "            lon, lat = centroid[0], centroid[1]\n",
    "            \n",
    "            if lat > 15 and lon > -140 and lon < -40:  # North America\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"\n",
    "            elif lat < 35 and lon > -120 and lon < -30:  # Latin America  \n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/latin_america\"\n",
    "            elif lat > 30 and lon > -15 and lon < 180:  # Europe & Asia\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/europe_asia\"\n",
    "            elif lat < 40 and lon > -20 and lon < 55:  # Africa\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/africa\"\n",
    "            elif lat < -5 and lon > 110 and lon < 180:  # Australia\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/australia\"\n",
    "            else:\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"  # Default\n",
    "        \n",
    "        # Function to get temperature collection - FIXED: No longer applying scaling here\n",
    "        def get_temperature_collection(region_geom, start_date, end_date, temp_type='tmax'):\n",
    "            \"\"\"Get daily air temperature collection for the specified region and period\"\"\"\n",
    "            collection_id = get_region_collection(region_geom)\n",
    "            print(f'   üì° Using collection: {collection_id.split(\"/\")[-1]}')\n",
    "            \n",
    "            collection = ee.ImageCollection(collection_id)\n",
    "            \n",
    "            # Filter by date, bounds, and temperature type using prop_type metadata\n",
    "            filtered_collection = (collection.filterDate(start_date, end_date)\n",
    "                                 .filterBounds(region_geom)\n",
    "                                 .filter(ee.Filter.eq('prop_type', temp_type)))\n",
    "            \n",
    "            # FIXED: Just select and clip, don't apply scaling here since getRegion handles raw values\n",
    "            temp_collection = filtered_collection.map(lambda img: \n",
    "                img.select('b1')\n",
    "                  .clip(region_geom)\n",
    "                  .copyProperties(img, ['system:time_start'])\n",
    "            )\n",
    "            \n",
    "            return temp_collection\n",
    "        \n",
    "        # Test pixel count at 1km resolution\n",
    "        test_collection = get_temperature_collection(analysis_geom, f'{year}-01-01', f'{year}-01-02', 'tmax')\n",
    "        \n",
    "        if test_collection.size().getInfo() == 0:\n",
    "            print('‚ùå No images found for test date - check ROI coverage')\n",
    "            return False\n",
    "        \n",
    "        first_image = test_collection.first()\n",
    "        pixel_count = first_image.select('b1').reduceRegion(\n",
    "            reducer=ee.Reducer.count(),\n",
    "            geometry=analysis_geom,\n",
    "            scale=1000,  # 1km resolution\n",
    "            maxPixels=1e9\n",
    "        ).getInfo()\n",
    "        \n",
    "        expected_pixels = pixel_count.get('b1', 0)\n",
    "        print(f'   üîç Expected pixels per image at 1km: {expected_pixels}')\n",
    "        \n",
    "        if expected_pixels == 0:\n",
    "            print('‚ùå No pixels found in ROI - check if ROI overlaps with data coverage')\n",
    "            return False\n",
    "        \n",
    "        # Calculate years to extract\n",
    "        years_to_extract = list(range(ref_start, ref_end + 1)) + [year]\n",
    "        years_to_extract = sorted(list(set(years_to_extract)))  # Remove duplicates and sort\n",
    "        \n",
    "        print(f'   üìÖ Will extract {len(years_to_extract)} years: {years_to_extract}')\n",
    "        print(f'   üéØ Using temporal chunking to maintain 1km resolution')\n",
    "        \n",
    "        # Extract data year by year\n",
    "        all_dataframes = []\n",
    "        \n",
    "        for extract_year in years_to_extract:\n",
    "            print(f'\\\\n   üìÖ Extracting year {extract_year}...')\n",
    "            \n",
    "            year_collection = get_temperature_collection(\n",
    "                analysis_geom, f'{extract_year}-01-01', f'{extract_year}-12-31', 'tmax'\n",
    "            )\n",
    "            \n",
    "            year_size = year_collection.size().getInfo()\n",
    "            estimated_values = expected_pixels * year_size\n",
    "            \n",
    "            print(f'      Images: {year_size}, Estimated values: {estimated_values:,}')\n",
    "            \n",
    "            if estimated_values > 900000:  # Still too large\n",
    "                print(f'      ‚ö†Ô∏è Still too large for single year, using 2km scale')\n",
    "                scale = 2000\n",
    "            else:\n",
    "                print(f'      ‚úÖ Using 1km scale')\n",
    "                scale = 1000\n",
    "            \n",
    "            try:\n",
    "                region_data = year_collection.getRegion(\n",
    "                    geometry=analysis_geom,\n",
    "                    scale=scale,\n",
    "                    crs='EPSG:4326'\n",
    "                ).getInfo()\n",
    "                \n",
    "                print(f'      ‚úÖ Extracted {len(region_data)} rows')\n",
    "                \n",
    "                if len(region_data) > 1:  # More than just header\n",
    "                    header = region_data[0]\n",
    "                    data = region_data[1:]\n",
    "                    \n",
    "                    df_year = pd.DataFrame(data, columns=header)\n",
    "                    df_year['time'] = pd.to_datetime(df_year['time'], unit='ms')\n",
    "                    \n",
    "                    # FIXED: Apply temperature scaling and rename column BEFORE dropping nulls\n",
    "                    if 'b1' in df_year.columns:\n",
    "                        df_year['temperature'] = df_year['b1'] / 10.0  # Scale to Celsius\n",
    "                        df_year = df_year.drop(columns=['b1'])  # Remove original column\n",
    "                    \n",
    "                    # Now drop nulls from the correctly named temperature column\n",
    "                    df_year = df_year.dropna(subset=['temperature'])\n",
    "                    \n",
    "                    print(f'      üìä Valid observations: {len(df_year)}')\n",
    "                    \n",
    "                    if len(df_year) > 0:\n",
    "                        all_dataframes.append(df_year)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'      ‚ùå Failed to extract {extract_year}: {e}')\n",
    "                continue\n",
    "        \n",
    "        if not all_dataframes:\n",
    "            print('‚ùå No data extracted for any year')\n",
    "            return False\n",
    "        \n",
    "        # Combine all years\n",
    "        print(f'\\\\n   üîó Combining {len(all_dataframes)} years of data...')\n",
    "        df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        \n",
    "        print(f'   üìä Total combined data: {len(df)} observations')\n",
    "        \n",
    "        unique_pixels = df[['longitude', 'latitude']].drop_duplicates()\n",
    "        print(f'   üìç Unique spatial pixels: {len(unique_pixels)}')\n",
    "        print(f'   üå°Ô∏è Temperature range: {df[\"temperature\"].min():.1f}¬∞C to {df[\"temperature\"].max():.1f}¬∞C')\n",
    "        print(f'   üìê Resolution achieved: {scale}m')\n",
    "        \n",
    "        # Show sample of the data\n",
    "        print('\\\\nüìã Sample of extracted data:')\n",
    "        print(df[['time', 'latitude', 'longitude', 'temperature']].head())\n",
    "        \n",
    "        # Convert to xarray\n",
    "        try:\n",
    "            temperature_data = df.set_index(['time', 'latitude', 'longitude']).to_xarray()\n",
    "            \n",
    "            print(f'\\\\n‚úÖ Xarray dataset created successfully!')\n",
    "            print(f'   üìÖ Time range: {temperature_data.time.min().values} to {temperature_data.time.max().values}')\n",
    "            print(f'   üåç Spatial dimensions: {temperature_data.dims[\"latitude\"]} √ó {temperature_data.dims[\"longitude\"]} pixels')\n",
    "            print(f'   üìä Total observations: {temperature_data.temperature.count().values}')\n",
    "            print(f'   üéØ Dataset: GSHTD Daily Air Temperature at {scale}m resolution')\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Error converting to xarray: {e}')\n",
    "            print('   Raw DataFrame saved as backup for debugging')\n",
    "            globals()['debug_df'] = df\n",
    "            return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error extracting data: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "extract_button = widgets.Button(description='üîÑ Extract Data', button_style='primary')\n",
    "extract_button.on_click(lambda b: extract_temperature_data())\n",
    "\n",
    "display(extract_button)\n",
    "print('üîÑ Ready to extract pixel-level temperature data using temporal chunking')\n",
    "print('üéØ Maintains 1km resolution for intra-urban analysis')\n",
    "print('‚ö° Extracts year-by-year to avoid GEE limits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 3.5: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaebdfaa75d44992af19f8e33622b1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='üîç Explore Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Click to explore your extracted xarray dataset with inline plots\n",
      "üõ°Ô∏è Enhanced with better error handling for small datasets\n"
     ]
    }
   ],
   "source": [
    "def explore_temperature_data():\n",
    "    '''Explore the extracted temperature xarray dataset with inline visualization'''\n",
    "    global temperature_data\n",
    "    \n",
    "    if temperature_data is None:\n",
    "        print('‚ùå Please extract temperature data first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('üîç EXPLORING TEMPERATURE XARRAY DATASET')\n",
    "        print('='*50)\n",
    "        \n",
    "        # Dataset overview\n",
    "        print('üìä DATASET OVERVIEW:')\n",
    "        print(f'   Data variables: {list(temperature_data.data_vars)}')\n",
    "        print(f'   Coordinates: {list(temperature_data.coords)}')\n",
    "        print(f'   Dimensions: {dict(temperature_data.dims)}')\n",
    "        print(f'   Size in memory: {temperature_data.nbytes / 1024**2:.1f} MB')\n",
    "        \n",
    "        # Check if we have valid spatial dimensions\n",
    "        if 'latitude' not in temperature_data.dims or 'longitude' not in temperature_data.dims:\n",
    "            print('‚ùå Missing spatial dimensions (latitude/longitude)')\n",
    "            return\n",
    "            \n",
    "        if len(temperature_data.latitude) == 0 or len(temperature_data.longitude) == 0:\n",
    "            print('‚ùå Empty spatial dimensions')\n",
    "            return\n",
    "        \n",
    "        # Spatial coverage\n",
    "        lats = temperature_data.latitude.values\n",
    "        lons = temperature_data.longitude.values\n",
    "        print(f'\\\\nüåç SPATIAL COVERAGE:')\n",
    "        print(f'   Latitude range: {lats.min():.3f} to {lats.max():.3f}')\n",
    "        print(f'   Longitude range: {lons.min():.3f} to {lons.max():.3f}')\n",
    "        print(f'   Number of spatial pixels: {len(lats) * len(lons)}')\n",
    "        \n",
    "        # Temperature statistics\n",
    "        temp_vals = temperature_data.temperature.values\n",
    "        temp_vals_clean = temp_vals[~np.isnan(temp_vals)]\n",
    "        \n",
    "        if len(temp_vals_clean) == 0:\n",
    "            print('‚ùå No valid temperature values found')\n",
    "            return\n",
    "            \n",
    "        print(f'\\\\nüå°Ô∏è TEMPERATURE STATISTICS:')\n",
    "        print(f'   Valid values: {len(temp_vals_clean):,} of {temp_vals.size:,} total')\n",
    "        print(f'   Temperature range: {temp_vals_clean.min():.1f}¬∞C to {temp_vals_clean.max():.1f}¬∞C')\n",
    "        print(f'   Mean temperature: {temp_vals_clean.mean():.1f}¬∞C')\n",
    "        \n",
    "        # Check thresholds\n",
    "        abs_thresh = absolute_threshold.value\n",
    "        pct_thresh = percentile_threshold.value\n",
    "        overall_percentile = np.percentile(temp_vals_clean, pct_thresh)\n",
    "        \n",
    "        print(f'\\\\n‚ö†Ô∏è THRESHOLD ANALYSIS:')\n",
    "        print(f'   Absolute threshold: {abs_thresh}¬∞C')\n",
    "        print(f'   {pct_thresh}th percentile: {overall_percentile:.1f}¬∞C')\n",
    "        \n",
    "        values_above_abs = (temp_vals_clean > abs_thresh).sum()\n",
    "        values_above_pct = (temp_vals_clean > overall_percentile).sum()\n",
    "        \n",
    "        print(f'   Values above {abs_thresh}¬∞C: {values_above_abs:,} ({values_above_abs/len(temp_vals_clean)*100:.1f}%)')\n",
    "        print(f'   Values above {pct_thresh}th percentile: {values_above_pct:,} ({values_above_pct/len(temp_vals_clean)*100:.1f}%)')\n",
    "        \n",
    "        if values_above_abs < 10 and values_above_pct < 10:\n",
    "            print('   üö® WARNING: Very few values exceed your thresholds!')\n",
    "            print('   üö® Results may have many zero heat days (this may be scientifically correct)')\n",
    "        \n",
    "        # Create inline visualization with error handling\n",
    "        print('\\\\nüìä CREATING EXPLORATION PLOTS...')\n",
    "        \n",
    "        try:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            \n",
    "            # Temperature histogram\n",
    "            axes[0,0].hist(temp_vals_clean, bins=min(50, len(temp_vals_clean)//10), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            axes[0,0].axvline(abs_thresh, color='red', linestyle='--', linewidth=2, label=f'Absolute threshold ({abs_thresh}¬∞C)')\n",
    "            axes[0,0].axvline(overall_percentile, color='orange', linestyle='--', linewidth=2, label=f'{pct_thresh}th percentile ({overall_percentile:.1f}¬∞C)')\n",
    "            axes[0,0].set_title('Temperature Distribution')\n",
    "            axes[0,0].set_xlabel('Temperature (¬∞C)')\n",
    "            axes[0,0].set_ylabel('Frequency')\n",
    "            axes[0,0].legend()\n",
    "            axes[0,0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Sample time series - handle single pixel case\n",
    "            if len(lats) > 0 and len(lons) > 0:\n",
    "                sample_lat = lats[len(lats)//2] if len(lats) > 1 else lats[0]\n",
    "                sample_lon = lons[len(lons)//2] if len(lons) > 1 else lons[0]\n",
    "                sample_pixel = temperature_data.sel(latitude=sample_lat, longitude=sample_lon, method='nearest')\n",
    "                \n",
    "                if len(sample_pixel.temperature.dropna('time')) > 0:\n",
    "                    sample_pixel.temperature.plot(ax=axes[0,1], linewidth=1, alpha=0.7)\n",
    "                    axes[0,1].axhline(abs_thresh, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({abs_thresh}¬∞C)')\n",
    "                    axes[0,1].set_title(f'Sample Pixel Time Series\\\\n({sample_lat:.3f}¬∞, {sample_lon:.3f}¬∞)')\n",
    "                    axes[0,1].set_ylabel('Temperature (¬∞C)')\n",
    "                    axes[0,1].legend()\n",
    "                    axes[0,1].grid(True, alpha=0.3)\n",
    "                else:\n",
    "                    axes[0,1].text(0.5, 0.5, 'No valid data\\\\nfor sample pixel', ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "                    axes[0,1].set_title('Sample Pixel Time Series - No Data')\n",
    "            \n",
    "            # Spatial temperature mean - handle single pixel case\n",
    "            temp_mean = temperature_data.temperature.mean(dim='time')\n",
    "            if len(lats) > 1 and len(lons) > 1:\n",
    "                temp_mean.plot(ax=axes[1,0], cmap='RdYlBu_r', add_colorbar=True, cbar_kwargs={'label': 'Mean Temperature (¬∞C)'})\n",
    "                axes[1,0].set_title('Spatial Mean Temperature')\n",
    "                axes[1,0].set_xlabel('Longitude')\n",
    "                axes[1,0].set_ylabel('Latitude')\n",
    "            else:\n",
    "                # For single pixel, show as text\n",
    "                mean_temp = temp_mean.values.item() if temp_mean.size == 1 else np.nanmean(temp_mean.values)\n",
    "                axes[1,0].text(0.5, 0.5, f'Single Pixel\\\\nMean: {mean_temp:.1f}¬∞C', ha='center', va='center', transform=axes[1,0].transAxes, fontsize=14)\n",
    "                axes[1,0].set_title('Spatial Mean Temperature')\n",
    "            \n",
    "            # Monthly temperature cycle\n",
    "            try:\n",
    "                monthly_temps = temperature_data.temperature.groupby('time.month').mean()\n",
    "                monthly_avg = monthly_temps.mean(dim=['latitude', 'longitude'])\n",
    "                monthly_avg.plot(ax=axes[1,1], marker='o', linewidth=2)\n",
    "                axes[1,1].axhline(abs_thresh, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({abs_thresh}¬∞C)')\n",
    "                axes[1,1].set_title('Monthly Temperature Cycle')\n",
    "                axes[1,1].set_xlabel('Month')\n",
    "                axes[1,1].set_ylabel('Temperature (¬∞C)')\n",
    "                axes[1,1].legend()\n",
    "                axes[1,1].grid(True, alpha=0.3)\n",
    "            except Exception as e:\n",
    "                axes[1,1].text(0.5, 0.5, f'Error creating\\\\nmonthly plot:\\\\n{str(e)[:50]}', ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "                axes[1,1].set_title('Monthly Temperature Cycle - Error')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Error creating plots: {e}')\n",
    "            import traceback\n",
    "            print(f'   Details: {traceback.format_exc()}')\n",
    "        \n",
    "        print('\\\\n‚úÖ Data exploration complete!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error in data exploration: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "explore_button = widgets.Button(description='üîç Explore Data', button_style='info')\n",
    "explore_button.on_click(lambda b: explore_temperature_data())\n",
    "\n",
    "display(explore_button)\n",
    "print('üîç Click to explore your extracted xarray dataset with inline plots')\n",
    "print('üõ°Ô∏è Enhanced with better error handling for small datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 4: Analysis with Inline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c22109b80947bd93b226fd7364bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='üìà Calculate & Visualize', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Ready to calculate climate metrics with inline visualization\n",
      "üîß Fixed to properly store results for export\n",
      "üêõ Added debug output to trace heat days calculation issue\n"
     ]
    }
   ],
   "source": [
    "def calculate_and_visualize_metrics():\n",
    "    '''Calculate climate metrics and create inline visualizations'''\n",
    "    global temperature_data, analysis_results\n",
    "    \n",
    "    if temperature_data is None:\n",
    "        print('‚ùå Please extract temperature data first!')\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print('üìà Calculating climate metrics with inline visualization...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        abs_threshold = absolute_threshold.value\n",
    "        pct_threshold = percentile_threshold.value\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Filter data\n",
    "        analysis_data = temperature_data.sel(time=str(year))\n",
    "        reference_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{ref_end}-12-31'))\n",
    "        \n",
    "        print(f'   üìÖ Analysis year: {len(analysis_data.time)} days')\n",
    "        print(f'   üìÖ Reference period: {len(reference_data.time)} days')\n",
    "        \n",
    "        # DEBUG: Check analysis data\n",
    "        print(f'\\nüîç DEBUG - Analysis data for {year}:')\n",
    "        print(f'   Analysis data shape: {analysis_data.temperature.shape}')\n",
    "        print(f'   Analysis temp range: {analysis_data.temperature.min().values:.1f} to {analysis_data.temperature.max().values:.1f}¬∞C')\n",
    "        print(f'   Analysis data sample dates: {analysis_data.time[:3].values}')\n",
    "        \n",
    "        # Calculate reference percentile\n",
    "        print(f'   üßÆ Calculating {pct_threshold}th percentile...')\n",
    "        reference_percentile = reference_data.temperature.quantile(pct_threshold/100, dim='time')\n",
    "        results['reference_percentile'] = reference_percentile\n",
    "        \n",
    "        # Heat Days calculation with DEBUG\n",
    "        print('   üî• Calculating heat days...')\n",
    "        threshold = xr.where(\n",
    "            reference_percentile > abs_threshold,\n",
    "            reference_percentile,\n",
    "            abs_threshold\n",
    "        )\n",
    "        \n",
    "        # DEBUG: Check threshold calculation\n",
    "        print(f'\\nüîç DEBUG - Threshold calculation:')\n",
    "        print(f'   Reference percentile range: {reference_percentile.min().values:.1f} to {reference_percentile.max().values:.1f}¬∞C')\n",
    "        print(f'   Absolute threshold: {abs_threshold}¬∞C')\n",
    "        print(f'   Final threshold range: {threshold.min().values:.1f} to {threshold.max().values:.1f}¬∞C')\n",
    "        \n",
    "        # DEBUG: Check the comparison\n",
    "        print(f'\\nüîç DEBUG - Heat days calculation:')\n",
    "        temp_above_threshold = analysis_data.temperature > threshold\n",
    "        print(f'   Boolean comparison shape: {temp_above_threshold.shape}')\n",
    "        print(f'   Days above threshold (before sum): {temp_above_threshold.sum().values} total instances')\n",
    "        \n",
    "        # Check a specific pixel manually\n",
    "        if len(analysis_data.latitude) > 0 and len(analysis_data.longitude) > 0:\n",
    "            test_lat = analysis_data.latitude.values[0]\n",
    "            test_lon = analysis_data.longitude.values[0] \n",
    "            test_temps = analysis_data.temperature.sel(latitude=test_lat, longitude=test_lon)\n",
    "            test_threshold = threshold.sel(latitude=test_lat, longitude=test_lon)\n",
    "            test_above = (test_temps > test_threshold).sum()\n",
    "            \n",
    "            print(f'   Test pixel ({test_lat:.3f}, {test_lon:.3f}):')\n",
    "            print(f'     Temperature range: {test_temps.min().values:.1f} to {test_temps.max().values:.1f}¬∞C')\n",
    "            print(f'     Threshold: {test_threshold.values:.1f}¬∞C')\n",
    "            print(f'     Days above threshold: {test_above.values}')\n",
    "        \n",
    "        heat_days = (analysis_data.temperature > threshold).sum(dim='time').fillna(0)\n",
    "        print(f'   Final heat days range: {heat_days.min().values} to {heat_days.max().values}')\n",
    "        \n",
    "        results['heat_days'] = heat_days\n",
    "        results['threshold_used'] = threshold\n",
    "        \n",
    "        # Temperature Trends\n",
    "        print('   üìà Calculating temperature trends...')\n",
    "        trends = reference_data.temperature.polyfit(dim='time', deg=1)\n",
    "        trend_slope = trends.polyfit_coefficients.sel(degree=1)\n",
    "        ns_per_year = 365.25 * 24 * 60 * 60 * 1e9\n",
    "        trend_per_year = (trend_slope * ns_per_year).fillna(0)\n",
    "        results['temperature_trend'] = trend_per_year\n",
    "        \n",
    "        # Seasonal Means\n",
    "        print('   üåÖ Calculating seasonal means...')\n",
    "        seasonal_means = analysis_data.temperature.groupby('time.season').mean()\n",
    "        results['seasonal_means'] = seasonal_means\n",
    "        \n",
    "        # Annual extremes\n",
    "        print('   üå°Ô∏è Calculating annual extremes...')\n",
    "        annual_max = analysis_data.temperature.max(dim='time').fillna(0)\n",
    "        annual_min = analysis_data.temperature.min(dim='time').fillna(0)\n",
    "        annual_range = (annual_max - annual_min).fillna(0)\n",
    "        \n",
    "        results['annual_max'] = annual_max\n",
    "        results['annual_min'] = annual_min\n",
    "        results['annual_range'] = annual_range\n",
    "        \n",
    "        print('\\\\n‚úÖ Climate metrics calculated successfully!')\n",
    "        \n",
    "        # Print summary\n",
    "        print(f'\\\\nüìä RESULTS SUMMARY:')\n",
    "        print(f'   Mean heat days: {heat_days.mean().values:.1f}')\n",
    "        print(f'   Max heat days: {heat_days.max().values:.0f}')\n",
    "        print(f'   Pixels with >0 heat days: {(heat_days > 0).sum().values} of {heat_days.count().values}')\n",
    "        print(f'   Mean temperature trend: {trend_per_year.mean().values:.3f} ¬∞C/year')\n",
    "        \n",
    "        # Create comprehensive inline visualization\n",
    "        print('\\\\nüìä CREATING RESULTS VISUALIZATION...')\n",
    "        \n",
    "        try:\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "            \n",
    "            # Heat Days Map\n",
    "            heat_days.plot(ax=axes[0,0], cmap='Reds', add_colorbar=True, cbar_kwargs={'label': 'Heat Days'})\n",
    "            axes[0,0].set_title('Heat Days per Pixel', fontweight='bold')\n",
    "            \n",
    "            # Temperature Trends\n",
    "            trend_per_year.plot(ax=axes[0,1], cmap='RdBu_r', add_colorbar=True, cbar_kwargs={'label': '¬∞C/year'})\n",
    "            axes[0,1].set_title('Temperature Trends (¬∞C/year)', fontweight='bold')\n",
    "            \n",
    "            # Annual Temperature Range\n",
    "            annual_range.plot(ax=axes[0,2], cmap='viridis', add_colorbar=True, cbar_kwargs={'label': '¬∞C'})\n",
    "            axes[0,2].set_title('Annual Temperature Range (¬∞C)', fontweight='bold')\n",
    "            \n",
    "            # Time Series\n",
    "            daily_avg = analysis_data.temperature.mean(dim=['latitude', 'longitude'])\n",
    "            daily_avg.plot(ax=axes[1,0], linewidth=1.5, color='blue')\n",
    "            axes[1,0].axhline(abs_threshold, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({abs_threshold}¬∞C)')\n",
    "            axes[1,0].set_title(f'Daily Average Temperature - {year}', fontweight='bold')\n",
    "            axes[1,0].set_ylabel('Temperature (¬∞C)')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Seasonal Means\n",
    "            seasonal_avg = seasonal_means.mean(dim=['latitude', 'longitude'])\n",
    "            seasonal_avg.plot.bar(ax=axes[1,1], color=['lightblue', 'lightgreen', 'orange', 'lightcoral'])\n",
    "            axes[1,1].set_title('Seasonal Temperature Means', fontweight='bold')\n",
    "            axes[1,1].set_ylabel('Temperature (¬∞C)')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Heat Days Distribution\n",
    "            heat_days_flat = heat_days.values.flatten()\n",
    "            heat_days_clean = heat_days_flat[~np.isnan(heat_days_flat)]\n",
    "            axes[1,2].hist(heat_days_clean, bins=20, alpha=0.7, color='red', edgecolor='black')\n",
    "            axes[1,2].set_title('Heat Days Distribution', fontweight='bold')\n",
    "            axes[1,2].set_xlabel('Heat Days per Pixel')\n",
    "            axes[1,2].set_ylabel('Frequency')\n",
    "            axes[1,2].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as viz_error:\n",
    "            print(f'‚ö†Ô∏è Visualization error (results still calculated): {viz_error}')\n",
    "        \n",
    "        print('\\\\n‚úÖ Analysis and visualization complete!')\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error calculating metrics: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return None\n",
    "\n",
    "# Fixed analyze button to properly set global variable\n",
    "analyze_button = widgets.Button(description='üìà Calculate & Visualize', button_style='success')\n",
    "analysis_results = None\n",
    "\n",
    "def run_analysis_with_viz(button):\n",
    "    global analysis_results  # Make sure this is global\n",
    "    print('üîÑ Starting analysis...')\n",
    "    analysis_results = calculate_and_visualize_metrics()\n",
    "    if analysis_results is not None:\n",
    "        print('‚úÖ Analysis results stored successfully!')\n",
    "        print('üìÅ Ready for export')\n",
    "    else:\n",
    "        print('‚ùå Analysis failed - results not available for export')\n",
    "\n",
    "analyze_button.on_click(run_analysis_with_viz)\n",
    "\n",
    "display(analyze_button)\n",
    "print('üìà Ready to calculate climate metrics with inline visualization')\n",
    "print('üîß Fixed to properly store results for export')\n",
    "print('üêõ Added debug output to trace heat days calculation issue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Step 5: Export Results to ../outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb54b653bd4aee8429abbdfff0b021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='üìÅ Export to ../outputs', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Ready to export full pixel-level results to ../outputs directory\n",
      "üåç Fixed: NetCDF files now include proper WGS84 CRS information\n",
      "üîß Fixed: CSV export now properly extracts values from analysis results\n"
     ]
    }
   ],
   "source": [
    "def export_results():\n",
    "    '''Export analysis results to ../outputs directory with proper CRS'''\n",
    "    global analysis_results, temperature_data\n",
    "    \n",
    "    if analysis_results is None:\n",
    "        print('‚ùå Please run analysis first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('üìÅ Exporting results to ../outputs directory...')\n",
    "        year = analysis_year.value\n",
    "        \n",
    "        # Create outputs directory\n",
    "        os.makedirs('../outputs', exist_ok=True)\n",
    "        \n",
    "        # 1. Summary Table\n",
    "        print('   üìÑ Creating summary statistics table...')\n",
    "        summary_data = []\n",
    "        \n",
    "        for metric_name, metric_data in analysis_results.items():\n",
    "            if hasattr(metric_data, 'mean') and len(metric_data.dims) <= 2:\n",
    "                try:\n",
    "                    if metric_name != 'seasonal_means':\n",
    "                        valid_count = metric_data.count().values\n",
    "                        if valid_count > 0:\n",
    "                            summary_data.append({\n",
    "                                'metric': metric_name,\n",
    "                                'valid_pixels': int(valid_count),\n",
    "                                'mean': float(metric_data.mean().values),\n",
    "                                'min': float(metric_data.min().values),\n",
    "                                'max': float(metric_data.max().values),\n",
    "                                'std': float(metric_data.std().values),\n",
    "                                'median': float(metric_data.median().values)\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f'     ‚ö†Ô∏è Skipping {metric_name}: {e}')\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_filename = f'../outputs/climate_summary_{year}.csv'\n",
    "            summary_df.to_csv(summary_filename, index=False)\n",
    "            print(f'   ‚úÖ Summary saved: {summary_filename}')\n",
    "            \n",
    "            # Display summary table inline\n",
    "            print('\\nüìä SUMMARY STATISTICS:')\n",
    "            display(summary_df)\n",
    "        \n",
    "        # 2. FIXED: Full Pixel-wise Data Export using NetCDF coordinates\n",
    "        print('\\n   üìä Creating full pixel-wise data export...')\n",
    "        \n",
    "        # Use coordinates from analysis_results instead of temperature_data\n",
    "        sample_metric = next(iter(analysis_results.values()))\n",
    "        if hasattr(sample_metric, 'latitude') and hasattr(sample_metric, 'longitude'):\n",
    "            lats = sample_metric.latitude.values\n",
    "            lons = sample_metric.longitude.values\n",
    "        else:\n",
    "            print('‚ùå No spatial coordinates found in analysis results')\n",
    "            return\n",
    "        \n",
    "        total_pixels = len(lats) * len(lons)\n",
    "        print(f'      Processing {total_pixels} pixels...')\n",
    "        \n",
    "        pixel_data = []\n",
    "        processed = 0\n",
    "        \n",
    "        for i, lat in enumerate(lats):\n",
    "            for j, lon in enumerate(lons):\n",
    "                row = {\n",
    "                    'pixel_id': f'{i}_{j}',\n",
    "                    'latitude': float(lat),\n",
    "                    'longitude': float(lon)\n",
    "                }\n",
    "                \n",
    "                # FIXED: Extract values for each metric with better error handling\n",
    "                for metric_name, metric_data in analysis_results.items():\n",
    "                    if hasattr(metric_data, 'sel') and hasattr(metric_data, 'dims'):\n",
    "                        try:\n",
    "                            if 'latitude' in metric_data.dims and 'longitude' in metric_data.dims:\n",
    "                                if len(metric_data.dims) == 2:\n",
    "                                    # Use exact coordinate matching instead of nearest\n",
    "                                    value = metric_data.loc[lat, lon].values\n",
    "                                    if np.isscalar(value) and not np.isnan(value):\n",
    "                                        row[metric_name] = float(value)\n",
    "                                    else:\n",
    "                                        row[metric_name] = 0.0\n",
    "                                else:\n",
    "                                    row[metric_name] = 0.0\n",
    "                        except (KeyError, IndexError) as e:\n",
    "                            # Coordinate not found - this is expected for water pixels\n",
    "                            row[metric_name] = 0.0\n",
    "                        except Exception as e:\n",
    "                            print(f'      ‚ö†Ô∏è Error extracting {metric_name} at ({lat}, {lon}): {e}')\n",
    "                            row[metric_name] = 0.0\n",
    "                    else:\n",
    "                        row[metric_name] = 0.0\n",
    "                \n",
    "                pixel_data.append(row)\n",
    "                processed += 1\n",
    "                \n",
    "                if processed % max(1, total_pixels // 10) == 0:\n",
    "                    print(f'      Progress: {processed}/{total_pixels} ({processed/total_pixels*100:.0f}%)')\n",
    "        \n",
    "        if pixel_data:\n",
    "            pixel_df = pd.DataFrame(pixel_data)\n",
    "            pixel_filename = f'../outputs/climate_pixels_{year}.csv'\n",
    "            pixel_df.to_csv(pixel_filename, index=False)\n",
    "            \n",
    "            print(f'\\n   ‚úÖ Full pixel data saved: {pixel_filename}')\n",
    "            print(f'      Rows: {len(pixel_df):,}')\n",
    "            print(f'      Columns: {len(pixel_df.columns)}')\n",
    "            \n",
    "            # Check for non-zero values\n",
    "            non_zero_counts = {}\n",
    "            for col in pixel_df.columns:\n",
    "                if col not in ['pixel_id', 'latitude', 'longitude']:\n",
    "                    non_zero_counts[col] = (pixel_df[col] != 0).sum()\n",
    "            \n",
    "            print(f'      Non-zero value counts:')\n",
    "            for col, count in non_zero_counts.items():\n",
    "                print(f'        {col}: {count}')\n",
    "            \n",
    "            # Show sample inline\n",
    "            print('\\nüìä SAMPLE PIXEL DATA:')\n",
    "            display(pixel_df.head(10))\n",
    "        \n",
    "        # 3. NetCDF Export with proper CRS\n",
    "        print('\\n   üì¶ Creating NetCDF file with proper CRS...')\n",
    "        \n",
    "        spatial_results = {}\n",
    "        for k, v in analysis_results.items():\n",
    "            if hasattr(v, 'dims') and 'latitude' in v.dims and 'longitude' in v.dims:\n",
    "                if len(v.dims) == 2:\n",
    "                    spatial_results[k] = v.fillna(0)\n",
    "        \n",
    "        if spatial_results:\n",
    "            results_ds = xr.Dataset(spatial_results)\n",
    "            \n",
    "            # Add proper CRS information (WGS84)\n",
    "            results_ds.latitude.attrs['standard_name'] = 'latitude'\n",
    "            results_ds.latitude.attrs['long_name'] = 'latitude'\n",
    "            results_ds.latitude.attrs['units'] = 'degrees_north'\n",
    "            results_ds.latitude.attrs['axis'] = 'Y'\n",
    "            \n",
    "            results_ds.longitude.attrs['standard_name'] = 'longitude'\n",
    "            results_ds.longitude.attrs['long_name'] = 'longitude'\n",
    "            results_ds.longitude.attrs['units'] = 'degrees_east'\n",
    "            results_ds.longitude.attrs['axis'] = 'X'\n",
    "            \n",
    "            # Add CRS variable following CF conventions\n",
    "            crs = xr.DataArray(\n",
    "                data=np.int32(1),\n",
    "                attrs={\n",
    "                    'grid_mapping_name': 'latitude_longitude',\n",
    "                    'longitude_of_prime_meridian': 0.0,\n",
    "                    'semi_major_axis': 6378137.0,\n",
    "                    'inverse_flattening': 298.257223563,\n",
    "                    'spatial_ref': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]',\n",
    "                    'crs_wkt': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]'\n",
    "                }\n",
    "            )\n",
    "            results_ds['crs'] = crs\n",
    "            \n",
    "            # Add grid_mapping attribute to all data variables\n",
    "            for var_name in results_ds.data_vars:\n",
    "                if var_name != 'crs':\n",
    "                    results_ds[var_name].attrs['grid_mapping'] = 'crs'\n",
    "            \n",
    "            # Add metadata\n",
    "            results_ds.attrs['analysis_year'] = year\n",
    "            results_ds.attrs['reference_period'] = f'{reference_start.value}-{reference_end.value}'\n",
    "            results_ds.attrs['created'] = datetime.now().isoformat()\n",
    "            results_ds.attrs['absolute_threshold'] = absolute_threshold.value\n",
    "            results_ds.attrs['percentile_threshold'] = percentile_threshold.value\n",
    "            results_ds.attrs['crs'] = 'EPSG:4326'\n",
    "            \n",
    "            netcdf_filename = f'../outputs/climate_analysis_{year}.nc'\n",
    "            results_ds.to_netcdf(netcdf_filename)\n",
    "            \n",
    "            print(f'   ‚úÖ NetCDF saved with proper CRS: {netcdf_filename}')\n",
    "            print(f'      Variables: {list(results_ds.data_vars)}')\n",
    "            print(f'      Dimensions: {dict(results_ds.dims)}')\n",
    "            print(f'      CRS: EPSG:4326 (WGS84)')\n",
    "            print(f'      File size: {os.path.getsize(netcdf_filename) / 1024**2:.1f} MB')\n",
    "        \n",
    "        print('\\n‚úÖ Export complete to ../outputs directory!')\n",
    "        print('\\nüìä Files created:')\n",
    "        print(f'   ‚Ä¢ ../outputs/climate_summary_{year}.csv - Summary statistics')\n",
    "        print(f'   ‚Ä¢ ../outputs/climate_pixels_{year}.csv - ALL pixel values with coordinates')\n",
    "        print(f'   ‚Ä¢ ../outputs/climate_analysis_{year}.nc - NetCDF spatial dataset WITH CRS')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error exporting: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "export_button = widgets.Button(description='üìÅ Export to ../outputs', button_style='warning')\n",
    "export_button.on_click(lambda b: export_results())\n",
    "\n",
    "display(export_button)\n",
    "print('üìÅ Ready to export full pixel-level results to ../outputs directory')\n",
    "print('üåç Fixed: NetCDF files now include proper WGS84 CRS information')\n",
    "print('üîß Fixed: CSV export now properly extracts values from analysis results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook provides the complete xarray climate analysis workflow with:\n",
    "\n",
    "### ‚úÖ **Enhanced Features:**\n",
    "- **File browser button** - Easy raster file selection (no typing paths)\n",
    "- **Inline plots** - All visualizations appear in notebook cells\n",
    "- **Drawing tools** - Interactive ROI selection on map\n",
    "- **Data exploration** - Examine dataset before analysis\n",
    "- **Full pixel export** - Every individual pixel value preserved\n",
    "- **Organized output** - All files saved to ../outputs\n",
    "\n",
    "### üìä **Complete Workflow:**\n",
    "1. **ROI Selection** - Draw, coordinates, or browse for raster\n",
    "2. **Configure Analysis** - Set thresholds and time periods\n",
    "3. **Extract Data** - Get time series from Google Earth Engine\n",
    "4. **Explore Dataset** - Examine structure with inline plots\n",
    "5. **Run Analysis** - Calculate metrics with inline visualization\n",
    "6. **Export Results** - Save to ../outputs with inline preview\n",
    "\n",
    "### üöÄ **Performance Benefits:**\n",
    "- **Extract once, analyze many times** - No repeated GEE API calls\n",
    "- **Fast local analysis** - xarray operations are vectorized\n",
    "- **Easy iteration** - Test different thresholds instantly\n",
    "- **Complete spatial data** - Every pixel value exported\n",
    "\n",
    "This version provides the ideal user experience with file browsers, inline visualization, and complete data export capabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes to self - at 35 degrees or 90% percentile, only max 6 days per year extreme, relative to a reference period of 10 years and 15 day moving window\n",
    "# the current implementation in this notebook calculates percentiles across the whole year - which will give false 'hot periods'\n",
    "# as the colder days in the winter drag the averages down. we actually need a moving window so that the percentiles are calculated against\n",
    "# the same period in the reference period. 5 days is quite short, perhaps we could allow the user to adjust, 10 or 15 days too?\n",
    "# question is how useful is this kind of analysis. What if the user picks a year for analysis that was not particularly hot?\n",
    "# is there a way of forcing the tool to select a few recent 'hot' year\n",
    "# or is there a better metric that shows both the current / most recent number of extreme heat days per year, Plus the trend i.e., in crease\n",
    "# in extreme heat days, and also an indication of the year within the last 10 years that had the most extreme heat days?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
