{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ¡ï¸ Climate Analysis with xarray - Complete Version\n",
    "\n",
    "This notebook demonstrates the xarray approach to climate analysis with:\n",
    "- File browser for raster upload\n",
    "- Inline plots within notebook cells\n",
    "- Full ROI selection tools (drawing, coordinates, raster upload)\n",
    "- Data exploration before analysis\n",
    "- Export to ../outputs directory\n",
    "\n",
    "## Key Features:\n",
    "- âš¡ **Fast analysis**: No repeated GEE API calls\n",
    "- ğŸ”§ **Data exploration**: Examine xarray structure before analysis\n",
    "- ğŸ“Š **Inline plots**: All visualizations appear in notebook cells\n",
    "- ğŸ¯ **File browser**: Easy raster file selection\n",
    "- ğŸ“ **Full pixel export**: Every individual pixel value preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_7TDKVSyKvBdmMqW?ref=4i2o6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Earth Engine initialized successfully\n",
      "ğŸ“¦ Available packages:\n",
      "   - xarray: 2024.7.0\n",
      "   - pandas: 2.3.1\n",
      "   - numpy: 1.26.4\n",
      "ğŸ“ Created outputs directory: ../outputs\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import ee\n",
    "import geemap\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import rasterio\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Initialize Earth Engine with your project\n",
    "try:\n",
    "    ee.Initialize(project='tl-cities')\n",
    "    print('âœ… Earth Engine initialized successfully')\n",
    "except Exception as e:\n",
    "    print(f'âŒ Earth Engine initialization failed: {e}')\n",
    "\n",
    "print('ğŸ“¦ Available packages:')\n",
    "print(f'   - xarray: {xr.__version__}')\n",
    "print(f'   - pandas: {pd.__version__}')\n",
    "print(f'   - numpy: {np.__version__}')\n",
    "\n",
    "# Create outputs directory\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "print('ğŸ“ Created outputs directory: ../outputs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 1: Enhanced ROI Selection with File Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd00bd04ca5444ef867848f817013c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ğŸ¯ ROI Selection - Enhanced with File Browser</h3>'), HTML(value='<b>Method 1: Dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fa234c5e754f42b2c2c9f2c9d4f55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-12.9714, -38.5014], controls=(WidgetControl(options=['position', 'transparent_bg'], position='topâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Enhanced ROI Selection Ready with File Browser\n",
      "ğŸ”§ Improved CRS handling and coordinate validation\n",
      "Choose any method to define your region of interest\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "analysis_geom = None\n",
    "temperature_data = None\n",
    "\n",
    "# Create map for ROI selection\n",
    "m = geemap.Map(center=[-12.9714, -38.5014], zoom=10)  # Salvador, Brazil\n",
    "m.add_basemap('SATELLITE')\n",
    "m.add('draw_control')\n",
    "\n",
    "def set_roi_from_drawing():\n",
    "    '''Extract ROI from map drawing'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        if hasattr(m, 'draw_control') and len(m.draw_control.data) > 0:\n",
    "            # Get the last drawn feature\n",
    "            feature = m.draw_control.data[-1]\n",
    "            coords = feature['geometry']['coordinates']\n",
    "            \n",
    "            if feature['geometry']['type'] == 'Polygon':\n",
    "                analysis_geom = ee.Geometry.Polygon(coords)\n",
    "            elif feature['geometry']['type'] == 'Rectangle':\n",
    "                analysis_geom = ee.Geometry.Rectangle(coords)\n",
    "            \n",
    "            area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "            bounds_info = analysis_geom.bounds().getInfo()['coordinates'][0]\n",
    "            west, south = bounds_info[0]\n",
    "            east, north = bounds_info[2]\n",
    "            \n",
    "            print(f'âœ… ROI set from drawing: {area_km2:.1f} kmÂ²')\n",
    "            print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            return True\n",
    "        else:\n",
    "            print('âŒ No drawing found. Please draw a polygon or rectangle on the map.')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error setting ROI from drawing: {e}')\n",
    "        return False\n",
    "\n",
    "def set_roi_from_coordinates():\n",
    "    '''Set ROI from coordinate inputs'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        west = float(west_input.value) if west_input.value else -38.7\n",
    "        east = float(east_input.value) if east_input.value else -38.3\n",
    "        south = float(south_input.value) if south_input.value else -13.1\n",
    "        north = float(north_input.value) if north_input.value else -12.8\n",
    "        \n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north])\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        # Add rectangle to map with proper visualization\n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['red'], 'max': 1}, 'ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'âœ… ROI set from coordinates: {area_km2:.1f} kmÂ²')\n",
    "        print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error setting ROI from coordinates: {e}')\n",
    "        return False\n",
    "\n",
    "def browse_raster_file():\n",
    "    '''Open file browser to select raster file'''\n",
    "    try:\n",
    "        # Create a temporary tkinter root window\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()  # Hide the root window\n",
    "        \n",
    "        # Open file dialog\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title='Select Reference Raster File',\n",
    "            filetypes=[\n",
    "                ('Raster files', '*.tif *.tiff *.img *.nc *.hdf *.jp2'),\n",
    "                ('GeoTIFF', '*.tif *.tiff'),\n",
    "                ('NetCDF', '*.nc'),\n",
    "                ('All files', '*.*')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        root.destroy()  # Clean up\n",
    "        \n",
    "        if file_path:\n",
    "            raster_path_display.value = file_path\n",
    "            print(f'ğŸ“ Selected file: {os.path.basename(file_path)}')\n",
    "            print(f'    Full path: {file_path}')\n",
    "            return file_path\n",
    "        else:\n",
    "            print('âŒ No file selected')\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error opening file browser: {e}')\n",
    "        print('   Note: File browser requires GUI environment')\n",
    "        return None\n",
    "\n",
    "def set_roi_from_raster():\n",
    "    '''Set ROI from selected raster extent with proper CRS handling'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        raster_path = raster_path_display.value.strip()\n",
    "        \n",
    "        if not raster_path or not os.path.exists(raster_path):\n",
    "            print('âŒ Please select a valid raster file first')\n",
    "            return False\n",
    "        \n",
    "        print(f'ğŸ“– Reading raster: {os.path.basename(raster_path)}')\n",
    "        \n",
    "        # Read raster bounds and CRS information\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "            shape = src.shape\n",
    "            transform = src.transform\n",
    "            \n",
    "            # Get bounds in original CRS\n",
    "            west, south, east, north = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "            \n",
    "            print(f'   ğŸ“Š Raster info:')\n",
    "            print(f'      CRS: {crs}')\n",
    "            print(f'      Shape: {shape}')\n",
    "            print(f'      Original bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            \n",
    "            # Transform to WGS84 if needed\n",
    "            if crs.to_epsg() != 4326:\n",
    "                from rasterio.warp import transform_bounds\n",
    "                west_wgs84, south_wgs84, east_wgs84, north_wgs84 = transform_bounds(\n",
    "                    crs, 'EPSG:4326', west, south, east, north\n",
    "                )\n",
    "                print(f'      Transformed to WGS84:')\n",
    "                print(f'      WGS84 bounds: W={west_wgs84:.6f}, E={east_wgs84:.6f}, S={south_wgs84:.6f}, N={north_wgs84:.6f}')\n",
    "                west, south, east, north = west_wgs84, south_wgs84, east_wgs84, north_wgs84\n",
    "            else:\n",
    "                print(f'      Already in WGS84')\n",
    "        \n",
    "        # Validate bounds are reasonable\n",
    "        if abs(west) > 180 or abs(east) > 180 or abs(south) > 90 or abs(north) > 90:\n",
    "            print(f'âŒ Invalid bounds detected - coordinates out of valid range')\n",
    "            print(f'   This suggests a CRS projection issue')\n",
    "            return False\n",
    "        \n",
    "        if west >= east or south >= north:\n",
    "            print(f'âŒ Invalid bounds - west >= east or south >= north')\n",
    "            return False\n",
    "        \n",
    "        # Create geometry in WGS84\n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north], 'EPSG:4326')\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        # Add to map with proper visualization\n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['blue'], 'max': 1}, 'Raster ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'   âœ… ROI set from raster extent: {area_km2:.1f} kmÂ²')\n",
    "        print(f'   Final WGS84 bounds: W={west:.6f}, E={east:.6f}, S={south:.6f}, N={north:.6f}')\n",
    "        \n",
    "        # Test if ROI overlaps with GSHTD data coverage\n",
    "        test_centroid = analysis_geom.centroid().coordinates().getInfo()\n",
    "        test_lon, test_lat = test_centroid[0], test_centroid[1]\n",
    "        print(f'   ğŸ¯ ROI center: {test_lat:.3f}Â°N, {test_lon:.3f}Â°E')\n",
    "        \n",
    "        # Check if in valid GSHTD coverage areas\n",
    "        valid_coverage = False\n",
    "        if test_lat > 15 and test_lon > -140 and test_lon < -40:  # North America\n",
    "            print(f'   ğŸŒ ROI appears to be in North America coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat < 35 and test_lon > -120 and test_lon < -30:  # Latin America  \n",
    "            print(f'   ğŸŒ ROI appears to be in Latin America coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat > 30 and test_lon > -15 and test_lon < 180:  # Europe & Asia\n",
    "            print(f'   ğŸŒ ROI appears to be in Europe/Asia coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat < 40 and test_lon > -20 and test_lon < 55:  # Africa\n",
    "            print(f'   ğŸŒ ROI appears to be in Africa coverage')\n",
    "            valid_coverage = True\n",
    "        elif test_lat < -5 and test_lon > 110 and test_lon < 180:  # Australia\n",
    "            print(f'   ğŸŒ ROI appears to be in Australia coverage')\n",
    "            valid_coverage = True\n",
    "        \n",
    "        if not valid_coverage:\n",
    "            print(f'   âš ï¸ Warning: ROI may be outside GSHTD coverage areas')\n",
    "            print(f'   âš ï¸ GSHTD covers: North America, Latin America, Europe/Asia, Africa, Australia')\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error setting ROI from raster: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "# ROI input widgets\n",
    "west_input = widgets.FloatText(value=-38.7, description='West:')\n",
    "east_input = widgets.FloatText(value=-38.3, description='East:')\n",
    "south_input = widgets.FloatText(value=-13.1, description='South:')\n",
    "north_input = widgets.FloatText(value=-12.8, description='North:')\n",
    "\n",
    "# File browser widgets\n",
    "raster_path_display = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='No file selected...',\n",
    "    description='Selected File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    disabled=True  # Read-only display\n",
    ")\n",
    "\n",
    "browse_button = widgets.Button(\n",
    "    description='ğŸ“‚ Browse Files',\n",
    "    button_style='info',\n",
    "    tooltip='Click to select a raster file'\n",
    ")\n",
    "browse_button.on_click(lambda b: browse_raster_file())\n",
    "\n",
    "# Action buttons\n",
    "set_drawing_button = widgets.Button(description='ğŸ“ Use Drawing', button_style='success')\n",
    "set_coords_button = widgets.Button(description='ğŸ“ Use Coordinates', button_style='info')\n",
    "set_raster_button = widgets.Button(description='ğŸ“ Use Raster Extent', button_style='warning')\n",
    "\n",
    "set_drawing_button.on_click(lambda b: set_roi_from_drawing())\n",
    "set_coords_button.on_click(lambda b: set_roi_from_coordinates())\n",
    "set_raster_button.on_click(lambda b: set_roi_from_raster())\n",
    "\n",
    "roi_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>ğŸ¯ ROI Selection - Enhanced with File Browser</h3>'),\n",
    "    \n",
    "    widgets.HTML('<b>Method 1: Draw on Map</b>'),\n",
    "    widgets.HTML('Draw a polygon or rectangle on the map below, then click:'),\n",
    "    set_drawing_button,\n",
    "    \n",
    "    widgets.HTML('<b>Method 2: Enter Coordinates</b>'),\n",
    "    widgets.HBox([west_input, east_input]),\n",
    "    widgets.HBox([south_input, north_input]),\n",
    "    set_coords_button,\n",
    "    \n",
    "    widgets.HTML('<b>Method 3: Use Raster File Extent</b>'),\n",
    "    widgets.HTML('Click Browse to select a reference raster file:'),\n",
    "    widgets.HBox([browse_button, raster_path_display]),\n",
    "    set_raster_button\n",
    "])\n",
    "\n",
    "display(roi_interface)\n",
    "display(m)\n",
    "\n",
    "print('ğŸ¯ Enhanced ROI Selection Ready with File Browser')\n",
    "print('ğŸ”§ Improved CRS handling and coordinate validation')\n",
    "print('Choose any method to define your region of interest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 2: Analysis Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14ff904ea2d4d1aa15218f3c19fd641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ğŸ“Š Analysis Configuration</h3>'), HTML(value='<div style=\"background-color: #fffâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Configuration Ready\n"
     ]
    }
   ],
   "source": [
    "# Analysis configuration\n",
    "analysis_year = widgets.IntSlider(value=2020, min=2003, max=2020, description='Analysis Year:')\n",
    "reference_start = widgets.IntSlider(value=2010, min=2003, max=2019, description='Reference Start:')\n",
    "reference_end = widgets.IntSlider(value=2019, min=2004, max=2020, description='Reference End:')\n",
    "absolute_threshold = widgets.FloatSlider(value=35.0, min=20.0, max=45.0, step=0.5, description='Threshold (Â°C):')\n",
    "percentile_threshold = widgets.FloatSlider(value=95.0, min=50.0, max=99.0, step=1.0, description='Percentile:')\n",
    "\n",
    "config_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>ğŸ“Š Analysis Configuration</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>Note:</b> High thresholds (35Â°C, 95th percentile) may result in few/zero heat days ' +\n",
    "                'in some regions. This is scientifically valid for climatological extremes.</div>'),\n",
    "    analysis_year,\n",
    "    widgets.HBox([reference_start, reference_end]),\n",
    "    widgets.HBox([absolute_threshold, percentile_threshold])\n",
    "])\n",
    "\n",
    "display(config_interface)\n",
    "print('ğŸ“Š Configuration Ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Step 3: Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9121d8c52ac641d4a69984e27364b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='ğŸ”„ Extract Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Ready to extract pixel-level temperature data using temporal chunking\n",
      "ğŸ¯ Maintains 1km resolution for intra-urban analysis\n",
      "âš¡ Extracts year-by-year to avoid GEE limits\n"
     ]
    }
   ],
   "source": [
    "def extract_temperature_data():\n",
    "    '''Extract temperature data from GSHTD using temporal chunking for 1km resolution'''\n",
    "    global temperature_data, analysis_geom\n",
    "    \n",
    "    if analysis_geom is None:\n",
    "        print('âŒ Please set an ROI first!')\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print('ğŸ”„ Extracting temperature data from GSHTD with temporal chunking for 1km resolution...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        \n",
    "        # Debug ROI information\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        bounds = analysis_geom.bounds().getInfo()\n",
    "        print(f'   ğŸ“ ROI area: {area_km2:.2f} kmÂ²')\n",
    "        print(f'   ğŸ—ºï¸ ROI bounds: {bounds}')\n",
    "        \n",
    "        # Function to get regional collection based on location\n",
    "        def get_region_collection(geom):\n",
    "            \"\"\"Determine which regional GSHTD collection to use based on geometry location\"\"\"\n",
    "            centroid = geom.centroid().coordinates().getInfo()\n",
    "            lon, lat = centroid[0], centroid[1]\n",
    "            \n",
    "            if lat > 15 and lon > -140 and lon < -40:  # North America\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"\n",
    "            elif lat < 35 and lon > -120 and lon < -30:  # Latin America  \n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/latin_america\"\n",
    "            elif lat > 30 and lon > -15 and lon < 180:  # Europe & Asia\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/europe_asia\"\n",
    "            elif lat < 40 and lon > -20 and lon < 55:  # Africa\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/africa\"\n",
    "            elif lat < -5 and lon > 110 and lon < 180:  # Australia\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/australia\"\n",
    "            else:\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"  # Default\n",
    "        \n",
    "        # Function to get temperature collection - FIXED: No longer applying scaling here\n",
    "        def get_temperature_collection(region_geom, start_date, end_date, temp_type='tmax'):\n",
    "            \"\"\"Get daily air temperature collection for the specified region and period\"\"\"\n",
    "            collection_id = get_region_collection(region_geom)\n",
    "            print(f'   ğŸ“¡ Using collection: {collection_id.split(\"/\")[-1]}')\n",
    "            \n",
    "            collection = ee.ImageCollection(collection_id)\n",
    "            \n",
    "            # Filter by date, bounds, and temperature type using prop_type metadata\n",
    "            filtered_collection = (collection.filterDate(start_date, end_date)\n",
    "                                 .filterBounds(region_geom)\n",
    "                                 .filter(ee.Filter.eq('prop_type', temp_type)))\n",
    "            \n",
    "            # FIXED: Just select and clip, don't apply scaling here since getRegion handles raw values\n",
    "            temp_collection = filtered_collection.map(lambda img: \n",
    "                img.select('b1')\n",
    "                  .clip(region_geom)\n",
    "                  .copyProperties(img, ['system:time_start'])\n",
    "            )\n",
    "            \n",
    "            return temp_collection\n",
    "        \n",
    "        # Test pixel count at 1km resolution\n",
    "        test_collection = get_temperature_collection(analysis_geom, f'{year}-01-01', f'{year}-01-02', 'tmax')\n",
    "        \n",
    "        if test_collection.size().getInfo() == 0:\n",
    "            print('âŒ No images found for test date - check ROI coverage')\n",
    "            return False\n",
    "        \n",
    "        first_image = test_collection.first()\n",
    "        pixel_count = first_image.select('b1').reduceRegion(\n",
    "            reducer=ee.Reducer.count(),\n",
    "            geometry=analysis_geom,\n",
    "            scale=1000,  # 1km resolution\n",
    "            maxPixels=1e9\n",
    "        ).getInfo()\n",
    "        \n",
    "        expected_pixels = pixel_count.get('b1', 0)\n",
    "        print(f'   ğŸ” Expected pixels per image at 1km: {expected_pixels}')\n",
    "        \n",
    "        if expected_pixels == 0:\n",
    "            print('âŒ No pixels found in ROI - check if ROI overlaps with data coverage')\n",
    "            return False\n",
    "        \n",
    "        # Calculate years to extract\n",
    "        years_to_extract = list(range(ref_start, ref_end + 1)) + [year]\n",
    "        years_to_extract = sorted(list(set(years_to_extract)))  # Remove duplicates and sort\n",
    "        \n",
    "        print(f'   ğŸ“… Will extract {len(years_to_extract)} years: {years_to_extract}')\n",
    "        print(f'   ğŸ¯ Using temporal chunking to maintain 1km resolution')\n",
    "        \n",
    "        # Extract data year by year\n",
    "        all_dataframes = []\n",
    "        \n",
    "        for extract_year in years_to_extract:\n",
    "            print(f'\\\\n   ğŸ“… Extracting year {extract_year}...')\n",
    "            \n",
    "            year_collection = get_temperature_collection(\n",
    "                analysis_geom, f'{extract_year}-01-01', f'{extract_year}-12-31', 'tmax'\n",
    "            )\n",
    "            \n",
    "            year_size = year_collection.size().getInfo()\n",
    "            estimated_values = expected_pixels * year_size\n",
    "            \n",
    "            print(f'      Images: {year_size}, Estimated values: {estimated_values:,}')\n",
    "            \n",
    "            if estimated_values > 900000:  # Still too large\n",
    "                print(f'      âš ï¸ Still too large for single year, using 2km scale')\n",
    "                scale = 2000\n",
    "            else:\n",
    "                print(f'      âœ… Using 1km scale')\n",
    "                scale = 1000\n",
    "            \n",
    "            try:\n",
    "                region_data = year_collection.getRegion(\n",
    "                    geometry=analysis_geom,\n",
    "                    scale=scale,\n",
    "                    crs='EPSG:4326'\n",
    "                ).getInfo()\n",
    "                \n",
    "                print(f'      âœ… Extracted {len(region_data)} rows')\n",
    "                \n",
    "                if len(region_data) > 1:  # More than just header\n",
    "                    header = region_data[0]\n",
    "                    data = region_data[1:]\n",
    "                    \n",
    "                    df_year = pd.DataFrame(data, columns=header)\n",
    "                    df_year['time'] = pd.to_datetime(df_year['time'], unit='ms')\n",
    "                    \n",
    "                    # FIXED: Apply temperature scaling and rename column BEFORE dropping nulls\n",
    "                    if 'b1' in df_year.columns:\n",
    "                        df_year['temperature'] = df_year['b1'] / 10.0  # Scale to Celsius\n",
    "                        df_year = df_year.drop(columns=['b1'])  # Remove original column\n",
    "                    \n",
    "                    # Now drop nulls from the correctly named temperature column\n",
    "                    df_year = df_year.dropna(subset=['temperature'])\n",
    "                    \n",
    "                    print(f'      ğŸ“Š Valid observations: {len(df_year)}')\n",
    "                    \n",
    "                    if len(df_year) > 0:\n",
    "                        all_dataframes.append(df_year)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'      âŒ Failed to extract {extract_year}: {e}')\n",
    "                continue\n",
    "        \n",
    "        if not all_dataframes:\n",
    "            print('âŒ No data extracted for any year')\n",
    "            return False\n",
    "        \n",
    "        # Combine all years\n",
    "        print(f'\\\\n   ğŸ”— Combining {len(all_dataframes)} years of data...')\n",
    "        df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        \n",
    "        print(f'   ğŸ“Š Total combined data: {len(df)} observations')\n",
    "        \n",
    "        unique_pixels = df[['longitude', 'latitude']].drop_duplicates()\n",
    "        print(f'   ğŸ“ Unique spatial pixels: {len(unique_pixels)}')\n",
    "        print(f'   ğŸŒ¡ï¸ Temperature range: {df[\"temperature\"].min():.1f}Â°C to {df[\"temperature\"].max():.1f}Â°C')\n",
    "        print(f'   ğŸ“ Resolution achieved: {scale}m')\n",
    "        \n",
    "        # Show sample of the data\n",
    "        print('\\\\nğŸ“‹ Sample of extracted data:')\n",
    "        print(df[['time', 'latitude', 'longitude', 'temperature']].head())\n",
    "        \n",
    "        # Convert to xarray\n",
    "        try:\n",
    "            temperature_data = df.set_index(['time', 'latitude', 'longitude']).to_xarray()\n",
    "            \n",
    "            print(f'\\\\nâœ… Xarray dataset created successfully!')\n",
    "            print(f'   ğŸ“… Time range: {temperature_data.time.min().values} to {temperature_data.time.max().values}')\n",
    "            print(f'   ğŸŒ Spatial dimensions: {temperature_data.dims[\"latitude\"]} Ã— {temperature_data.dims[\"longitude\"]} pixels')\n",
    "            print(f'   ğŸ“Š Total observations: {temperature_data.temperature.count().values}')\n",
    "            print(f'   ğŸ¯ Dataset: GSHTD Daily Air Temperature at {scale}m resolution')\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'âŒ Error converting to xarray: {e}')\n",
    "            print('   Raw DataFrame saved as backup for debugging')\n",
    "            globals()['debug_df'] = df\n",
    "            return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error extracting data: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "extract_button = widgets.Button(description='ğŸ”„ Extract Data', button_style='primary')\n",
    "extract_button.on_click(lambda b: extract_temperature_data())\n",
    "\n",
    "display(extract_button)\n",
    "print('ğŸ”„ Ready to extract pixel-level temperature data using temporal chunking')\n",
    "print('ğŸ¯ Maintains 1km resolution for intra-urban analysis')\n",
    "print('âš¡ Extracts year-by-year to avoid GEE limits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Step 3.5: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaebdfaa75d44992af19f8e33622b1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='ğŸ” Explore Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Click to explore your extracted xarray dataset with inline plots\n",
      "ğŸ›¡ï¸ Enhanced with better error handling for small datasets\n"
     ]
    }
   ],
   "source": [
    "def explore_temperature_data():\n",
    "    '''Explore the extracted temperature xarray dataset with inline visualization'''\n",
    "    global temperature_data\n",
    "    \n",
    "    if temperature_data is None:\n",
    "        print('âŒ Please extract temperature data first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('ğŸ” EXPLORING TEMPERATURE XARRAY DATASET')\n",
    "        print('='*50)\n",
    "        \n",
    "        # Dataset overview\n",
    "        print('ğŸ“Š DATASET OVERVIEW:')\n",
    "        print(f'   Data variables: {list(temperature_data.data_vars)}')\n",
    "        print(f'   Coordinates: {list(temperature_data.coords)}')\n",
    "        print(f'   Dimensions: {dict(temperature_data.dims)}')\n",
    "        print(f'   Size in memory: {temperature_data.nbytes / 1024**2:.1f} MB')\n",
    "        \n",
    "        # Check if we have valid spatial dimensions\n",
    "        if 'latitude' not in temperature_data.dims or 'longitude' not in temperature_data.dims:\n",
    "            print('âŒ Missing spatial dimensions (latitude/longitude)')\n",
    "            return\n",
    "            \n",
    "        if len(temperature_data.latitude) == 0 or len(temperature_data.longitude) == 0:\n",
    "            print('âŒ Empty spatial dimensions')\n",
    "            return\n",
    "        \n",
    "        # Spatial coverage\n",
    "        lats = temperature_data.latitude.values\n",
    "        lons = temperature_data.longitude.values\n",
    "        print(f'\\\\nğŸŒ SPATIAL COVERAGE:')\n",
    "        print(f'   Latitude range: {lats.min():.3f} to {lats.max():.3f}')\n",
    "        print(f'   Longitude range: {lons.min():.3f} to {lons.max():.3f}')\n",
    "        print(f'   Number of spatial pixels: {len(lats) * len(lons)}')\n",
    "        \n",
    "        # Temperature statistics\n",
    "        temp_vals = temperature_data.temperature.values\n",
    "        temp_vals_clean = temp_vals[~np.isnan(temp_vals)]\n",
    "        \n",
    "        if len(temp_vals_clean) == 0:\n",
    "            print('âŒ No valid temperature values found')\n",
    "            return\n",
    "            \n",
    "        print(f'\\\\nğŸŒ¡ï¸ TEMPERATURE STATISTICS:')\n",
    "        print(f'   Valid values: {len(temp_vals_clean):,} of {temp_vals.size:,} total')\n",
    "        print(f'   Temperature range: {temp_vals_clean.min():.1f}Â°C to {temp_vals_clean.max():.1f}Â°C')\n",
    "        print(f'   Mean temperature: {temp_vals_clean.mean():.1f}Â°C')\n",
    "        \n",
    "        # Check thresholds\n",
    "        abs_thresh = absolute_threshold.value\n",
    "        pct_thresh = percentile_threshold.value\n",
    "        overall_percentile = np.percentile(temp_vals_clean, pct_thresh)\n",
    "        \n",
    "        print(f'\\\\nâš ï¸ THRESHOLD ANALYSIS:')\n",
    "        print(f'   Absolute threshold: {abs_thresh}Â°C')\n",
    "        print(f'   {pct_thresh}th percentile: {overall_percentile:.1f}Â°C')\n",
    "        \n",
    "        values_above_abs = (temp_vals_clean > abs_thresh).sum()\n",
    "        values_above_pct = (temp_vals_clean > overall_percentile).sum()\n",
    "        \n",
    "        print(f'   Values above {abs_thresh}Â°C: {values_above_abs:,} ({values_above_abs/len(temp_vals_clean)*100:.1f}%)')\n",
    "        print(f'   Values above {pct_thresh}th percentile: {values_above_pct:,} ({values_above_pct/len(temp_vals_clean)*100:.1f}%)')\n",
    "        \n",
    "        if values_above_abs < 10 and values_above_pct < 10:\n",
    "            print('   ğŸš¨ WARNING: Very few values exceed your thresholds!')\n",
    "            print('   ğŸš¨ Results may have many zero heat days (this may be scientifically correct)')\n",
    "        \n",
    "        # Create inline visualization with error handling\n",
    "        print('\\\\nğŸ“Š CREATING EXPLORATION PLOTS...')\n",
    "        \n",
    "        try:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "            \n",
    "            # Temperature histogram\n",
    "            axes[0,0].hist(temp_vals_clean, bins=min(50, len(temp_vals_clean)//10), alpha=0.7, color='skyblue', edgecolor='black')\n",
    "            axes[0,0].axvline(abs_thresh, color='red', linestyle='--', linewidth=2, label=f'Absolute threshold ({abs_thresh}Â°C)')\n",
    "            axes[0,0].axvline(overall_percentile, color='orange', linestyle='--', linewidth=2, label=f'{pct_thresh}th percentile ({overall_percentile:.1f}Â°C)')\n",
    "            axes[0,0].set_title('Temperature Distribution')\n",
    "            axes[0,0].set_xlabel('Temperature (Â°C)')\n",
    "            axes[0,0].set_ylabel('Frequency')\n",
    "            axes[0,0].legend()\n",
    "            axes[0,0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Sample time series - handle single pixel case\n",
    "            if len(lats) > 0 and len(lons) > 0:\n",
    "                sample_lat = lats[len(lats)//2] if len(lats) > 1 else lats[0]\n",
    "                sample_lon = lons[len(lons)//2] if len(lons) > 1 else lons[0]\n",
    "                sample_pixel = temperature_data.sel(latitude=sample_lat, longitude=sample_lon, method='nearest')\n",
    "                \n",
    "                if len(sample_pixel.temperature.dropna('time')) > 0:\n",
    "                    sample_pixel.temperature.plot(ax=axes[0,1], linewidth=1, alpha=0.7)\n",
    "                    axes[0,1].axhline(abs_thresh, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({abs_thresh}Â°C)')\n",
    "                    axes[0,1].set_title(f'Sample Pixel Time Series\\\\n({sample_lat:.3f}Â°, {sample_lon:.3f}Â°)')\n",
    "                    axes[0,1].set_ylabel('Temperature (Â°C)')\n",
    "                    axes[0,1].legend()\n",
    "                    axes[0,1].grid(True, alpha=0.3)\n",
    "                else:\n",
    "                    axes[0,1].text(0.5, 0.5, 'No valid data\\\\nfor sample pixel', ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "                    axes[0,1].set_title('Sample Pixel Time Series - No Data')\n",
    "            \n",
    "            # Spatial temperature mean - handle single pixel case\n",
    "            temp_mean = temperature_data.temperature.mean(dim='time')\n",
    "            if len(lats) > 1 and len(lons) > 1:\n",
    "                temp_mean.plot(ax=axes[1,0], cmap='RdYlBu_r', add_colorbar=True, cbar_kwargs={'label': 'Mean Temperature (Â°C)'})\n",
    "                axes[1,0].set_title('Spatial Mean Temperature')\n",
    "                axes[1,0].set_xlabel('Longitude')\n",
    "                axes[1,0].set_ylabel('Latitude')\n",
    "            else:\n",
    "                # For single pixel, show as text\n",
    "                mean_temp = temp_mean.values.item() if temp_mean.size == 1 else np.nanmean(temp_mean.values)\n",
    "                axes[1,0].text(0.5, 0.5, f'Single Pixel\\\\nMean: {mean_temp:.1f}Â°C', ha='center', va='center', transform=axes[1,0].transAxes, fontsize=14)\n",
    "                axes[1,0].set_title('Spatial Mean Temperature')\n",
    "            \n",
    "            # Monthly temperature cycle\n",
    "            try:\n",
    "                monthly_temps = temperature_data.temperature.groupby('time.month').mean()\n",
    "                monthly_avg = monthly_temps.mean(dim=['latitude', 'longitude'])\n",
    "                monthly_avg.plot(ax=axes[1,1], marker='o', linewidth=2)\n",
    "                axes[1,1].axhline(abs_thresh, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({abs_thresh}Â°C)')\n",
    "                axes[1,1].set_title('Monthly Temperature Cycle')\n",
    "                axes[1,1].set_xlabel('Month')\n",
    "                axes[1,1].set_ylabel('Temperature (Â°C)')\n",
    "                axes[1,1].legend()\n",
    "                axes[1,1].grid(True, alpha=0.3)\n",
    "            except Exception as e:\n",
    "                axes[1,1].text(0.5, 0.5, f'Error creating\\\\nmonthly plot:\\\\n{str(e)[:50]}', ha='center', va='center', transform=axes[1,1].transAxes)\n",
    "                axes[1,1].set_title('Monthly Temperature Cycle - Error')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'âŒ Error creating plots: {e}')\n",
    "            import traceback\n",
    "            print(f'   Details: {traceback.format_exc()}')\n",
    "        \n",
    "        print('\\\\nâœ… Data exploration complete!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error in data exploration: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "explore_button = widgets.Button(description='ğŸ” Explore Data', button_style='info')\n",
    "explore_button.on_click(lambda b: explore_temperature_data())\n",
    "\n",
    "display(explore_button)\n",
    "print('ğŸ” Click to explore your extracted xarray dataset with inline plots')\n",
    "print('ğŸ›¡ï¸ Enhanced with better error handling for small datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 4: Analysis with Inline Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c22109b80947bd93b226fd7364bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='ğŸ“ˆ Calculate & Visualize', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ Ready to calculate climate metrics with inline visualization\n",
      "ğŸ”§ Fixed to properly store results for export\n",
      "ğŸ› Added debug output to trace heat days calculation issue\n"
     ]
    }
   ],
   "source": [
    "def calculate_and_visualize_metrics():\n",
    "    '''Calculate climate metrics and create inline visualizations'''\n",
    "    global temperature_data, analysis_results\n",
    "    \n",
    "    if temperature_data is None:\n",
    "        print('âŒ Please extract temperature data first!')\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print('ğŸ“ˆ Calculating climate metrics with inline visualization...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        abs_threshold = absolute_threshold.value\n",
    "        pct_threshold = percentile_threshold.value\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Filter data\n",
    "        analysis_data = temperature_data.sel(time=str(year))\n",
    "        reference_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{ref_end}-12-31'))\n",
    "        \n",
    "        print(f'   ğŸ“… Analysis year: {len(analysis_data.time)} days')\n",
    "        print(f'   ğŸ“… Reference period: {len(reference_data.time)} days')\n",
    "        \n",
    "        # DEBUG: Check analysis data\n",
    "        print(f'\\nğŸ” DEBUG - Analysis data for {year}:')\n",
    "        print(f'   Analysis data shape: {analysis_data.temperature.shape}')\n",
    "        print(f'   Analysis temp range: {analysis_data.temperature.min().values:.1f} to {analysis_data.temperature.max().values:.1f}Â°C')\n",
    "        print(f'   Analysis data sample dates: {analysis_data.time[:3].values}')\n",
    "        \n",
    "        # Calculate reference percentile\n",
    "        print(f'   ğŸ§® Calculating {pct_threshold}th percentile...')\n",
    "        reference_percentile = reference_data.temperature.quantile(pct_threshold/100, dim='time')\n",
    "        results['reference_percentile'] = reference_percentile\n",
    "        \n",
    "        # Heat Days calculation with DEBUG\n",
    "        print('   ğŸ”¥ Calculating heat days...')\n",
    "        threshold = xr.where(\n",
    "            reference_percentile > abs_threshold,\n",
    "            reference_percentile,\n",
    "            abs_threshold\n",
    "        )\n",
    "        \n",
    "        # DEBUG: Check threshold calculation\n",
    "        print(f'\\nğŸ” DEBUG - Threshold calculation:')\n",
    "        print(f'   Reference percentile range: {reference_percentile.min().values:.1f} to {reference_percentile.max().values:.1f}Â°C')\n",
    "        print(f'   Absolute threshold: {abs_threshold}Â°C')\n",
    "        print(f'   Final threshold range: {threshold.min().values:.1f} to {threshold.max().values:.1f}Â°C')\n",
    "        \n",
    "        # DEBUG: Check the comparison\n",
    "        print(f'\\nğŸ” DEBUG - Heat days calculation:')\n",
    "        temp_above_threshold = analysis_data.temperature > threshold\n",
    "        print(f'   Boolean comparison shape: {temp_above_threshold.shape}')\n",
    "        print(f'   Days above threshold (before sum): {temp_above_threshold.sum().values} total instances')\n",
    "        \n",
    "        # Check a specific pixel manually\n",
    "        if len(analysis_data.latitude) > 0 and len(analysis_data.longitude) > 0:\n",
    "            test_lat = analysis_data.latitude.values[0]\n",
    "            test_lon = analysis_data.longitude.values[0] \n",
    "            test_temps = analysis_data.temperature.sel(latitude=test_lat, longitude=test_lon)\n",
    "            test_threshold = threshold.sel(latitude=test_lat, longitude=test_lon)\n",
    "            test_above = (test_temps > test_threshold).sum()\n",
    "            \n",
    "            print(f'   Test pixel ({test_lat:.3f}, {test_lon:.3f}):')\n",
    "            print(f'     Temperature range: {test_temps.min().values:.1f} to {test_temps.max().values:.1f}Â°C')\n",
    "            print(f'     Threshold: {test_threshold.values:.1f}Â°C')\n",
    "            print(f'     Days above threshold: {test_above.values}')\n",
    "        \n",
    "        heat_days = (analysis_data.temperature > threshold).sum(dim='time').fillna(0)\n",
    "        print(f'   Final heat days range: {heat_days.min().values} to {heat_days.max().values}')\n",
    "        \n",
    "        results['heat_days'] = heat_days\n",
    "        results['threshold_used'] = threshold\n",
    "        \n",
    "        # Temperature Trends\n",
    "        print('   ğŸ“ˆ Calculating temperature trends...')\n",
    "        trends = reference_data.temperature.polyfit(dim='time', deg=1)\n",
    "        trend_slope = trends.polyfit_coefficients.sel(degree=1)\n",
    "        ns_per_year = 365.25 * 24 * 60 * 60 * 1e9\n",
    "        trend_per_year = (trend_slope * ns_per_year).fillna(0)\n",
    "        results['temperature_trend'] = trend_per_year\n",
    "        \n",
    "        # Seasonal Means\n",
    "        print('   ğŸŒ… Calculating seasonal means...')\n",
    "        seasonal_means = analysis_data.temperature.groupby('time.season').mean()\n",
    "        results['seasonal_means'] = seasonal_means\n",
    "        \n",
    "        # Annual extremes\n",
    "        print('   ğŸŒ¡ï¸ Calculating annual extremes...')\n",
    "        annual_max = analysis_data.temperature.max(dim='time').fillna(0)\n",
    "        annual_min = analysis_data.temperature.min(dim='time').fillna(0)\n",
    "        annual_range = (annual_max - annual_min).fillna(0)\n",
    "        \n",
    "        results['annual_max'] = annual_max\n",
    "        results['annual_min'] = annual_min\n",
    "        results['annual_range'] = annual_range\n",
    "        \n",
    "        print('\\\\nâœ… Climate metrics calculated successfully!')\n",
    "        \n",
    "        # Print summary\n",
    "        print(f'\\\\nğŸ“Š RESULTS SUMMARY:')\n",
    "        print(f'   Mean heat days: {heat_days.mean().values:.1f}')\n",
    "        print(f'   Max heat days: {heat_days.max().values:.0f}')\n",
    "        print(f'   Pixels with >0 heat days: {(heat_days > 0).sum().values} of {heat_days.count().values}')\n",
    "        print(f'   Mean temperature trend: {trend_per_year.mean().values:.3f} Â°C/year')\n",
    "        \n",
    "        # Create comprehensive inline visualization\n",
    "        print('\\\\nğŸ“Š CREATING RESULTS VISUALIZATION...')\n",
    "        \n",
    "        try:\n",
    "            fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "            \n",
    "            # Heat Days Map\n",
    "            heat_days.plot(ax=axes[0,0], cmap='Reds', add_colorbar=True, cbar_kwargs={'label': 'Heat Days'})\n",
    "            axes[0,0].set_title('Heat Days per Pixel', fontweight='bold')\n",
    "            \n",
    "            # Temperature Trends\n",
    "            trend_per_year.plot(ax=axes[0,1], cmap='RdBu_r', add_colorbar=True, cbar_kwargs={'label': 'Â°C/year'})\n",
    "            axes[0,1].set_title('Temperature Trends (Â°C/year)', fontweight='bold')\n",
    "            \n",
    "            # Annual Temperature Range\n",
    "            annual_range.plot(ax=axes[0,2], cmap='viridis', add_colorbar=True, cbar_kwargs={'label': 'Â°C'})\n",
    "            axes[0,2].set_title('Annual Temperature Range (Â°C)', fontweight='bold')\n",
    "            \n",
    "            # Time Series\n",
    "            daily_avg = analysis_data.temperature.mean(dim=['latitude', 'longitude'])\n",
    "            daily_avg.plot(ax=axes[1,0], linewidth=1.5, color='blue')\n",
    "            axes[1,0].axhline(abs_threshold, color='red', linestyle='--', alpha=0.7, label=f'Threshold ({abs_threshold}Â°C)')\n",
    "            axes[1,0].set_title(f'Daily Average Temperature - {year}', fontweight='bold')\n",
    "            axes[1,0].set_ylabel('Temperature (Â°C)')\n",
    "            axes[1,0].legend()\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Seasonal Means\n",
    "            seasonal_avg = seasonal_means.mean(dim=['latitude', 'longitude'])\n",
    "            seasonal_avg.plot.bar(ax=axes[1,1], color=['lightblue', 'lightgreen', 'orange', 'lightcoral'])\n",
    "            axes[1,1].set_title('Seasonal Temperature Means', fontweight='bold')\n",
    "            axes[1,1].set_ylabel('Temperature (Â°C)')\n",
    "            axes[1,1].tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Heat Days Distribution\n",
    "            heat_days_flat = heat_days.values.flatten()\n",
    "            heat_days_clean = heat_days_flat[~np.isnan(heat_days_flat)]\n",
    "            axes[1,2].hist(heat_days_clean, bins=20, alpha=0.7, color='red', edgecolor='black')\n",
    "            axes[1,2].set_title('Heat Days Distribution', fontweight='bold')\n",
    "            axes[1,2].set_xlabel('Heat Days per Pixel')\n",
    "            axes[1,2].set_ylabel('Frequency')\n",
    "            axes[1,2].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as viz_error:\n",
    "            print(f'âš ï¸ Visualization error (results still calculated): {viz_error}')\n",
    "        \n",
    "        print('\\\\nâœ… Analysis and visualization complete!')\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error calculating metrics: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return None\n",
    "\n",
    "# Fixed analyze button to properly set global variable\n",
    "analyze_button = widgets.Button(description='ğŸ“ˆ Calculate & Visualize', button_style='success')\n",
    "analysis_results = None\n",
    "\n",
    "def run_analysis_with_viz(button):\n",
    "    global analysis_results  # Make sure this is global\n",
    "    print('ğŸ”„ Starting analysis...')\n",
    "    analysis_results = calculate_and_visualize_metrics()\n",
    "    if analysis_results is not None:\n",
    "        print('âœ… Analysis results stored successfully!')\n",
    "        print('ğŸ“ Ready for export')\n",
    "    else:\n",
    "        print('âŒ Analysis failed - results not available for export')\n",
    "\n",
    "analyze_button.on_click(run_analysis_with_viz)\n",
    "\n",
    "display(analyze_button)\n",
    "print('ğŸ“ˆ Ready to calculate climate metrics with inline visualization')\n",
    "print('ğŸ”§ Fixed to properly store results for export')\n",
    "print('ğŸ› Added debug output to trace heat days calculation issue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Step 5: Export Results to ../outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb54b653bd4aee8429abbdfff0b021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='ğŸ“ Export to ../outputs', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Ready to export full pixel-level results to ../outputs directory\n",
      "ğŸŒ Fixed: NetCDF files now include proper WGS84 CRS information\n",
      "ğŸ”§ Fixed: CSV export now properly extracts values from analysis results\n"
     ]
    }
   ],
   "source": [
    "def export_results():\n",
    "    '''Export analysis results to ../outputs directory with proper CRS'''\n",
    "    global analysis_results, temperature_data\n",
    "    \n",
    "    if analysis_results is None:\n",
    "        print('âŒ Please run analysis first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('ğŸ“ Exporting results to ../outputs directory...')\n",
    "        year = analysis_year.value\n",
    "        \n",
    "        # Create outputs directory\n",
    "        os.makedirs('../outputs', exist_ok=True)\n",
    "        \n",
    "        # 1. Summary Table\n",
    "        print('   ğŸ“„ Creating summary statistics table...')\n",
    "        summary_data = []\n",
    "        \n",
    "        for metric_name, metric_data in analysis_results.items():\n",
    "            if hasattr(metric_data, 'mean') and len(metric_data.dims) <= 2:\n",
    "                try:\n",
    "                    if metric_name != 'seasonal_means':\n",
    "                        valid_count = metric_data.count().values\n",
    "                        if valid_count > 0:\n",
    "                            summary_data.append({\n",
    "                                'metric': metric_name,\n",
    "                                'valid_pixels': int(valid_count),\n",
    "                                'mean': float(metric_data.mean().values),\n",
    "                                'min': float(metric_data.min().values),\n",
    "                                'max': float(metric_data.max().values),\n",
    "                                'std': float(metric_data.std().values),\n",
    "                                'median': float(metric_data.median().values)\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f'     âš ï¸ Skipping {metric_name}: {e}')\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_filename = f'../outputs/climate_summary_{year}.csv'\n",
    "            summary_df.to_csv(summary_filename, index=False)\n",
    "            print(f'   âœ… Summary saved: {summary_filename}')\n",
    "            \n",
    "            # Display summary table inline\n",
    "            print('\\nğŸ“Š SUMMARY STATISTICS:')\n",
    "            display(summary_df)\n",
    "        \n",
    "        # 2. FIXED: Full Pixel-wise Data Export using NetCDF coordinates\n",
    "        print('\\n   ğŸ“Š Creating full pixel-wise data export...')\n",
    "        \n",
    "        # Use coordinates from analysis_results instead of temperature_data\n",
    "        sample_metric = next(iter(analysis_results.values()))\n",
    "        if hasattr(sample_metric, 'latitude') and hasattr(sample_metric, 'longitude'):\n",
    "            lats = sample_metric.latitude.values\n",
    "            lons = sample_metric.longitude.values\n",
    "        else:\n",
    "            print('âŒ No spatial coordinates found in analysis results')\n",
    "            return\n",
    "        \n",
    "        total_pixels = len(lats) * len(lons)\n",
    "        print(f'      Processing {total_pixels} pixels...')\n",
    "        \n",
    "        pixel_data = []\n",
    "        processed = 0\n",
    "        \n",
    "        for i, lat in enumerate(lats):\n",
    "            for j, lon in enumerate(lons):\n",
    "                row = {\n",
    "                    'pixel_id': f'{i}_{j}',\n",
    "                    'latitude': float(lat),\n",
    "                    'longitude': float(lon)\n",
    "                }\n",
    "                \n",
    "                # FIXED: Extract values for each metric with better error handling\n",
    "                for metric_name, metric_data in analysis_results.items():\n",
    "                    if hasattr(metric_data, 'sel') and hasattr(metric_data, 'dims'):\n",
    "                        try:\n",
    "                            if 'latitude' in metric_data.dims and 'longitude' in metric_data.dims:\n",
    "                                if len(metric_data.dims) == 2:\n",
    "                                    # Use exact coordinate matching instead of nearest\n",
    "                                    value = metric_data.loc[lat, lon].values\n",
    "                                    if np.isscalar(value) and not np.isnan(value):\n",
    "                                        row[metric_name] = float(value)\n",
    "                                    else:\n",
    "                                        row[metric_name] = 0.0\n",
    "                                else:\n",
    "                                    row[metric_name] = 0.0\n",
    "                        except (KeyError, IndexError) as e:\n",
    "                            # Coordinate not found - this is expected for water pixels\n",
    "                            row[metric_name] = 0.0\n",
    "                        except Exception as e:\n",
    "                            print(f'      âš ï¸ Error extracting {metric_name} at ({lat}, {lon}): {e}')\n",
    "                            row[metric_name] = 0.0\n",
    "                    else:\n",
    "                        row[metric_name] = 0.0\n",
    "                \n",
    "                pixel_data.append(row)\n",
    "                processed += 1\n",
    "                \n",
    "                if processed % max(1, total_pixels // 10) == 0:\n",
    "                    print(f'      Progress: {processed}/{total_pixels} ({processed/total_pixels*100:.0f}%)')\n",
    "        \n",
    "        if pixel_data:\n",
    "            pixel_df = pd.DataFrame(pixel_data)\n",
    "            pixel_filename = f'../outputs/climate_pixels_{year}.csv'\n",
    "            pixel_df.to_csv(pixel_filename, index=False)\n",
    "            \n",
    "            print(f'\\n   âœ… Full pixel data saved: {pixel_filename}')\n",
    "            print(f'      Rows: {len(pixel_df):,}')\n",
    "            print(f'      Columns: {len(pixel_df.columns)}')\n",
    "            \n",
    "            # Check for non-zero values\n",
    "            non_zero_counts = {}\n",
    "            for col in pixel_df.columns:\n",
    "                if col not in ['pixel_id', 'latitude', 'longitude']:\n",
    "                    non_zero_counts[col] = (pixel_df[col] != 0).sum()\n",
    "            \n",
    "            print(f'      Non-zero value counts:')\n",
    "            for col, count in non_zero_counts.items():\n",
    "                print(f'        {col}: {count}')\n",
    "            \n",
    "            # Show sample inline\n",
    "            print('\\nğŸ“Š SAMPLE PIXEL DATA:')\n",
    "            display(pixel_df.head(10))\n",
    "        \n",
    "        # 3. NetCDF Export with proper CRS\n",
    "        print('\\n   ğŸ“¦ Creating NetCDF file with proper CRS...')\n",
    "        \n",
    "        spatial_results = {}\n",
    "        for k, v in analysis_results.items():\n",
    "            if hasattr(v, 'dims') and 'latitude' in v.dims and 'longitude' in v.dims:\n",
    "                if len(v.dims) == 2:\n",
    "                    spatial_results[k] = v.fillna(0)\n",
    "        \n",
    "        if spatial_results:\n",
    "            results_ds = xr.Dataset(spatial_results)\n",
    "            \n",
    "            # Add proper CRS information (WGS84)\n",
    "            results_ds.latitude.attrs['standard_name'] = 'latitude'\n",
    "            results_ds.latitude.attrs['long_name'] = 'latitude'\n",
    "            results_ds.latitude.attrs['units'] = 'degrees_north'\n",
    "            results_ds.latitude.attrs['axis'] = 'Y'\n",
    "            \n",
    "            results_ds.longitude.attrs['standard_name'] = 'longitude'\n",
    "            results_ds.longitude.attrs['long_name'] = 'longitude'\n",
    "            results_ds.longitude.attrs['units'] = 'degrees_east'\n",
    "            results_ds.longitude.attrs['axis'] = 'X'\n",
    "            \n",
    "            # Add CRS variable following CF conventions\n",
    "            crs = xr.DataArray(\n",
    "                data=np.int32(1),\n",
    "                attrs={\n",
    "                    'grid_mapping_name': 'latitude_longitude',\n",
    "                    'longitude_of_prime_meridian': 0.0,\n",
    "                    'semi_major_axis': 6378137.0,\n",
    "                    'inverse_flattening': 298.257223563,\n",
    "                    'spatial_ref': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]',\n",
    "                    'crs_wkt': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]'\n",
    "                }\n",
    "            )\n",
    "            results_ds['crs'] = crs\n",
    "            \n",
    "            # Add grid_mapping attribute to all data variables\n",
    "            for var_name in results_ds.data_vars:\n",
    "                if var_name != 'crs':\n",
    "                    results_ds[var_name].attrs['grid_mapping'] = 'crs'\n",
    "            \n",
    "            # Add metadata\n",
    "            results_ds.attrs['analysis_year'] = year\n",
    "            results_ds.attrs['reference_period'] = f'{reference_start.value}-{reference_end.value}'\n",
    "            results_ds.attrs['created'] = datetime.now().isoformat()\n",
    "            results_ds.attrs['absolute_threshold'] = absolute_threshold.value\n",
    "            results_ds.attrs['percentile_threshold'] = percentile_threshold.value\n",
    "            results_ds.attrs['crs'] = 'EPSG:4326'\n",
    "            \n",
    "            netcdf_filename = f'../outputs/climate_analysis_{year}.nc'\n",
    "            results_ds.to_netcdf(netcdf_filename)\n",
    "            \n",
    "            print(f'   âœ… NetCDF saved with proper CRS: {netcdf_filename}')\n",
    "            print(f'      Variables: {list(results_ds.data_vars)}')\n",
    "            print(f'      Dimensions: {dict(results_ds.dims)}')\n",
    "            print(f'      CRS: EPSG:4326 (WGS84)')\n",
    "            print(f'      File size: {os.path.getsize(netcdf_filename) / 1024**2:.1f} MB')\n",
    "        \n",
    "        print('\\nâœ… Export complete to ../outputs directory!')\n",
    "        print('\\nğŸ“Š Files created:')\n",
    "        print(f'   â€¢ ../outputs/climate_summary_{year}.csv - Summary statistics')\n",
    "        print(f'   â€¢ ../outputs/climate_pixels_{year}.csv - ALL pixel values with coordinates')\n",
    "        print(f'   â€¢ ../outputs/climate_analysis_{year}.nc - NetCDF spatial dataset WITH CRS')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'âŒ Error exporting: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "export_button = widgets.Button(description='ğŸ“ Export to ../outputs', button_style='warning')\n",
    "export_button.on_click(lambda b: export_results())\n",
    "\n",
    "display(export_button)\n",
    "print('ğŸ“ Ready to export full pixel-level results to ../outputs directory')\n",
    "print('ğŸŒ Fixed: NetCDF files now include proper WGS84 CRS information')\n",
    "print('ğŸ”§ Fixed: CSV export now properly extracts values from analysis results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary\n",
    "\n",
    "This notebook provides the complete xarray climate analysis workflow with:\n",
    "\n",
    "### âœ… **Enhanced Features:**\n",
    "- **File browser button** - Easy raster file selection (no typing paths)\n",
    "- **Inline plots** - All visualizations appear in notebook cells\n",
    "- **Drawing tools** - Interactive ROI selection on map\n",
    "- **Data exploration** - Examine dataset before analysis\n",
    "- **Full pixel export** - Every individual pixel value preserved\n",
    "- **Organized output** - All files saved to ../outputs\n",
    "\n",
    "### ğŸ“Š **Complete Workflow:**\n",
    "1. **ROI Selection** - Draw, coordinates, or browse for raster\n",
    "2. **Configure Analysis** - Set thresholds and time periods\n",
    "3. **Extract Data** - Get time series from Google Earth Engine\n",
    "4. **Explore Dataset** - Examine structure with inline plots\n",
    "5. **Run Analysis** - Calculate metrics with inline visualization\n",
    "6. **Export Results** - Save to ../outputs with inline preview\n",
    "\n",
    "### ğŸš€ **Performance Benefits:**\n",
    "- **Extract once, analyze many times** - No repeated GEE API calls\n",
    "- **Fast local analysis** - xarray operations are vectorized\n",
    "- **Easy iteration** - Test different thresholds instantly\n",
    "- **Complete spatial data** - Every pixel value exported\n",
    "\n",
    "This version provides the ideal user experience with file browsers, inline visualization, and complete data export capabilities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes to self - at 35 degrees or 90% percentile, only max 6 days per year extreme, relative to a reference period of 10 years and 15 day moving window\n",
    "# the current implementation in this notebook calculates percentiles across the whole year - which will give false 'hot periods'\n",
    "# as the colder days in the winter drag the averages down. we actually need a moving window so that the percentiles are calculated against\n",
    "# the same period in the reference period. 5 days is quite short, perhaps we could allow the user to adjust, 10 or 15 days too?\n",
    "# question is how useful is this kind of analysis. What if the user picks a year for analysis that was not particularly hot?\n",
    "# is there a way of forcing the tool to select a few recent 'hot' year\n",
    "# or is there a better metric that shows both the current / most recent number of extreme heat days per year, Plus the trend i.e., in crease\n",
    "# in extreme heat days, and also an indication of the year within the last 10 years that had the most extreme heat days?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
