{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå°Ô∏è Seasonal Extreme Heat Days Analysis - Enhanced Methodology\n",
    "\n",
    "This notebook implements the **climatologically appropriate** extreme heat day calculation using seasonal percentiles:\n",
    "\n",
    "## üìê **Formula:**\n",
    "```\n",
    "Surface_Heat_Day = 1 if LST_daily_max > max(LST_abs, LST_rel)\n",
    "```\n",
    "Where:\n",
    "- **LST_abs**: Absolute threshold (e.g., 35¬∞C)\n",
    "- **LST_rel**: percentile_X{LST_daily_max for calendar_day ¬± 5 days over 30-year period}\n",
    "\n",
    "## üî¨ **Scientific Advantages:**\n",
    "- ‚ö° **Seasonal context**: July heat vs January heat appropriately weighted\n",
    "- üìà **Climatological accuracy**: Follows meteorological best practices\n",
    "- üéØ **Sensitive detection**: Can identify winter/spring heat anomalies\n",
    "- üîÑ **Day-specific baselines**: Each day compared to its historical context\n",
    "\n",
    "## üèóÔ∏è **Architecture:**\n",
    "- Same robust data processing as notebook 17\n",
    "- Enhanced seasonal percentile calculation\n",
    "- Improved visualization and export capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_7TDKVSyKvBdmMqW?ref=4i2o6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Earth Engine initialized successfully\n",
      "üì¶ Available packages:\n",
      "   - xarray: 2024.7.0\n",
      "   - pandas: 2.3.1\n",
      "   - numpy: 1.26.4\n",
      "üìÅ Created outputs directory: ../outputs\n",
      "üå°Ô∏è Seasonal Extreme Heat Analysis - Ready!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import ee\n",
    "import geemap\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import rasterio\n",
    "from tkinter import filedialog\n",
    "import tkinter as tk\n",
    "\n",
    "# Set matplotlib to display inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Initialize Earth Engine with your project\n",
    "try:\n",
    "    ee.Initialize(project='tl-cities')\n",
    "    print('‚úÖ Earth Engine initialized successfully')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Earth Engine initialization failed: {e}')\n",
    "\n",
    "print('üì¶ Available packages:')\n",
    "print(f'   - xarray: {xr.__version__}')\n",
    "print(f'   - pandas: {pd.__version__}')\n",
    "print(f'   - numpy: {np.__version__}')\n",
    "\n",
    "# Create outputs directory\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "print('üìÅ Created outputs directory: ../outputs')\n",
    "print('üå°Ô∏è Seasonal Extreme Heat Analysis - Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 1: ROI Selection (Same as Notebook 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20cf732e1444d31b950a60b9e4ce0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üéØ ROI Selection for Seasonal Analysis</h3>'), HTML(value='<b>Method 1: Draw on ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656a07fb1adc41dfa0b1a370aa4c9aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-12.9714, -38.5014], controls=(WidgetControl(options=['position', 'transparent_bg'], position='top‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Enhanced ROI Selection Ready for Seasonal Analysis\n",
      "üîß Complete functionality from notebook 17: drawing, coordinates, and file browser\n",
      "Choose any method to define your region of interest\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "analysis_geom = None\n",
    "temperature_data = None\n",
    "\n",
    "# Create map for ROI selection\n",
    "m = geemap.Map(center=[-12.9714, -38.5014], zoom=10)  # Salvador, Brazil\n",
    "m.add_basemap('SATELLITE')\n",
    "m.add('draw_control')\n",
    "\n",
    "def set_roi_from_drawing():\n",
    "    '''Extract ROI from map drawing'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        if hasattr(m, 'draw_control') and len(m.draw_control.data) > 0:\n",
    "            # Get the last drawn feature\n",
    "            feature = m.draw_control.data[-1]\n",
    "            coords = feature['geometry']['coordinates']\n",
    "            \n",
    "            if feature['geometry']['type'] == 'Polygon':\n",
    "                analysis_geom = ee.Geometry.Polygon(coords)\n",
    "            elif feature['geometry']['type'] == 'Rectangle':\n",
    "                analysis_geom = ee.Geometry.Rectangle(coords)\n",
    "            \n",
    "            area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "            bounds_info = analysis_geom.bounds().getInfo()['coordinates'][0]\n",
    "            west, south = bounds_info[0]\n",
    "            east, north = bounds_info[2]\n",
    "            \n",
    "            print(f'‚úÖ ROI set from drawing: {area_km2:.1f} km¬≤')\n",
    "            print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            return True\n",
    "        else:\n",
    "            print('‚ùå No drawing found. Please draw a polygon or rectangle on the map.')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from drawing: {e}')\n",
    "        return False\n",
    "\n",
    "def set_roi_from_coordinates():\n",
    "    '''Set ROI from coordinate inputs'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        west = float(west_input.value) if west_input.value else -38.7\n",
    "        east = float(east_input.value) if east_input.value else -38.3\n",
    "        south = float(south_input.value) if south_input.value else -13.1\n",
    "        north = float(north_input.value) if north_input.value else -12.8\n",
    "        \n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north])\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        # Add rectangle to map with proper visualization\n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['red'], 'max': 1}, 'ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'‚úÖ ROI set from coordinates: {area_km2:.1f} km¬≤')\n",
    "        print(f'   Bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from coordinates: {e}')\n",
    "        return False\n",
    "\n",
    "def browse_raster_file():\n",
    "    '''Open file browser to select raster file'''\n",
    "    try:\n",
    "        # Create a temporary tkinter root window\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()  # Hide the root window\n",
    "        \n",
    "        # Open file dialog\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title='Select Reference Raster File',\n",
    "            filetypes=[\n",
    "                ('Raster files', '*.tif *.tiff *.img *.nc *.hdf *.jp2'),\n",
    "                ('GeoTIFF', '*.tif *.tiff'),\n",
    "                ('NetCDF', '*.nc'),\n",
    "                ('All files', '*.*')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        root.destroy()  # Clean up\n",
    "        \n",
    "        if file_path:\n",
    "            raster_path_display.value = file_path\n",
    "            print(f'üìÅ Selected file: {os.path.basename(file_path)}')\n",
    "            print(f'    Full path: {file_path}')\n",
    "            return file_path\n",
    "        else:\n",
    "            print('‚ùå No file selected')\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error opening file browser: {e}')\n",
    "        print('   Note: File browser requires GUI environment')\n",
    "        return None\n",
    "\n",
    "def set_roi_from_raster():\n",
    "    '''Set ROI from selected raster extent with proper CRS handling'''\n",
    "    global analysis_geom\n",
    "    \n",
    "    try:\n",
    "        raster_path = raster_path_display.value.strip()\n",
    "        \n",
    "        if not raster_path or not os.path.exists(raster_path):\n",
    "            print('‚ùå Please select a valid raster file first')\n",
    "            return False\n",
    "        \n",
    "        print(f'üìñ Reading raster: {os.path.basename(raster_path)}')\n",
    "        \n",
    "        # Read raster bounds and CRS information\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "            shape = src.shape\n",
    "            transform = src.transform\n",
    "            \n",
    "            # Get bounds in original CRS\n",
    "            west, south, east, north = bounds.left, bounds.bottom, bounds.right, bounds.top\n",
    "            \n",
    "            print(f'   üìä Raster info:')\n",
    "            print(f'      CRS: {crs}')\n",
    "            print(f'      Shape: {shape}')\n",
    "            print(f'      Original bounds: W={west:.3f}, E={east:.3f}, S={south:.3f}, N={north:.3f}')\n",
    "            \n",
    "            # Transform to WGS84 if needed\n",
    "            if crs.to_epsg() != 4326:\n",
    "                from rasterio.warp import transform_bounds\n",
    "                west_wgs84, south_wgs84, east_wgs84, north_wgs84 = transform_bounds(\n",
    "                    crs, 'EPSG:4326', west, south, east, north\n",
    "                )\n",
    "                print(f'      Transformed to WGS84:')\n",
    "                print(f'      WGS84 bounds: W={west_wgs84:.6f}, E={east_wgs84:.6f}, S={south_wgs84:.6f}, N={north_wgs84:.6f}')\n",
    "                west, south, east, north = west_wgs84, south_wgs84, east_wgs84, north_wgs84\n",
    "            else:\n",
    "                print(f'      Already in WGS84')\n",
    "        \n",
    "        # Validate bounds are reasonable\n",
    "        if abs(west) > 180 or abs(east) > 180 or abs(south) > 90 or abs(north) > 90:\n",
    "            print(f'‚ùå Invalid bounds detected - coordinates out of valid range')\n",
    "            print(f'   This suggests a CRS projection issue')\n",
    "            return False\n",
    "        \n",
    "        if west >= east or south >= north:\n",
    "            print(f'‚ùå Invalid bounds - west >= east or south >= north')\n",
    "            return False\n",
    "        \n",
    "        # Create geometry in WGS84\n",
    "        analysis_geom = ee.Geometry.Rectangle([west, south, east, north], 'EPSG:4326')\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        \n",
    "        # Add to map with proper visualization\n",
    "        roi_image = ee.Image().paint(analysis_geom, 1, 2)\n",
    "        m.addLayer(roi_image, {'palette': ['blue'], 'max': 1}, 'Raster ROI')\n",
    "        m.centerObject(analysis_geom, 11)\n",
    "        \n",
    "        print(f'   ‚úÖ ROI set from raster extent: {area_km2:.1f} km¬≤')\n",
    "        print(f'   Final WGS84 bounds: W={west:.6f}, E={east:.6f}, S={south:.6f}, N={north:.6f}')\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error setting ROI from raster: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "# ROI input widgets\n",
    "west_input = widgets.FloatText(value=-38.7, description='West:')\n",
    "east_input = widgets.FloatText(value=-38.3, description='East:')\n",
    "south_input = widgets.FloatText(value=-13.1, description='South:')\n",
    "north_input = widgets.FloatText(value=-12.8, description='North:')\n",
    "\n",
    "# File browser widgets\n",
    "raster_path_display = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='No file selected...',\n",
    "    description='Selected File:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px'),\n",
    "    disabled=True  # Read-only display\n",
    ")\n",
    "\n",
    "browse_button = widgets.Button(\n",
    "    description='üìÇ Browse Files',\n",
    "    button_style='info',\n",
    "    tooltip='Click to select a raster file'\n",
    ")\n",
    "browse_button.on_click(lambda b: browse_raster_file())\n",
    "\n",
    "# Action buttons\n",
    "set_drawing_button = widgets.Button(description='üìç Use Drawing', button_style='success')\n",
    "set_coords_button = widgets.Button(description='üìç Use Coordinates', button_style='info')\n",
    "set_raster_button = widgets.Button(description='üìç Use Raster Extent', button_style='warning')\n",
    "\n",
    "set_drawing_button.on_click(lambda b: set_roi_from_drawing())\n",
    "set_coords_button.on_click(lambda b: set_roi_from_coordinates())\n",
    "set_raster_button.on_click(lambda b: set_roi_from_raster())\n",
    "\n",
    "roi_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üéØ ROI Selection for Seasonal Analysis</h3>'),\n",
    "    \n",
    "    widgets.HTML('<b>Method 1: Draw on Map</b>'),\n",
    "    widgets.HTML('Draw a polygon or rectangle on the map below, then click:'),\n",
    "    set_drawing_button,\n",
    "    \n",
    "    widgets.HTML('<b>Method 2: Enter Coordinates</b>'),\n",
    "    widgets.HBox([west_input, east_input]),\n",
    "    widgets.HBox([south_input, north_input]),\n",
    "    set_coords_button,\n",
    "    \n",
    "    widgets.HTML('<b>Method 3: Use Raster File Extent</b>'),\n",
    "    widgets.HTML('Click Browse to select a reference raster file:'),\n",
    "    widgets.HBox([browse_button, raster_path_display]),\n",
    "    set_raster_button\n",
    "])\n",
    "\n",
    "display(roi_interface)\n",
    "display(m)\n",
    "\n",
    "print('üéØ Enhanced ROI Selection Ready for Seasonal Analysis')\n",
    "print('üîß Complete functionality from notebook 17: drawing, coordinates, and file browser')\n",
    "print('Choose any method to define your region of interest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Analysis Configuration - Enhanced for Seasonal Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccb74bae36f4c7c972e7a79a9f0691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìä Seasonal Analysis Configuration</h3>'), HTML(value='<div style=\"background-co‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Seasonal Configuration Ready\n",
      "üå°Ô∏è Formula: Heat_Day = LST_max > max(absolute_threshold, seasonal_percentile)\n",
      "‚ö†Ô∏è GSHTD data: 2003-2020 (17 years provides robust seasonal percentiles)\n"
     ]
    }
   ],
   "source": [
    "# Analysis configuration with seasonal parameters\n",
    "analysis_year = widgets.IntSlider(value=2020, min=2003, max=2020, description='Analysis Year:')\n",
    "reference_start = widgets.IntSlider(value=2003, min=2003, max=2019, description='Reference Start:')\n",
    "reference_end = widgets.IntSlider(value=2019, min=2004, max=2020, description='Reference End:')\n",
    "absolute_threshold = widgets.FloatSlider(value=35.0, min=20.0, max=45.0, step=0.5, description='Threshold (¬∞C):')\n",
    "percentile_threshold = widgets.FloatSlider(value=90.0, min=50.0, max=99.0, step=1.0, description='Percentile:')\n",
    "day_window = widgets.IntSlider(value=5, min=1, max=15, step=1, description='Day Window (¬±):')\n",
    "\n",
    "config_interface = widgets.VBox([\n",
    "    widgets.HTML('<h3>üìä Seasonal Analysis Configuration</h3>'),\n",
    "    widgets.HTML('<div style=\"background-color: #e7f3ff; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>üî¨ Seasonal Method:</b> Each day compared to historical temperatures ' +\n",
    "                'for the same calendar day ¬± window over reference period.</div>'),\n",
    "    widgets.HTML('<div style=\"background-color: #fff3cd; padding: 10px; border-radius: 5px;\">' +\n",
    "                '<b>‚ö†Ô∏è Data Availability:</b> GSHTD data available 2003-2020. ' +\n",
    "                'Reference period adjusted to available years (17 years still provides robust percentiles).</div>'),\n",
    "    analysis_year,\n",
    "    widgets.HTML('<b>Reference Period (GSHTD available 2003-2020):</b>'),\n",
    "    widgets.HBox([reference_start, reference_end]),\n",
    "    widgets.HTML('<b>Threshold Parameters:</b>'),\n",
    "    widgets.HBox([absolute_threshold, percentile_threshold]),\n",
    "    widgets.HTML('<b>Seasonal Window:</b>'),\n",
    "    day_window,\n",
    "    widgets.HTML('<small><i>Day Window: ¬±5 means July 15 compared to July 10-20 historical data</i></small>')\n",
    "])\n",
    "\n",
    "display(config_interface)\n",
    "print('üìä Seasonal Configuration Ready')\n",
    "print('üå°Ô∏è Formula: Heat_Day = LST_max > max(absolute_threshold, seasonal_percentile)')\n",
    "print('‚ö†Ô∏è GSHTD data: 2003-2020 (17 years provides robust seasonal percentiles)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Step 3: Data Extraction (Same Architecture as Notebook 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9b160655654ee48d74870d0e0c85f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='üîÑ Extract Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Ready to extract temperature data for seasonal analysis\n",
      "üéØ Will extract extended time period for robust seasonal percentiles\n",
      "‚ö° NEW: Adaptive extraction with monthly chunking for large datasets\n",
      "üîß Automatically handles Earth Engine 1M value limit at 1000m resolution\n"
     ]
    }
   ],
   "source": [
    "def extract_temperature_data():\n",
    "    '''Extract temperature data from GSHTD using monthly chunking for large datasets at 1km resolution'''\n",
    "    global temperature_data, analysis_geom\n",
    "    \n",
    "    if analysis_geom is None:\n",
    "        print('‚ùå Please set an ROI first!')\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        print('üîÑ Extracting temperature data for seasonal analysis...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        \n",
    "        # Debug ROI information\n",
    "        area_km2 = analysis_geom.area().divide(1000000).getInfo()\n",
    "        bounds = analysis_geom.bounds().getInfo()\n",
    "        print(f'   üìè ROI area: {area_km2:.2f} km¬≤')\n",
    "        print(f'   üó∫Ô∏è ROI bounds: {bounds}')\n",
    "        \n",
    "        # Function to get regional collection based on location\n",
    "        def get_region_collection(geom):\n",
    "            \"\"\"Determine which regional GSHTD collection to use based on geometry location\"\"\"\n",
    "            centroid = geom.centroid().coordinates().getInfo()\n",
    "            lon, lat = centroid[0], centroid[1]\n",
    "            \n",
    "            if lat > 15 and lon > -140 and lon < -40:  # North America\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"\n",
    "            elif lat < 35 and lon > -120 and lon < -30:  # Latin America  \n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/latin_america\"\n",
    "            elif lat > 30 and lon > -15 and lon < 180:  # Europe & Asia\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/europe_asia\"\n",
    "            elif lat < 40 and lon > -20 and lon < 55:  # Africa\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/africa\"\n",
    "            elif lat < -5 and lon > 110 and lon < 180:  # Australia\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/australia\"\n",
    "            else:\n",
    "                return \"projects/sat-io/open-datasets/global-daily-air-temp/north_america\"  # Default\n",
    "        \n",
    "        # Function to get temperature collection\n",
    "        def get_temperature_collection(region_geom, start_date, end_date, temp_type='tmax'):\n",
    "            \"\"\"Get daily air temperature collection for the specified region and period\"\"\"\n",
    "            collection_id = get_region_collection(region_geom)\n",
    "            print(f'   üì° Using collection: {collection_id.split(\"/\")[-1]}')\n",
    "            \n",
    "            collection = ee.ImageCollection(collection_id)\n",
    "            \n",
    "            # Filter by date, bounds, and temperature type using prop_type metadata\n",
    "            filtered_collection = (collection.filterDate(start_date, end_date)\n",
    "                                 .filterBounds(region_geom)\n",
    "                                 .filter(ee.Filter.eq('prop_type', temp_type)))\n",
    "            \n",
    "            # Just select and clip, scaling handled in pandas processing\n",
    "            temp_collection = filtered_collection.map(lambda img: \n",
    "                img.select('b1')\n",
    "                  .clip(region_geom)\n",
    "                  .copyProperties(img, ['system:time_start'])\n",
    "            )\n",
    "            \n",
    "            return temp_collection\n",
    "        \n",
    "        # Test pixel count at 1km resolution\n",
    "        test_collection = get_temperature_collection(analysis_geom, f'{year}-01-01', f'{year}-01-02', 'tmax')\n",
    "        \n",
    "        if test_collection.size().getInfo() == 0:\n",
    "            print('‚ùå No images found for test date - check ROI coverage')\n",
    "            return False\n",
    "        \n",
    "        first_image = test_collection.first()\n",
    "        pixel_count = first_image.select('b1').reduceRegion(\n",
    "            reducer=ee.Reducer.count(),\n",
    "            geometry=analysis_geom,\n",
    "            scale=1000,  # 1km resolution\n",
    "            maxPixels=1e9\n",
    "        ).getInfo()\n",
    "        \n",
    "        expected_pixels = pixel_count.get('b1', 0)\n",
    "        print(f'   üîç Expected pixels per image at 1km: {expected_pixels}')\n",
    "        \n",
    "        if expected_pixels == 0:\n",
    "            print('‚ùå No pixels found in ROI - check if ROI overlaps with data coverage')\n",
    "            return False\n",
    "        \n",
    "        # Calculate years to extract (need full reference period for seasonal analysis)\n",
    "        years_to_extract = list(range(ref_start, ref_end + 1)) + [year]\n",
    "        years_to_extract = sorted(list(set(years_to_extract)))  # Remove duplicates and sort\n",
    "        \n",
    "        print(f'   üìÖ Will extract {len(years_to_extract)} years: {years_to_extract}')\n",
    "        print(f'   üî¨ Extended period needed for seasonal percentile calculation')\n",
    "        \n",
    "        # Check if we need monthly chunking for very large datasets\n",
    "        total_estimated = expected_pixels * 365 * len(years_to_extract)\n",
    "        print(f'   üîç Total estimated values for all years: {total_estimated:,}')\n",
    "        \n",
    "        if total_estimated > 2000000 or expected_pixels > 300:  # Very large dataset\n",
    "            print(f'   ‚ö†Ô∏è Dataset too large - using monthly chunking extraction')\n",
    "            use_monthly_chunking = True\n",
    "        else:\n",
    "            print(f'   ‚úÖ Using yearly extraction')\n",
    "            use_monthly_chunking = False\n",
    "        \n",
    "        # Extract data with appropriate chunking strategy\n",
    "        all_dataframes = []\n",
    "        \n",
    "        if use_monthly_chunking:\n",
    "            print(f'\\n   üìÖ Extracting data month by month for {len(years_to_extract)} years...')\n",
    "            total_months = len(years_to_extract) * 12\n",
    "            processed_months = 0\n",
    "            \n",
    "            for extract_year in years_to_extract:\n",
    "                print(f'\\n   üìÖ Processing year {extract_year}...')\n",
    "                \n",
    "                for month in range(1, 13):\n",
    "                    print(f'      Month {month:02d} ({processed_months+1}/{total_months})...', end=' ')\n",
    "                    \n",
    "                    # Monthly date range\n",
    "                    start_date = f'{extract_year}-{month:02d}-01'\n",
    "                    if month == 12:\n",
    "                        end_date = f'{extract_year+1}-01-01'\n",
    "                    else:\n",
    "                        end_date = f'{extract_year}-{month+1:02d}-01'\n",
    "                    \n",
    "                    month_collection = get_temperature_collection(\n",
    "                        analysis_geom, start_date, end_date, 'tmax'\n",
    "                    )\n",
    "                    \n",
    "                    month_count = month_collection.size().getInfo()\n",
    "                    if month_count == 0:\n",
    "                        print('No data')\n",
    "                        processed_months += 1\n",
    "                        continue\n",
    "                    \n",
    "                    month_estimated = expected_pixels * month_count\n",
    "                    if month_estimated > 800000:  # Even monthly is too large\n",
    "                        scale = 2000\n",
    "                        print(f'Using 2km scale ({month_estimated:,} values)')\n",
    "                    else:\n",
    "                        scale = 1000\n",
    "                        print(f'Using 1km scale ({month_estimated:,} values)')\n",
    "                    \n",
    "                    try:\n",
    "                        region_data = month_collection.getRegion(\n",
    "                            geometry=analysis_geom,\n",
    "                            scale=scale,\n",
    "                            crs='EPSG:4326'\n",
    "                        ).getInfo()\n",
    "                        \n",
    "                        if len(region_data) > 1:  # More than just header\n",
    "                            header = region_data[0]\n",
    "                            data = region_data[1:]\n",
    "                            \n",
    "                            df_month = pd.DataFrame(data, columns=header)\n",
    "                            df_month['time'] = pd.to_datetime(df_month['time'], unit='ms')\n",
    "                            \n",
    "                            # Apply temperature scaling and rename column\n",
    "                            if 'b1' in df_month.columns:\n",
    "                                df_month['temperature'] = df_month['b1'] / 10.0  # Scale to Celsius\n",
    "                                df_month = df_month.drop(columns=['b1'])\n",
    "                            \n",
    "                            # Drop nulls and filter realistic temperatures\n",
    "                            df_month = df_month.dropna(subset=['temperature'])\n",
    "                            df_month = df_month[df_month['temperature'] <= 50.0]  # Remove outliers\n",
    "                            \n",
    "                            if len(df_month) > 0:\n",
    "                                all_dataframes.append(df_month)\n",
    "                        \n",
    "                        processed_months += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f'Failed: {e}')\n",
    "                        processed_months += 1\n",
    "                        continue\n",
    "        \n",
    "        else:  # Yearly extraction for smaller datasets\n",
    "            for extract_year in years_to_extract:\n",
    "                print(f'\\n   üìÖ Extracting year {extract_year}...')\n",
    "                \n",
    "                year_collection = get_temperature_collection(\n",
    "                    analysis_geom, f'{extract_year}-01-01', f'{extract_year}-12-31', 'tmax'\n",
    "                )\n",
    "                \n",
    "                year_size = year_collection.size().getInfo()\n",
    "                estimated_values = expected_pixels * year_size\n",
    "                \n",
    "                print(f'      Images: {year_size}, Estimated values: {estimated_values:,}')\n",
    "                \n",
    "                if estimated_values > 900000:  # Still too large\n",
    "                    print(f'      ‚ö†Ô∏è Still too large for single year, using 2km scale')\n",
    "                    scale = 2000\n",
    "                else:\n",
    "                    print(f'      ‚úÖ Using 1km scale')\n",
    "                    scale = 1000\n",
    "                \n",
    "                try:\n",
    "                    region_data = year_collection.getRegion(\n",
    "                        geometry=analysis_geom,\n",
    "                        scale=scale,\n",
    "                        crs='EPSG:4326'\n",
    "                    ).getInfo()\n",
    "                    \n",
    "                    print(f'      ‚úÖ Extracted {len(region_data)} rows')\n",
    "                    \n",
    "                    if len(region_data) > 1:  # More than just header\n",
    "                        header = region_data[0]\n",
    "                        data = region_data[1:]\n",
    "                        \n",
    "                        df_year = pd.DataFrame(data, columns=header)\n",
    "                        df_year['time'] = pd.to_datetime(df_year['time'], unit='ms')\n",
    "                        \n",
    "                        # Apply temperature scaling and rename column BEFORE dropping nulls\n",
    "                        if 'b1' in df_year.columns:\n",
    "                            df_year['temperature'] = df_year['b1'] / 10.0  # Scale to Celsius\n",
    "                            df_year = df_year.drop(columns=['b1'])  # Remove original column\n",
    "                        \n",
    "                        # Now drop nulls from the correctly named temperature column\n",
    "                        df_year = df_year.dropna(subset=['temperature'])\n",
    "                        \n",
    "                        print(f'      üìä Valid observations: {len(df_year)}')\n",
    "                        \n",
    "                        if len(df_year) > 0:\n",
    "                            all_dataframes.append(df_year)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f'      ‚ùå Failed to extract {extract_year}: {e}')\n",
    "                    continue\n",
    "        \n",
    "        if not all_dataframes:\n",
    "            print('‚ùå No data extracted for any period')\n",
    "            return False\n",
    "        \n",
    "        # Combine all periods\n",
    "        print(f'\\n   üîó Combining {len(all_dataframes)} data chunks...')\n",
    "        df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        \n",
    "        print(f'   üìä Total combined data: {len(df)} observations')\n",
    "        \n",
    "        unique_pixels = df[['longitude', 'latitude']].drop_duplicates()\n",
    "        print(f'   üìç Unique spatial pixels: {len(unique_pixels)}')\n",
    "        print(f'   üå°Ô∏è Temperature range: {df[\"temperature\"].min():.1f}¬∞C to {df[\"temperature\"].max():.1f}¬∞C')\n",
    "        \n",
    "        # Determine actual resolution achieved\n",
    "        if 'scale' in locals():\n",
    "            print(f'   üìê Resolution achieved: {scale}m')\n",
    "        else:\n",
    "            print(f'   üìê Resolution: Mixed (adaptive scaling)')\n",
    "        \n",
    "        # Show sample of the data\n",
    "        print('\\nüìã Sample of extracted data:')\n",
    "        print(df[['time', 'latitude', 'longitude', 'temperature']].head())\n",
    "        \n",
    "        # Convert to xarray\n",
    "        try:\n",
    "            temperature_data = df.set_index(['time', 'latitude', 'longitude']).to_xarray()\n",
    "            \n",
    "            print(f'\\n‚úÖ Xarray dataset created successfully!')\n",
    "            print(f'   üìÖ Time range: {temperature_data.time.min().values} to {temperature_data.time.max().values}')\n",
    "            print(f'   üåç Spatial dimensions: {temperature_data.dims[\"latitude\"]} √ó {temperature_data.dims[\"longitude\"]} pixels')\n",
    "            print(f'   üìä Total observations: {temperature_data.temperature.count().values}')\n",
    "            print(f'   üéØ Dataset: GSHTD Daily Air Temperature for Seasonal Analysis')\n",
    "            print(f'   üîß Extraction method: {\"Monthly chunking\" if use_monthly_chunking else \"Yearly chunking\"}')\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'‚ùå Error converting to xarray: {e}')\n",
    "            print('   Raw DataFrame saved as backup for debugging')\n",
    "            globals()['debug_df'] = df\n",
    "            return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error extracting data: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return False\n",
    "\n",
    "extract_button = widgets.Button(description='üîÑ Extract Data', button_style='primary')\n",
    "extract_button.on_click(lambda b: extract_temperature_data())\n",
    "\n",
    "display(extract_button)\n",
    "print('üîÑ Ready to extract temperature data for seasonal analysis')\n",
    "print('üéØ Will extract extended time period for robust seasonal percentiles')\n",
    "print('‚ö° NEW: Adaptive extraction with monthly chunking for large datasets')\n",
    "print('üîß Automatically handles Earth Engine 1M value limit at 1000m resolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Step 4: Seasonal Heat Days Calculation - NEW METHODOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9c1501e59342c8bd38ba09982b0f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='üî¨ Calculate Seasonal Heat Days', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Ready to calculate seasonal extreme heat days\n",
      "üìê Formula: Heat_Day = LST_max > max(absolute_threshold, seasonal_percentile)\n",
      "ü™ü Each day compared to historical ¬±window days for climatological context\n"
     ]
    }
   ],
   "source": [
    "def calculate_seasonal_heat_days():\n",
    "    '''Calculate heat days using seasonal percentile methodology'''\n",
    "    global temperature_data, analysis_results\n",
    "    \n",
    "    if temperature_data is None:\n",
    "        print('‚ùå Please extract temperature data first!')\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        print('üî¨ Calculating seasonal extreme heat days...')\n",
    "        \n",
    "        year = analysis_year.value\n",
    "        ref_start = reference_start.value\n",
    "        ref_end = reference_end.value\n",
    "        abs_threshold = absolute_threshold.value\n",
    "        pct_threshold = percentile_threshold.value\n",
    "        window_days = day_window.value\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Filter data\n",
    "        analysis_data = temperature_data.sel(time=str(year))\n",
    "        reference_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{ref_end}-12-31'))\n",
    "        \n",
    "        print(f'   üìÖ Analysis year: {len(analysis_data.time)} days')\n",
    "        print(f'   üìÖ Reference period: {len(reference_data.time)} days')\n",
    "        print(f'   ü™ü Day window: ¬±{window_days} days')\n",
    "        \n",
    "        # Add day of year to both datasets\n",
    "        analysis_data = analysis_data.assign_coords(dayofyear=analysis_data.time.dt.dayofyear)\n",
    "        reference_data = reference_data.assign_coords(dayofyear=reference_data.time.dt.dayofyear)\n",
    "        \n",
    "        print('\\nüî¨ Calculating seasonal percentiles for each day of year...')\n",
    "        \n",
    "        # Create seasonal percentile array\n",
    "        seasonal_percentiles = xr.DataArray(\n",
    "            np.full((366, len(analysis_data.latitude), len(analysis_data.longitude)), np.nan),\n",
    "            dims=['dayofyear', 'latitude', 'longitude'],\n",
    "            coords={\n",
    "                'dayofyear': np.arange(1, 367),\n",
    "                'latitude': analysis_data.latitude,\n",
    "                'longitude': analysis_data.longitude\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Calculate percentile for each day of year\n",
    "        for doy in range(1, 367):  # 1-366 (including leap day)\n",
    "            if doy % 50 == 0:  # Progress indicator\n",
    "                print(f'   Processing day {doy}/366...')\n",
    "            \n",
    "            # Create window around day of year (circular for year boundaries)\n",
    "            window_start = doy - window_days\n",
    "            window_end = doy + window_days\n",
    "            \n",
    "            # Handle year boundaries (e.g., Jan 1 ¬± 5 includes Dec 27-31)\n",
    "            if window_start <= 0:\n",
    "                # Wrap around to end of year\n",
    "                window_doys = list(range(366 + window_start, 367)) + list(range(1, window_end + 1))\n",
    "            elif window_end > 366:\n",
    "                # Wrap around to beginning of year\n",
    "                window_doys = list(range(window_start, 367)) + list(range(1, window_end - 366 + 1))\n",
    "            else:\n",
    "                # Normal case\n",
    "                window_doys = list(range(window_start, window_end + 1))\n",
    "            \n",
    "            # Select data for this window from all reference years\n",
    "            window_data = reference_data.where(\n",
    "                reference_data.dayofyear.isin(window_doys), drop=True\n",
    "            )\n",
    "            \n",
    "            if len(window_data.time) > 0:\n",
    "                # Calculate percentile for this day across all reference years\n",
    "                day_percentile = window_data.temperature.quantile(\n",
    "                    pct_threshold/100, dim='time', skipna=True\n",
    "                )\n",
    "                seasonal_percentiles[doy-1, :, :] = day_percentile\n",
    "        \n",
    "        print(f'\\n‚úÖ Seasonal percentiles calculated for all 366 days')\n",
    "        \n",
    "        # Apply seasonal thresholds to analysis year\n",
    "        print('\\nüî• Calculating seasonal heat days...')\n",
    "        \n",
    "        # Create threshold array for each day in analysis year\n",
    "        daily_thresholds = xr.full_like(analysis_data.temperature, np.nan)\n",
    "        \n",
    "        for i, day_time in enumerate(analysis_data.time):\n",
    "            doy = int(day_time.dt.dayofyear.values)\n",
    "            day_seasonal_pct = seasonal_percentiles[doy-1, :, :]\n",
    "            \n",
    "            # Apply formula: max(absolute_threshold, seasonal_percentile)\n",
    "            day_threshold = xr.where(\n",
    "                day_seasonal_pct > abs_threshold,\n",
    "                day_seasonal_pct,\n",
    "                abs_threshold\n",
    "            )\n",
    "            \n",
    "            daily_thresholds[i, :, :] = day_threshold\n",
    "        \n",
    "        # Calculate heat days: LST_daily_max > threshold for that day\n",
    "        heat_days_boolean = analysis_data.temperature > daily_thresholds\n",
    "        seasonal_heat_days = heat_days_boolean.sum(dim='time')\n",
    "        \n",
    "        # Store results\n",
    "        results['seasonal_heat_days'] = seasonal_heat_days\n",
    "        results['seasonal_percentiles_mean'] = seasonal_percentiles.mean(dim='dayofyear')\n",
    "        results['daily_thresholds_mean'] = daily_thresholds.mean(dim='time')\n",
    "        \n",
    "        # Also calculate traditional metrics for comparison\n",
    "        print('\\nüìä Calculating comparison metrics...')\n",
    "        \n",
    "        # Traditional annual percentile method\n",
    "        annual_percentile = reference_data.temperature.quantile(pct_threshold/100, dim='time')\n",
    "        annual_threshold = xr.where(\n",
    "            annual_percentile > abs_threshold,\n",
    "            annual_percentile,\n",
    "            abs_threshold\n",
    "        )\n",
    "        annual_heat_days = (analysis_data.temperature > annual_threshold).sum(dim='time')\n",
    "        \n",
    "        results['annual_heat_days'] = annual_heat_days\n",
    "        results['annual_percentile'] = annual_percentile\n",
    "        \n",
    "        # Annual extremes\n",
    "        results['annual_max'] = analysis_data.temperature.max(dim='time')\n",
    "        results['annual_min'] = analysis_data.temperature.min(dim='time')\n",
    "        results['annual_range'] = results['annual_max'] - results['annual_min']\n",
    "        \n",
    "        print('\\n‚úÖ Seasonal heat days calculation complete!')\n",
    "        \n",
    "        # Print comparison summary\n",
    "        seasonal_mean = seasonal_heat_days.mean().values\n",
    "        annual_mean = annual_heat_days.mean().values\n",
    "        seasonal_max = seasonal_heat_days.max().values\n",
    "        annual_max = annual_heat_days.max().values\n",
    "        seasonal_pixels = (seasonal_heat_days > 0).sum().values\n",
    "        annual_pixels = (annual_heat_days > 0).sum().values\n",
    "        \n",
    "        print(f'\\nüìä METHODOLOGY COMPARISON:')\n",
    "        print(f'   üî¨ Seasonal Method:')\n",
    "        print(f'      Mean heat days: {seasonal_mean:.1f}')\n",
    "        print(f'      Max heat days: {seasonal_max:.0f}')\n",
    "        print(f'      Pixels with >0 heat days: {seasonal_pixels}')\n",
    "        print(f'   üìÖ Annual Method:')\n",
    "        print(f'      Mean heat days: {annual_mean:.1f}')\n",
    "        print(f'      Max heat days: {annual_max:.0f}')\n",
    "        print(f'      Pixels with >0 heat days: {annual_pixels}')\n",
    "        print(f'   üìà Difference:')\n",
    "        print(f'      Mean: {seasonal_mean - annual_mean:+.1f} days')\n",
    "        print(f'      Pixels: {seasonal_pixels - annual_pixels:+.0f}')\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error calculating seasonal heat days: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "        return None\n",
    "\n",
    "# Analysis button\n",
    "analyze_button = widgets.Button(description='üî¨ Calculate Seasonal Heat Days', button_style='success')\n",
    "analysis_results = None\n",
    "\n",
    "def run_seasonal_analysis(button):\n",
    "    global analysis_results\n",
    "    print('üîÑ Starting seasonal analysis...')\n",
    "    analysis_results = calculate_seasonal_heat_days()\n",
    "    if analysis_results is not None:\n",
    "        print('‚úÖ Seasonal analysis complete!')\n",
    "        print('üìÅ Ready for visualization and export')\n",
    "    else:\n",
    "        print('‚ùå Seasonal analysis failed')\n",
    "\n",
    "analyze_button.on_click(run_seasonal_analysis)\n",
    "\n",
    "display(analyze_button)\n",
    "print('üî¨ Ready to calculate seasonal extreme heat days')\n",
    "print('üìê Formula: Heat_Day = LST_max > max(absolute_threshold, seasonal_percentile)')\n",
    "print('ü™ü Each day compared to historical ¬±window days for climatological context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: Visualization - Seasonal vs Annual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7241ded9083f4c8e93811a3f50c0734d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='üìä Create Visualizations', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Ready to create seasonal analysis visualizations\n",
      "üî¨ Will compare seasonal vs annual methodologies\n",
      "üìà Includes spatial maps, distributions, correlation analysis, monthly and time series comparisons\n",
      "üìÖ NEW: Monthly threshold comparison + Full time series analysis (2003-2020)\n",
      "‚è≥ Enhanced visualization shows temperature trends, anomalies, and temporal context\n"
     ]
    }
   ],
   "source": [
    "def create_seasonal_visualizations():\n",
    "    '''Create comprehensive visualizations comparing seasonal vs annual methods'''\n",
    "    global analysis_results, temperature_data\n",
    "    \n",
    "    if analysis_results is None:\n",
    "        print('‚ùå Please run seasonal analysis first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('üìä Creating seasonal analysis visualizations...')\n",
    "        \n",
    "        # Create comprehensive comparison plot with time series analysis\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(24, 24))\n",
    "        \n",
    "        # Seasonal Heat Days Map\n",
    "        seasonal_heat_days = analysis_results['seasonal_heat_days']\n",
    "        seasonal_heat_days.plot(ax=axes[0,0], cmap='Reds', add_colorbar=True, \n",
    "                                cbar_kwargs={'label': 'Heat Days'})\n",
    "        axes[0,0].set_title('üî¨ Seasonal Method Heat Days', fontweight='bold')\n",
    "        \n",
    "        # Annual Heat Days Map\n",
    "        annual_heat_days = analysis_results['annual_heat_days']\n",
    "        annual_heat_days.plot(ax=axes[0,1], cmap='Reds', add_colorbar=True,\n",
    "                             cbar_kwargs={'label': 'Heat Days'})\n",
    "        axes[0,1].set_title('üìÖ Annual Method Heat Days', fontweight='bold')\n",
    "        \n",
    "        # Difference Map\n",
    "        difference = seasonal_heat_days - annual_heat_days\n",
    "        difference.plot(ax=axes[0,2], cmap='RdBu_r', add_colorbar=True,\n",
    "                       cbar_kwargs={'label': 'Difference (Seasonal - Annual)'})\n",
    "        axes[0,2].set_title('üìà Method Difference', fontweight='bold')\n",
    "        \n",
    "        # Heat Days Distribution Comparison\n",
    "        seasonal_flat = seasonal_heat_days.values.flatten()\n",
    "        annual_flat = annual_heat_days.values.flatten()\n",
    "        seasonal_clean = seasonal_flat[~np.isnan(seasonal_flat)]\n",
    "        annual_clean = annual_flat[~np.isnan(annual_flat)]\n",
    "        \n",
    "        axes[1,0].hist(seasonal_clean, bins=20, alpha=0.7, color='red', \n",
    "                      edgecolor='black', label='Seasonal Method')\n",
    "        axes[1,0].hist(annual_clean, bins=20, alpha=0.5, color='blue',\n",
    "                      edgecolor='black', label='Annual Method')\n",
    "        axes[1,0].set_title('Heat Days Distribution Comparison', fontweight='bold')\n",
    "        axes[1,0].set_xlabel('Heat Days per Pixel')\n",
    "        axes[1,0].set_ylabel('Frequency')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Seasonal Thresholds Map\n",
    "        seasonal_thresholds = analysis_results['seasonal_percentiles_mean']\n",
    "        seasonal_thresholds.plot(ax=axes[1,1], cmap='viridis', add_colorbar=True,\n",
    "                               cbar_kwargs={'label': 'Temperature (¬∞C)'})\n",
    "        axes[1,1].set_title('Mean Seasonal Thresholds', fontweight='bold')\n",
    "        \n",
    "        # Scatter plot comparison\n",
    "        axes[1,2].scatter(annual_clean, seasonal_clean, alpha=0.6, s=20, color='purple')\n",
    "        max_val = max(annual_clean.max(), seasonal_clean.max())\n",
    "        axes[1,2].plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='1:1 line')\n",
    "        axes[1,2].set_xlabel('Annual Method Heat Days')\n",
    "        axes[1,2].set_ylabel('Seasonal Method Heat Days')\n",
    "        axes[1,2].set_title('Method Correlation', fontweight='bold')\n",
    "        axes[1,2].legend()\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Monthly Threshold and Temperature Comparison (for analysis year)\n",
    "        print('üìä Creating monthly threshold comparison...')\n",
    "        \n",
    "        try:\n",
    "            # Get analysis year data\n",
    "            analysis_year_val = analysis_year.value\n",
    "            analysis_data = temperature_data.sel(time=str(analysis_year_val))\n",
    "            \n",
    "            # Calculate monthly statistics\n",
    "            monthly_temps = analysis_data.temperature.groupby('time.month')\n",
    "            monthly_max_temps = monthly_temps.max().mean(dim=['latitude', 'longitude'])\n",
    "            \n",
    "            # Get reference data for percentile calculations\n",
    "            ref_start = reference_start.value\n",
    "            ref_end = reference_end.value\n",
    "            reference_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{ref_end}-12-31'))\n",
    "            \n",
    "            # Calculate monthly seasonal percentiles (average across all pixels)\n",
    "            seasonal_pct_monthly = []\n",
    "            for month in range(1, 13):\n",
    "                # Get all days in this month across all reference years\n",
    "                month_data = reference_data.where(reference_data.time.dt.month == month, drop=True)\n",
    "                if len(month_data.time) > 0:\n",
    "                    month_pct = month_data.temperature.quantile(\n",
    "                        percentile_threshold.value/100, dim='time', skipna=True\n",
    "                    ).mean(dim=['latitude', 'longitude'])\n",
    "                    seasonal_pct_monthly.append(float(month_pct.values))\n",
    "                else:\n",
    "                    seasonal_pct_monthly.append(np.nan)\n",
    "            \n",
    "            # Calculate annual percentile (constant across months)\n",
    "            annual_percentile_val = float(analysis_results['annual_percentile'].mean().values)\n",
    "            \n",
    "            # User-defined threshold (constant)\n",
    "            user_threshold = absolute_threshold.value\n",
    "            \n",
    "            # Create monthly comparison plot\n",
    "            months = range(1, 13)\n",
    "            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "            \n",
    "            axes[2,0].plot(months, seasonal_pct_monthly, 'o-', linewidth=2, markersize=6, \n",
    "                          color='red', label=f'Seasonal {percentile_threshold.value:.0f}th Percentile')\n",
    "            axes[2,0].axhline(annual_percentile_val, color='blue', linestyle='--', linewidth=2, \n",
    "                             label=f'Annual {percentile_threshold.value:.0f}th Percentile')\n",
    "            axes[2,0].axhline(user_threshold, color='green', linestyle='-', linewidth=2, \n",
    "                             label=f'User Threshold ({user_threshold}¬∞C)')\n",
    "            axes[2,0].plot(months, monthly_max_temps, 's-', linewidth=2, markersize=6, \n",
    "                          color='orange', label=f'Avg Max Temp {analysis_year_val}')\n",
    "            \n",
    "            axes[2,0].set_xlabel('Month')\n",
    "            axes[2,0].set_ylabel('Temperature (¬∞C)')\n",
    "            axes[2,0].set_title(f'Monthly Threshold Comparison ({analysis_year_val})', fontweight='bold')\n",
    "            axes[2,0].set_xticks(months)\n",
    "            axes[2,0].set_xticklabels(month_names)\n",
    "            axes[2,0].legend()\n",
    "            axes[2,0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Show which thresholds are used (max of absolute or percentile)\n",
    "            effective_seasonal = [max(user_threshold, pct) for pct in seasonal_pct_monthly]\n",
    "            effective_annual = max(user_threshold, annual_percentile_val)\n",
    "            \n",
    "            axes[2,1].plot(months, effective_seasonal, 'o-', linewidth=3, markersize=8, \n",
    "                          color='red', label='Seasonal Effective Threshold')\n",
    "            axes[2,1].axhline(effective_annual, color='blue', linestyle='--', linewidth=3,\n",
    "                             label='Annual Effective Threshold')\n",
    "            axes[2,1].plot(months, monthly_max_temps, 's-', linewidth=2, markersize=6, \n",
    "                          color='orange', label=f'Avg Max Temp {analysis_year_val}')\n",
    "            \n",
    "            axes[2,1].set_xlabel('Month')\n",
    "            axes[2,1].set_ylabel('Temperature (¬∞C)')\n",
    "            axes[2,1].set_title(f'Effective Thresholds ({analysis_year_val})', fontweight='bold')\n",
    "            axes[2,1].set_xticks(months)\n",
    "            axes[2,1].set_xticklabels(month_names)\n",
    "            axes[2,1].legend()\n",
    "            axes[2,1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Temperature exceedance analysis\n",
    "            seasonal_exceed = [max(0, temp - thresh) for temp, thresh in zip(monthly_max_temps, effective_seasonal)]\n",
    "            annual_exceed = [max(0, temp - effective_annual) for temp in monthly_max_temps]\n",
    "            \n",
    "            axes[2,2].plot(months, seasonal_exceed, 'o-', linewidth=2, markersize=6, \n",
    "                          color='red', label='Seasonal Exceedance')\n",
    "            axes[2,2].plot(months, annual_exceed, 's-', linewidth=2, markersize=6, \n",
    "                          color='blue', label='Annual Exceedance')\n",
    "            axes[2,2].axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "            \n",
    "            axes[2,2].set_xlabel('Month')\n",
    "            axes[2,2].set_ylabel('Temperature Exceedance (¬∞C)')\n",
    "            axes[2,2].set_title(f'Monthly Temperature Exceedance ({analysis_year_val})', fontweight='bold')\n",
    "            axes[2,2].set_xticks(months)\n",
    "            axes[2,2].set_xticklabels(month_names)\n",
    "            axes[2,2].legend()\n",
    "            axes[2,2].grid(True, alpha=0.3)\n",
    "            \n",
    "        except Exception as monthly_error:\n",
    "            print(f'‚ö†Ô∏è Error creating monthly comparison: {monthly_error}')\n",
    "            # Fill with placeholder text\n",
    "            for ax in [axes[2,0], axes[2,1], axes[2,2]]:\n",
    "                ax.text(0.5, 0.5, 'Monthly comparison\\nunavailable', \n",
    "                       ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "                ax.set_title('Monthly Analysis - Error', fontweight='bold')\n",
    "        \n",
    "        # NEW: Full Time Series Analysis (2003-2020)\n",
    "        print('üìä Creating full time series analysis (2003-2020)...')\n",
    "        \n",
    "        try:\n",
    "            # Get full time series data\n",
    "            ref_start = reference_start.value\n",
    "            ref_end = reference_end.value\n",
    "            analysis_year_val = analysis_year.value\n",
    "            \n",
    "            # Get all data from reference start to analysis year\n",
    "            full_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{analysis_year_val}-12-31'))\n",
    "            \n",
    "            # Calculate annual statistics for each year\n",
    "            years = range(ref_start, analysis_year_val + 1)\n",
    "            annual_max_temps_ts = []\n",
    "            annual_mean_temps_ts = []\n",
    "            annual_percentile_ts = []\n",
    "            \n",
    "            # Get reference data for consistent percentile calculation\n",
    "            reference_data = temperature_data.sel(time=slice(f'{ref_start}-01-01', f'{ref_end}-12-31'))\n",
    "            ref_percentile = float(reference_data.temperature.quantile(\n",
    "                percentile_threshold.value/100, dim='time', skipna=True\n",
    "            ).mean(dim=['latitude', 'longitude']).values)\n",
    "            \n",
    "            for year in years:\n",
    "                year_data = full_data.sel(time=str(year))\n",
    "                if len(year_data.time) > 0:\n",
    "                    # Annual maximum temperature (spatial average)\n",
    "                    year_max = float(year_data.temperature.max(dim='time').mean(dim=['latitude', 'longitude']).values)\n",
    "                    annual_max_temps_ts.append(year_max)\n",
    "                    \n",
    "                    # Annual mean temperature (spatial average)\n",
    "                    year_mean = float(year_data.temperature.mean(dim=['time', 'latitude', 'longitude']).values)\n",
    "                    annual_mean_temps_ts.append(year_mean)\n",
    "                    \n",
    "                    # Annual percentile for this specific year\n",
    "                    year_pct = float(year_data.temperature.quantile(\n",
    "                        percentile_threshold.value/100, dim='time', skipna=True\n",
    "                    ).mean(dim=['latitude', 'longitude']).values)\n",
    "                    annual_percentile_ts.append(year_pct)\n",
    "                else:\n",
    "                    annual_max_temps_ts.append(np.nan)\n",
    "                    annual_mean_temps_ts.append(np.nan)\n",
    "                    annual_percentile_ts.append(np.nan)\n",
    "            \n",
    "            # Time series plot 1: Annual temperatures and thresholds\n",
    "            axes[3,0].plot(years, annual_max_temps_ts, 'o-', linewidth=2, markersize=6, \n",
    "                          color='red', label='Annual Max Temperature')\n",
    "            axes[3,0].plot(years, annual_mean_temps_ts, 's-', linewidth=2, markersize=4, \n",
    "                          color='blue', label='Annual Mean Temperature')\n",
    "            axes[3,0].axhline(ref_percentile, color='green', linestyle='--', linewidth=2, \n",
    "                             label=f'Reference {percentile_threshold.value:.0f}th Percentile')\n",
    "            axes[3,0].axhline(user_threshold, color='orange', linestyle='-', linewidth=2, \n",
    "                             label=f'User Threshold ({user_threshold}¬∞C)')\n",
    "            \n",
    "            axes[3,0].set_xlabel('Year')\n",
    "            axes[3,0].set_ylabel('Temperature (¬∞C)')\n",
    "            axes[3,0].set_title('Temperature Time Series (2003-2020)', fontweight='bold')\n",
    "            axes[3,0].legend()\n",
    "            axes[3,0].grid(True, alpha=0.3)\n",
    "            axes[3,0].set_xlim(ref_start-0.5, analysis_year_val+0.5)\n",
    "            \n",
    "            # Time series plot 2: Annual percentiles vs reference\n",
    "            axes[3,1].plot(years, annual_percentile_ts, 'o-', linewidth=2, markersize=6, \n",
    "                          color='purple', label=f'Annual {percentile_threshold.value:.0f}th Percentile')\n",
    "            axes[3,1].axhline(ref_percentile, color='green', linestyle='--', linewidth=2, \n",
    "                             label=f'Reference {percentile_threshold.value:.0f}th Percentile')\n",
    "            axes[3,1].axhline(user_threshold, color='orange', linestyle='-', linewidth=2, \n",
    "                             label=f'User Threshold ({user_threshold}¬∞C)')\n",
    "            \n",
    "            axes[3,1].set_xlabel('Year')\n",
    "            axes[3,1].set_ylabel('Temperature (¬∞C)')\n",
    "            axes[3,1].set_title('Annual Percentiles vs Reference', fontweight='bold')\n",
    "            axes[3,1].legend()\n",
    "            axes[3,1].grid(True, alpha=0.3)\n",
    "            axes[3,1].set_xlim(ref_start-0.5, analysis_year_val+0.5)\n",
    "            \n",
    "            # Time series plot 3: Temperature anomalies\n",
    "            mean_temp_baseline = np.mean(annual_mean_temps_ts[:-1])  # Exclude analysis year\n",
    "            mean_anomalies = [temp - mean_temp_baseline for temp in annual_mean_temps_ts]\n",
    "            max_temp_baseline = np.mean(annual_max_temps_ts[:-1])  # Exclude analysis year\n",
    "            max_anomalies = [temp - max_temp_baseline for temp in annual_max_temps_ts]\n",
    "            \n",
    "            axes[3,2].plot(years, mean_anomalies, 'o-', linewidth=2, markersize=6, \n",
    "                          color='blue', label='Mean Temp Anomaly')\n",
    "            axes[3,2].plot(years, max_anomalies, 's-', linewidth=2, markersize=6, \n",
    "                          color='red', label='Max Temp Anomaly')\n",
    "            axes[3,2].axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "            axes[3,2].axvline(analysis_year_val, color='gray', linestyle=':', alpha=0.7, \n",
    "                             label=f'Analysis Year ({analysis_year_val})')\n",
    "            \n",
    "            axes[3,2].set_xlabel('Year')\n",
    "            axes[3,2].set_ylabel('Temperature Anomaly (¬∞C)')\n",
    "            axes[3,2].set_title('Temperature Anomalies (relative to 2003-2019)', fontweight='bold')\n",
    "            axes[3,2].legend()\n",
    "            axes[3,2].grid(True, alpha=0.3)\n",
    "            axes[3,2].set_xlim(ref_start-0.5, analysis_year_val+0.5)\n",
    "            \n",
    "        except Exception as timeseries_error:\n",
    "            print(f'‚ö†Ô∏è Error creating time series analysis: {timeseries_error}')\n",
    "            import traceback\n",
    "            print(f'   Details: {traceback.format_exc()}')\n",
    "            # Fill with placeholder text\n",
    "            for ax in [axes[3,0], axes[3,1], axes[3,2]]:\n",
    "                ax.text(0.5, 0.5, 'Time series analysis\\nunavailable', \n",
    "                       ha='center', va='center', transform=ax.transAxes, fontsize=12)\n",
    "                ax.set_title('Time Series Analysis - Error', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed statistics\n",
    "        print('\\nüìä DETAILED COMPARISON STATISTICS:')\n",
    "        print(f'üî¨ Seasonal Method:')\n",
    "        print(f'   Range: {seasonal_clean.min():.0f} to {seasonal_clean.max():.0f} heat days')\n",
    "        print(f'   Mean: {seasonal_clean.mean():.1f} ¬± {seasonal_clean.std():.1f}')\n",
    "        print(f'   Median: {np.median(seasonal_clean):.1f}')\n",
    "        print(f'   Pixels with >0: {(seasonal_clean > 0).sum()} ({(seasonal_clean > 0).mean()*100:.1f}%)')\n",
    "        \n",
    "        print(f'\\nüìÖ Annual Method:')\n",
    "        print(f'   Range: {annual_clean.min():.0f} to {annual_clean.max():.0f} heat days')\n",
    "        print(f'   Mean: {annual_clean.mean():.1f} ¬± {annual_clean.std():.1f}')\n",
    "        print(f'   Median: {np.median(annual_clean):.1f}')\n",
    "        print(f'   Pixels with >0: {(annual_clean > 0).sum()} ({(annual_clean > 0).mean()*100:.1f}%)')\n",
    "        \n",
    "        # Correlation analysis\n",
    "        correlation = np.corrcoef(annual_clean, seasonal_clean)[0,1]\n",
    "        print(f'\\nüìà Correlation between methods: {correlation:.3f}')\n",
    "        \n",
    "        if correlation > 0.8:\n",
    "            print('   ‚úÖ Strong positive correlation - methods generally agree')\n",
    "        elif correlation > 0.5:\n",
    "            print('   ‚ö†Ô∏è Moderate correlation - some differences in spatial patterns')\n",
    "        else:\n",
    "            print('   üîç Low correlation - significant methodological differences')\n",
    "        \n",
    "        # Monthly threshold insights\n",
    "        if 'seasonal_pct_monthly' in locals():\n",
    "            print(f'\\nüìÖ MONTHLY THRESHOLD INSIGHTS:')\n",
    "            print(f'   Seasonal threshold range: {min(seasonal_pct_monthly):.1f} to {max(seasonal_pct_monthly):.1f}¬∞C')\n",
    "            print(f'   Annual threshold (constant): {annual_percentile_val:.1f}¬∞C')\n",
    "            print(f'   User threshold: {user_threshold}¬∞C')\n",
    "            \n",
    "            seasonal_var = np.var(seasonal_pct_monthly)\n",
    "            print(f'   Seasonal variation: {seasonal_var:.2f}¬∞C¬≤ (higher = more seasonal contrast)')\n",
    "        \n",
    "        # Time series insights\n",
    "        if 'annual_max_temps_ts' in locals():\n",
    "            print(f'\\nüìà TIME SERIES INSIGHTS (2003-2020):')\n",
    "            print(f'   Average annual max: {np.nanmean(annual_max_temps_ts):.1f}¬∞C')\n",
    "            print(f'   Average annual mean: {np.nanmean(annual_mean_temps_ts):.1f}¬∞C')\n",
    "            print(f'   Max temp trend: {np.polyfit(years, annual_max_temps_ts, 1)[0]:.3f}¬∞C/year')\n",
    "            print(f'   {analysis_year_val} max temp anomaly: {max_anomalies[-1]:+.1f}¬∞C')\n",
    "            print(f'   {analysis_year_val} mean temp anomaly: {mean_anomalies[-1]:+.1f}¬∞C')\n",
    "            \n",
    "        print('\\n‚úÖ Visualization complete!')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error creating visualizations: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "viz_button = widgets.Button(description='üìä Create Visualizations', button_style='info')\n",
    "viz_button.on_click(lambda b: create_seasonal_visualizations())\n",
    "\n",
    "display(viz_button)\n",
    "print('üìä Ready to create seasonal analysis visualizations')\n",
    "print('üî¨ Will compare seasonal vs annual methodologies')\n",
    "print('üìà Includes spatial maps, distributions, correlation analysis, monthly and time series comparisons')\n",
    "print('üìÖ NEW: Monthly threshold comparison + Full time series analysis (2003-2020)')\n",
    "print('‚è≥ Enhanced visualization shows temperature trends, anomalies, and temporal context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Step 6: Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a050c0eb2b74f1ab853beae3bb1cc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='üìÅ Export Results', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Ready to export seasonal analysis results\n",
      "üî¨ Will include both seasonal and annual method results for comparison\n",
      "üåç FIXED: NetCDF export now includes proper WGS84 CRS metadata from notebook 17\n"
     ]
    }
   ],
   "source": [
    "def export_seasonal_results():\n",
    "    '''Export seasonal analysis results to ../outputs directory'''\n",
    "    global analysis_results, temperature_data\n",
    "    \n",
    "    if analysis_results is None:\n",
    "        print('‚ùå Please run seasonal analysis first!')\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        print('üìÅ Exporting seasonal analysis results...')\n",
    "        year = analysis_year.value\n",
    "        \n",
    "        # Create outputs directory\n",
    "        os.makedirs('../outputs', exist_ok=True)\n",
    "        \n",
    "        # 1. Summary Table with Both Methods\n",
    "        print('   üìÑ Creating comparison summary...')\n",
    "        \n",
    "        seasonal_heat_days = analysis_results['seasonal_heat_days']\n",
    "        annual_heat_days = analysis_results['annual_heat_days']\n",
    "        \n",
    "        summary_data = [\n",
    "            {\n",
    "                'method': 'seasonal',\n",
    "                'mean_heat_days': float(seasonal_heat_days.mean().values),\n",
    "                'max_heat_days': float(seasonal_heat_days.max().values),\n",
    "                'min_heat_days': float(seasonal_heat_days.min().values),\n",
    "                'std_heat_days': float(seasonal_heat_days.std().values),\n",
    "                'pixels_with_heat_days': int((seasonal_heat_days > 0).sum().values),\n",
    "                'total_pixels': int(seasonal_heat_days.count().values)\n",
    "            },\n",
    "            {\n",
    "                'method': 'annual',\n",
    "                'mean_heat_days': float(annual_heat_days.mean().values),\n",
    "                'max_heat_days': float(annual_heat_days.max().values),\n",
    "                'min_heat_days': float(annual_heat_days.min().values),\n",
    "                'std_heat_days': float(annual_heat_days.std().values),\n",
    "                'pixels_with_heat_days': int((annual_heat_days > 0).sum().values),\n",
    "                'total_pixels': int(annual_heat_days.count().values)\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_filename = f'../outputs/seasonal_comparison_{year}.csv'\n",
    "        summary_df.to_csv(summary_filename, index=False)\n",
    "        print(f'   ‚úÖ Comparison summary saved: {summary_filename}')\n",
    "        \n",
    "        # Display summary\n",
    "        print('\\nüìä METHODOLOGY COMPARISON:')\n",
    "        display(summary_df)\n",
    "        \n",
    "        # 2. Detailed Pixel Export\n",
    "        print('\\n   üìä Creating detailed pixel export...')\n",
    "        \n",
    "        lats = seasonal_heat_days.latitude.values\n",
    "        lons = seasonal_heat_days.longitude.values\n",
    "        \n",
    "        pixel_data = []\n",
    "        for i, lat in enumerate(lats):\n",
    "            for j, lon in enumerate(lons):\n",
    "                row = {\n",
    "                    'pixel_id': f'{i}_{j}',\n",
    "                    'latitude': float(lat),\n",
    "                    'longitude': float(lon),\n",
    "                    'seasonal_heat_days': float(seasonal_heat_days.loc[lat, lon].values),\n",
    "                    'annual_heat_days': float(annual_heat_days.loc[lat, lon].values),\n",
    "                    'heat_days_difference': float((seasonal_heat_days - annual_heat_days).loc[lat, lon].values),\n",
    "                    'seasonal_threshold_mean': float(analysis_results['seasonal_percentiles_mean'].loc[lat, lon].values),\n",
    "                    'annual_percentile': float(analysis_results['annual_percentile'].loc[lat, lon].values),\n",
    "                    'annual_max_temp': float(analysis_results['annual_max'].loc[lat, lon].values)\n",
    "                }\n",
    "                pixel_data.append(row)\n",
    "        \n",
    "        pixel_df = pd.DataFrame(pixel_data)\n",
    "        pixel_filename = f'../outputs/seasonal_pixels_{year}.csv'\n",
    "        pixel_df.to_csv(pixel_filename, index=False)\n",
    "        \n",
    "        print(f'   ‚úÖ Detailed pixel data saved: {pixel_filename}')\n",
    "        print(f'      Rows: {len(pixel_df):,}')\n",
    "        \n",
    "        # Show sample\n",
    "        print('\\nüìä SAMPLE PIXEL DATA:')\n",
    "        display(pixel_df.head(10))\n",
    "        \n",
    "        # 3. NetCDF Export with PROPER CRS (Fixed from notebook 17)\n",
    "        print('\\n   üì¶ Creating NetCDF file with proper CRS...')\n",
    "        \n",
    "        # Prepare spatial results\n",
    "        spatial_results = {\n",
    "            'seasonal_heat_days': seasonal_heat_days,\n",
    "            'annual_heat_days': annual_heat_days,\n",
    "            'heat_days_difference': seasonal_heat_days - annual_heat_days,\n",
    "            'seasonal_percentiles_mean': analysis_results['seasonal_percentiles_mean'],\n",
    "            'annual_percentile': analysis_results['annual_percentile'],\n",
    "            'annual_max': analysis_results['annual_max'],\n",
    "            'annual_min': analysis_results['annual_min'],\n",
    "            'annual_range': analysis_results['annual_range']\n",
    "        }\n",
    "        \n",
    "        # Fill NaN with 0 for consistent export\n",
    "        for k, v in spatial_results.items():\n",
    "            spatial_results[k] = v.fillna(0)\n",
    "        \n",
    "        results_ds = xr.Dataset(spatial_results)\n",
    "        \n",
    "        # Add proper CRS information (WGS84) - FIXED VERSION FROM NOTEBOOK 17\n",
    "        results_ds.latitude.attrs['standard_name'] = 'latitude'\n",
    "        results_ds.latitude.attrs['long_name'] = 'latitude'\n",
    "        results_ds.latitude.attrs['units'] = 'degrees_north'\n",
    "        results_ds.latitude.attrs['axis'] = 'Y'\n",
    "        \n",
    "        results_ds.longitude.attrs['standard_name'] = 'longitude'\n",
    "        results_ds.longitude.attrs['long_name'] = 'longitude'\n",
    "        results_ds.longitude.attrs['units'] = 'degrees_east'\n",
    "        results_ds.longitude.attrs['axis'] = 'X'\n",
    "        \n",
    "        # Add CRS variable following CF conventions\n",
    "        crs = xr.DataArray(\n",
    "            data=np.int32(1),\n",
    "            attrs={\n",
    "                'grid_mapping_name': 'latitude_longitude',\n",
    "                'longitude_of_prime_meridian': 0.0,\n",
    "                'semi_major_axis': 6378137.0,\n",
    "                'inverse_flattening': 298.257223563,\n",
    "                'spatial_ref': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]',\n",
    "                'crs_wkt': 'GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]'\n",
    "            }\n",
    "        )\n",
    "        results_ds['crs'] = crs\n",
    "        \n",
    "        # Add grid_mapping attribute to all data variables\n",
    "        for var_name in results_ds.data_vars:\n",
    "            if var_name != 'crs':\n",
    "                results_ds[var_name].attrs['grid_mapping'] = 'crs'\n",
    "        \n",
    "        # Add metadata\n",
    "        results_ds.attrs.update({\n",
    "            'analysis_year': year,\n",
    "            'reference_period': f'{reference_start.value}-{reference_end.value}',\n",
    "            'created': datetime.now().isoformat(),\n",
    "            'absolute_threshold': absolute_threshold.value,\n",
    "            'percentile_threshold': percentile_threshold.value,\n",
    "            'day_window': day_window.value,\n",
    "            'methodology': 'seasonal_percentile_¬±window_days',\n",
    "            'formula': 'Heat_Day = LST_max > max(absolute_threshold, seasonal_percentile)',\n",
    "            'crs': 'EPSG:4326'\n",
    "        })\n",
    "        \n",
    "        netcdf_filename = f'../outputs/seasonal_analysis_{year}.nc'\n",
    "        results_ds.to_netcdf(netcdf_filename)\n",
    "        \n",
    "        print(f'   ‚úÖ NetCDF saved with proper CRS: {netcdf_filename}')\n",
    "        print(f'      Variables: {list(results_ds.data_vars)}')\n",
    "        print(f'      Dimensions: {dict(results_ds.dims)}')\n",
    "        print(f'      CRS: EPSG:4326 (WGS84)')\n",
    "        print(f'      File size: {os.path.getsize(netcdf_filename) / 1024**2:.1f} MB')\n",
    "        \n",
    "        # 4. Create methodology documentation\n",
    "        print('\\n   üìù Creating methodology documentation...')\n",
    "        \n",
    "        doc_content = f\"\"\"SEASONAL EXTREME HEAT DAYS ANALYSIS - METHODOLOGY REPORT\n",
    "===========================================================\n",
    "Generated: {datetime.now().isoformat()}\n",
    "Analysis Year: {year}\n",
    "Reference Period: {reference_start.value}-{reference_end.value}\n",
    "\n",
    "METHODOLOGY:\n",
    "============\n",
    "Formula: Surface_Heat_Day = 1 if LST_daily_max > max(LST_abs, LST_rel)\n",
    "\n",
    "Where:\n",
    "- LST_abs = {absolute_threshold.value}¬∞C (absolute threshold)\n",
    "- LST_rel = {percentile_threshold.value}th percentile of temperatures for calendar day ¬± {day_window.value} days\n",
    "- Calendar day window: Each day compared to historical temperatures for same day ¬± {day_window.value} days\n",
    "- Reference period: {reference_end.value - reference_start.value + 1} years of historical data\n",
    "\n",
    "SCIENTIFIC RATIONALE:\n",
    "====================\n",
    "1. Seasonal Context: July heat vs January heat appropriately weighted\n",
    "2. Climatological Accuracy: Follows meteorological best practices\n",
    "3. Sensitive Detection: Can identify winter/spring heat anomalies\n",
    "4. Day-specific Baselines: Each day compared to its historical context\n",
    "\n",
    "RESULTS SUMMARY:\n",
    "===============\n",
    "Seasonal Method:\n",
    "- Mean heat days: {seasonal_heat_days.mean().values:.1f}\n",
    "- Max heat days: {seasonal_heat_days.max().values:.0f}\n",
    "- Pixels with heat days: {(seasonal_heat_days > 0).sum().values} of {seasonal_heat_days.count().values}\n",
    "\n",
    "Annual Method (comparison):\n",
    "- Mean heat days: {annual_heat_days.mean().values:.1f}\n",
    "- Max heat days: {annual_heat_days.max().values:.0f}\n",
    "- Pixels with heat days: {(annual_heat_days > 0).sum().values} of {annual_heat_days.count().values}\n",
    "\n",
    "DIFFERENCE (Seasonal - Annual):\n",
    "- Mean difference: {(seasonal_heat_days - annual_heat_days).mean().values:.1f} days\n",
    "- Correlation: {np.corrcoef(seasonal_heat_days.values.flatten(), annual_heat_days.values.flatten())[0,1]:.3f}\n",
    "\n",
    "COORDINATE REFERENCE SYSTEM:\n",
    "===========================\n",
    "- CRS: EPSG:4326 (WGS84 Geographic)\n",
    "- Units: Decimal degrees\n",
    "- Datum: World Geodetic System 1984\n",
    "- NetCDF includes proper CF-compliant CRS metadata\n",
    "\n",
    "FILES GENERATED:\n",
    "===============\n",
    "1. {summary_filename} - Method comparison summary\n",
    "2. {pixel_filename} - Detailed pixel-level results\n",
    "3. {netcdf_filename} - NetCDF spatial dataset WITH PROPER CRS\n",
    "4. seasonal_methodology_{year}.txt - This documentation\n",
    "\n",
    "The seasonal methodology provides more climatologically appropriate \n",
    "extreme heat detection by accounting for natural seasonal temperature cycles.\n",
    "NetCDF file includes proper CRS metadata for GIS compatibility.\n",
    "\"\"\"\n",
    "        \n",
    "        doc_filename = f'../outputs/seasonal_methodology_{year}.txt'\n",
    "        with open(doc_filename, 'w') as f:\n",
    "            f.write(doc_content)\n",
    "        \n",
    "        print(f'   ‚úÖ Methodology documentation saved: {doc_filename}')\n",
    "        \n",
    "        print('\\n‚úÖ Export complete with PROPER CRS!')\n",
    "        print('\\nüìä Files created:')\n",
    "        print(f'   ‚Ä¢ {summary_filename} - Method comparison')\n",
    "        print(f'   ‚Ä¢ {pixel_filename} - Detailed pixel results')\n",
    "        print(f'   ‚Ä¢ {netcdf_filename} - NetCDF with WGS84 CRS metadata') \n",
    "        print(f'   ‚Ä¢ {doc_filename} - Methodology documentation')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error exporting: {e}')\n",
    "        import traceback\n",
    "        print(f'   Details: {traceback.format_exc()}')\n",
    "\n",
    "export_button = widgets.Button(description='üìÅ Export Results', button_style='warning')\n",
    "export_button.on_click(lambda b: export_seasonal_results())\n",
    "\n",
    "display(export_button)\n",
    "print('üìÅ Ready to export seasonal analysis results')\n",
    "print('üî¨ Will include both seasonal and annual method results for comparison')\n",
    "print('üåç FIXED: NetCDF export now includes proper WGS84 CRS metadata from notebook 17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook implements the **climatologically appropriate** extreme heat day calculation using seasonal percentiles:\n",
    "\n",
    "### üî¨ **Enhanced Methodology:**\n",
    "- **Day-specific thresholds**: Each day compared to historical temperatures for same calendar day ¬± window\n",
    "- **Seasonal context**: July heat vs January heat appropriately weighted  \n",
    "- **Formula**: `Heat_Day = LST_max > max(absolute_threshold, seasonal_percentile)`\n",
    "- **Robust baselines**: Uses 30+ years of reference data\n",
    "\n",
    "### üìä **Complete Workflow:**\n",
    "1. **ROI Selection** - Same interface as notebook 17\n",
    "2. **Configuration** - Enhanced with seasonal parameters\n",
    "3. **Data Extraction** - Extended time period for robust percentiles\n",
    "4. **Seasonal Analysis** - New day-of-year percentile calculation\n",
    "5. **Comparison Visualization** - Seasonal vs annual methods\n",
    "6. **Export** - Comprehensive results with methodology documentation\n",
    "\n",
    "### üéØ **Scientific Advantages:**\n",
    "- More sensitive to seasonal heat anomalies\n",
    "- Follows established meteorological practices\n",
    "- Can detect winter/spring extreme heat events\n",
    "- Provides climatologically meaningful baselines\n",
    "\n",
    "This represents a significant methodological improvement over simple annual percentiles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the CRS is all wrong here, the final exports are in the incorrect CRS - apply fix from notebook 17\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
